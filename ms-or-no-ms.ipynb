{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69f933f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce GTX 1660, compute capability 7.5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Dataset (Bangla ( Bengali ) sentiment analysis classification benchmark dataset corpus) : https://data.mendeley.com/datasets/p6zc7krs37/4\n",
    "\"\"\"\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import *\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import PorterStemmer\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras import mixed_precision\n",
    "import tensorflow as tf\n",
    "tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, LearningRateScheduler\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dc3c45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_units = 50\n",
    "w_decay = 0.05\n",
    "dropout_rate = 0.2\n",
    "epochs_to_run = 500\n",
    "sequence_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8966bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500 positive sentences\n",
      "3307 negative sentences\n",
      "3307 positive sentences\n",
      "3307 negative sentences\n"
     ]
    }
   ],
   "source": [
    "# Loading Bangla ( Bengali ) sentiment analysis classification benchmark dataset\n",
    "positive_sentences = []\n",
    "f = open('../datasets/all_positive_8500.txt','r', encoding = 'utf-8')\n",
    "for line in f:\n",
    "    positive_sentences.append(line.strip())\n",
    "\n",
    "negative_sentences = []\n",
    "f = open('../datasets/all_negative_3307.txt','r', encoding = 'utf-8')\n",
    "for line in f:\n",
    "    negative_sentences.append(line.strip())\n",
    "    \n",
    "print(len(positive_sentences), 'positive sentences')\n",
    "print(len(negative_sentences), 'negative sentences')\n",
    "\n",
    "import random\n",
    "random.shuffle(positive_sentences)\n",
    "\n",
    "for i in range(len(positive_sentences)-len(negative_sentences)):\n",
    "    positive_sentences.pop(0)\n",
    "\n",
    "print(len(positive_sentences), 'positive sentences')\n",
    "print(len(negative_sentences), 'negative sentences')\n",
    "\n",
    "\n",
    "y_pos = [1 for i in range(len(positive_sentences))]\n",
    "y_neg = [0 for i in range(len(negative_sentences))]\n",
    "\n",
    "X = positive_sentences + negative_sentences\n",
    "y = y_pos + y_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0c24841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141148\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec.load(\"word2vec.model\")\n",
    "words = list(w2v_model.wv.index_to_key)\n",
    "vocab_size = len(words)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4113e2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab_size)\n",
    "tokenizer.fit_on_texts(X)\n",
    "y = np.array(y)\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "X = pad_sequences(X, sequence_length)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "X_train_val = X_train\n",
    "y_train_val = y_train\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_val, test_size=0.2, random_state=1, stratify=y_train_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "747457da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "def gensim_to_keras_embedding(model, train_embeddings=False):\n",
    "    \"\"\"Get a Keras 'Embedding' layer with weights set from Word2Vec model's learned word embeddings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_embeddings : bool\n",
    "        If False, the returned weights are frozen and stopped from being updated.\n",
    "        If True, the weights can / will be further updated in Keras.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    `keras.layers.Embedding`\n",
    "        Embedding layer, to be used as input to deeper network layers.\n",
    "\n",
    "    \"\"\"\n",
    "    keyed_vectors = model.wv  # structure holding the result of training\n",
    "    weights = keyed_vectors.vectors  # vectors themselves, a 2D numpy array    \n",
    "    index_to_key = keyed_vectors.index_to_key  # which row in `weights` corresponds to which word?\n",
    "\n",
    "    layer = Embedding(\n",
    "        input_dim=weights.shape[0],\n",
    "        output_dim=weights.shape[1],\n",
    "        weights=[weights],\n",
    "        trainable=train_embeddings,\n",
    "    )\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41679010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 80)\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 200, 100)     14114800    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 200, 50), (N 30200       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 200, 1)       51          lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 200)          0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 200)          0           time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 200)          0           global_average_pooling1d[0][0]   \n",
      "                                                                 flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "before_split (Activation)       (None, 200)          0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_split (TensorFlowOp [(None, 20), (None,  0           before_split[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 80)           0           tf_op_layer_split[0][0]          \n",
      "                                                                 tf_op_layer_split[0][1]          \n",
      "                                                                 tf_op_layer_split[0][8]          \n",
      "                                                                 tf_op_layer_split[0][9]          \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 8, 10, 1)     0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 8, 10, 2)     130         reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 8, 10, 2)     8           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 160)          0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "op_main (Dense)                 (None, 1)            51          lstm[0][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "op_conv (Dense)                 (None, 1)            161         flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "avg (Average)                   (None, 1)            0           op_main[0][0]                    \n",
      "                                                                 op_conv[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 14,145,401\n",
      "Trainable params: 30,597\n",
      "Non-trainable params: 14,114,804\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 10.3578 - op_main_loss: 0.7064 - op_conv_loss: 0.6924 - avg_loss: 0.6956 - op_main_accuracy: 0.5069 - op_conv_accuracy: 0.5328 - avg_accuracy: 0.5139\n",
      "Epoch 00001: val_avg_accuracy improved from -inf to 0.55807, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 3s 20ms/step - loss: 10.3578 - op_main_loss: 0.7064 - op_conv_loss: 0.6924 - avg_loss: 0.6956 - op_main_accuracy: 0.5069 - op_conv_accuracy: 0.5328 - avg_accuracy: 0.5139 - val_loss: 9.3239 - val_op_main_loss: 0.6798 - val_op_conv_loss: 0.6931 - val_avg_loss: 0.6839 - val_op_main_accuracy: 0.5590 - val_op_conv_accuracy: 0.4920 - val_avg_accuracy: 0.5581\n",
      "Epoch 2/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 8.4892 - op_main_loss: 0.6742 - op_conv_loss: 0.6916 - avg_loss: 0.6797 - op_main_accuracy: 0.5753 - op_conv_accuracy: 0.5424 - avg_accuracy: 0.5758\n",
      "Epoch 00002: val_avg_accuracy improved from 0.55807 to 0.63456, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 8.4876 - op_main_loss: 0.6741 - op_conv_loss: 0.6917 - avg_loss: 0.6797 - op_main_accuracy: 0.5751 - op_conv_accuracy: 0.5418 - avg_accuracy: 0.5756 - val_loss: 7.6705 - val_op_main_loss: 0.6492 - val_op_conv_loss: 0.6929 - val_avg_loss: 0.6682 - val_op_main_accuracy: 0.6336 - val_op_conv_accuracy: 0.4882 - val_avg_accuracy: 0.6346\n",
      "Epoch 3/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 7.0239 - op_main_loss: 0.6534 - op_conv_loss: 0.6899 - avg_loss: 0.6680 - op_main_accuracy: 0.6139 - op_conv_accuracy: 0.5527 - avg_accuracy: 0.6226\n",
      "Epoch 00003: val_avg_accuracy improved from 0.63456 to 0.67328, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 7.0239 - op_main_loss: 0.6534 - op_conv_loss: 0.6899 - avg_loss: 0.6680 - op_main_accuracy: 0.6139 - op_conv_accuracy: 0.5527 - avg_accuracy: 0.6226 - val_loss: 6.3712 - val_op_main_loss: 0.6247 - val_op_conv_loss: 0.6919 - val_avg_loss: 0.6545 - val_op_main_accuracy: 0.6648 - val_op_conv_accuracy: 0.5590 - val_avg_accuracy: 0.6733\n",
      "Epoch 4/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 5.8613 - op_main_loss: 0.6307 - op_conv_loss: 0.6823 - avg_loss: 0.6521 - op_main_accuracy: 0.6567 - op_conv_accuracy: 0.5814 - avg_accuracy: 0.6631\n",
      "Epoch 00004: val_avg_accuracy improved from 0.67328 to 0.70255, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 5.8597 - op_main_loss: 0.6303 - op_conv_loss: 0.6823 - avg_loss: 0.6518 - op_main_accuracy: 0.6574 - op_conv_accuracy: 0.5813 - avg_accuracy: 0.6638 - val_loss: 5.3448 - val_op_main_loss: 0.6031 - val_op_conv_loss: 0.6832 - val_avg_loss: 0.6384 - val_op_main_accuracy: 0.6950 - val_op_conv_accuracy: 0.6062 - val_avg_accuracy: 0.7025\n",
      "Epoch 5/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 4.9216 - op_main_loss: 0.6061 - op_conv_loss: 0.6548 - avg_loss: 0.6244 - op_main_accuracy: 0.6889 - op_conv_accuracy: 0.6269 - avg_accuracy: 0.6955\n",
      "Epoch 00005: val_avg_accuracy improved from 0.70255 to 0.73371, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 4.9209 - op_main_loss: 0.6060 - op_conv_loss: 0.6549 - avg_loss: 0.6244 - op_main_accuracy: 0.6886 - op_conv_accuracy: 0.6267 - avg_accuracy: 0.6954 - val_loss: 4.5102 - val_op_main_loss: 0.5829 - val_op_conv_loss: 0.6446 - val_avg_loss: 0.6067 - val_op_main_accuracy: 0.7224 - val_op_conv_accuracy: 0.6619 - val_avg_accuracy: 0.7337\n",
      "Epoch 6/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/133 [============================>.] - ETA: 0s - loss: 4.1887 - op_main_loss: 0.5862 - op_conv_loss: 0.6183 - avg_loss: 0.5929 - op_main_accuracy: 0.7228 - op_conv_accuracy: 0.6703 - avg_accuracy: 0.7345\n",
      "Epoch 00006: val_avg_accuracy improved from 0.73371 to 0.77243, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 4.1856 - op_main_loss: 0.5862 - op_conv_loss: 0.6180 - avg_loss: 0.5927 - op_main_accuracy: 0.7235 - op_conv_accuracy: 0.6701 - avg_accuracy: 0.7342 - val_loss: 3.8386 - val_op_main_loss: 0.5647 - val_op_conv_loss: 0.5874 - val_avg_loss: 0.5646 - val_op_main_accuracy: 0.7403 - val_op_conv_accuracy: 0.7243 - val_avg_accuracy: 0.7724\n",
      "Epoch 7/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 3.6085 - op_main_loss: 0.5676 - op_conv_loss: 0.5713 - avg_loss: 0.5563 - op_main_accuracy: 0.7335 - op_conv_accuracy: 0.7135 - avg_accuracy: 0.7483\n",
      "Epoch 00007: val_avg_accuracy did not improve from 0.77243\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 3.6059 - op_main_loss: 0.5677 - op_conv_loss: 0.5706 - avg_loss: 0.5561 - op_main_accuracy: 0.7339 - op_conv_accuracy: 0.7141 - avg_accuracy: 0.7491 - val_loss: 3.3972 - val_op_main_loss: 0.5418 - val_op_conv_loss: 0.5955 - val_avg_loss: 0.5448 - val_op_main_accuracy: 0.7535 - val_op_conv_accuracy: 0.6667 - val_avg_accuracy: 0.7450\n",
      "Epoch 8/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 3.1792 - op_main_loss: 0.5519 - op_conv_loss: 0.5391 - avg_loss: 0.5296 - op_main_accuracy: 0.7474 - op_conv_accuracy: 0.7405 - avg_accuracy: 0.7722\n",
      "Epoch 00008: val_avg_accuracy improved from 0.77243 to 0.77904, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 3.1758 - op_main_loss: 0.5517 - op_conv_loss: 0.5379 - avg_loss: 0.5290 - op_main_accuracy: 0.7481 - op_conv_accuracy: 0.7417 - avg_accuracy: 0.7732 - val_loss: 2.9880 - val_op_main_loss: 0.5243 - val_op_conv_loss: 0.5429 - val_avg_loss: 0.5090 - val_op_main_accuracy: 0.7668 - val_op_conv_accuracy: 0.7252 - val_avg_accuracy: 0.7790\n",
      "Epoch 9/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 2.8345 - op_main_loss: 0.5348 - op_conv_loss: 0.5007 - avg_loss: 0.5024 - op_main_accuracy: 0.7536 - op_conv_accuracy: 0.7719 - avg_accuracy: 0.7820\n",
      "Epoch 00009: val_avg_accuracy improved from 0.77904 to 0.80264, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 2.8345 - op_main_loss: 0.5352 - op_conv_loss: 0.5010 - avg_loss: 0.5027 - op_main_accuracy: 0.7524 - op_conv_accuracy: 0.7720 - avg_accuracy: 0.7814 - val_loss: 2.6774 - val_op_main_loss: 0.5086 - val_op_conv_loss: 0.4984 - val_avg_loss: 0.4835 - val_op_main_accuracy: 0.7762 - val_op_conv_accuracy: 0.7602 - val_avg_accuracy: 0.8026\n",
      "Epoch 10/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 2.5727 - op_main_loss: 0.5154 - op_conv_loss: 0.4754 - avg_loss: 0.4796 - op_main_accuracy: 0.7730 - op_conv_accuracy: 0.7866 - avg_accuracy: 0.8018\n",
      "Epoch 00010: val_avg_accuracy improved from 0.80264 to 0.80359, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 2.5694 - op_main_loss: 0.5151 - op_conv_loss: 0.4748 - avg_loss: 0.4791 - op_main_accuracy: 0.7739 - op_conv_accuracy: 0.7871 - avg_accuracy: 0.8017 - val_loss: 2.4777 - val_op_main_loss: 0.4909 - val_op_conv_loss: 0.5003 - val_avg_loss: 0.4672 - val_op_main_accuracy: 0.7875 - val_op_conv_accuracy: 0.7554 - val_avg_accuracy: 0.8036\n",
      "Epoch 11/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 2.3736 - op_main_loss: 0.5029 - op_conv_loss: 0.4555 - avg_loss: 0.4622 - op_main_accuracy: 0.7739 - op_conv_accuracy: 0.8002 - avg_accuracy: 0.8085\n",
      "Epoch 00011: val_avg_accuracy improved from 0.80359 to 0.83853, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 2.3729 - op_main_loss: 0.5029 - op_conv_loss: 0.4552 - avg_loss: 0.4620 - op_main_accuracy: 0.7741 - op_conv_accuracy: 0.8006 - avg_accuracy: 0.8088 - val_loss: 2.2021 - val_op_main_loss: 0.4760 - val_op_conv_loss: 0.4086 - val_avg_loss: 0.4271 - val_op_main_accuracy: 0.8008 - val_op_conv_accuracy: 0.8263 - val_avg_accuracy: 0.8385\n",
      "Epoch 12/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 2.2123 - op_main_loss: 0.4911 - op_conv_loss: 0.4332 - avg_loss: 0.4452 - op_main_accuracy: 0.7798 - op_conv_accuracy: 0.8125 - avg_accuracy: 0.8203\n",
      "Epoch 00012: val_avg_accuracy did not improve from 0.83853\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 2.2126 - op_main_loss: 0.4916 - op_conv_loss: 0.4336 - avg_loss: 0.4459 - op_main_accuracy: 0.7798 - op_conv_accuracy: 0.8126 - avg_accuracy: 0.8199 - val_loss: 2.2668 - val_op_main_loss: 0.4678 - val_op_conv_loss: 0.5337 - val_avg_loss: 0.4708 - val_op_main_accuracy: 0.7904 - val_op_conv_accuracy: 0.7328 - val_avg_accuracy: 0.7838\n",
      "Epoch 13/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 2.0869 - op_main_loss: 0.4797 - op_conv_loss: 0.4164 - avg_loss: 0.4338 - op_main_accuracy: 0.7846 - op_conv_accuracy: 0.8184 - avg_accuracy: 0.8229\n",
      "Epoch 00013: val_avg_accuracy did not improve from 0.83853\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 2.0881 - op_main_loss: 0.4801 - op_conv_loss: 0.4169 - avg_loss: 0.4342 - op_main_accuracy: 0.7843 - op_conv_accuracy: 0.8178 - avg_accuracy: 0.8225 - val_loss: 1.9581 - val_op_main_loss: 0.4483 - val_op_conv_loss: 0.3869 - val_avg_loss: 0.4014 - val_op_main_accuracy: 0.8093 - val_op_conv_accuracy: 0.8319 - val_avg_accuracy: 0.8366\n",
      "Epoch 14/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 1.9759 - op_main_loss: 0.4640 - op_conv_loss: 0.4021 - avg_loss: 0.4173 - op_main_accuracy: 0.7948 - op_conv_accuracy: 0.8232 - avg_accuracy: 0.8304\n",
      "Epoch 00014: val_avg_accuracy improved from 0.83853 to 0.83947, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 1.9758 - op_main_loss: 0.4644 - op_conv_loss: 0.4021 - avg_loss: 0.4175 - op_main_accuracy: 0.7940 - op_conv_accuracy: 0.8228 - avg_accuracy: 0.8299 - val_loss: 1.8691 - val_op_main_loss: 0.4404 - val_op_conv_loss: 0.3720 - val_avg_loss: 0.3927 - val_op_main_accuracy: 0.8036 - val_op_conv_accuracy: 0.8376 - val_avg_accuracy: 0.8395\n",
      "Epoch 15/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 1.8900 - op_main_loss: 0.4553 - op_conv_loss: 0.3875 - avg_loss: 0.4061 - op_main_accuracy: 0.7993 - op_conv_accuracy: 0.8365 - avg_accuracy: 0.8382\n",
      "Epoch 00015: val_avg_accuracy improved from 0.83947 to 0.84325, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 1.8917 - op_main_loss: 0.4551 - op_conv_loss: 0.3890 - avg_loss: 0.4067 - op_main_accuracy: 0.7999 - op_conv_accuracy: 0.8353 - avg_accuracy: 0.8379 - val_loss: 1.7707 - val_op_main_loss: 0.4234 - val_op_conv_loss: 0.3539 - val_avg_loss: 0.3750 - val_op_main_accuracy: 0.8225 - val_op_conv_accuracy: 0.8451 - val_avg_accuracy: 0.8432\n",
      "Epoch 16/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 1.8136 - op_main_loss: 0.4441 - op_conv_loss: 0.3740 - avg_loss: 0.3942 - op_main_accuracy: 0.8010 - op_conv_accuracy: 0.8380 - avg_accuracy: 0.8414\n",
      "Epoch 00016: val_avg_accuracy did not improve from 0.84325\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 1.8122 - op_main_loss: 0.4435 - op_conv_loss: 0.3737 - avg_loss: 0.3938 - op_main_accuracy: 0.8017 - op_conv_accuracy: 0.8384 - avg_accuracy: 0.8422 - val_loss: 1.7447 - val_op_main_loss: 0.4125 - val_op_conv_loss: 0.3742 - val_avg_loss: 0.3739 - val_op_main_accuracy: 0.8272 - val_op_conv_accuracy: 0.8432 - val_avg_accuracy: 0.8432\n",
      "Epoch 17/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 1.7576 - op_main_loss: 0.4362 - op_conv_loss: 0.3653 - avg_loss: 0.3854 - op_main_accuracy: 0.8063 - op_conv_accuracy: 0.8430 - avg_accuracy: 0.8418\n",
      "Epoch 00017: val_avg_accuracy did not improve from 0.84325\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 1.7549 - op_main_loss: 0.4353 - op_conv_loss: 0.3645 - avg_loss: 0.3846 - op_main_accuracy: 0.8077 - op_conv_accuracy: 0.8438 - avg_accuracy: 0.8429 - val_loss: 1.7990 - val_op_main_loss: 0.4132 - val_op_conv_loss: 0.4296 - val_avg_loss: 0.3991 - val_op_main_accuracy: 0.8196 - val_op_conv_accuracy: 0.8083 - val_avg_accuracy: 0.8225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 1.7007 - op_main_loss: 0.4269 - op_conv_loss: 0.3531 - avg_loss: 0.3745 - op_main_accuracy: 0.8190 - op_conv_accuracy: 0.8495 - avg_accuracy: 0.8495\n",
      "Epoch 00018: val_avg_accuracy did not improve from 0.84325\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 1.7033 - op_main_loss: 0.4276 - op_conv_loss: 0.3543 - avg_loss: 0.3755 - op_main_accuracy: 0.8181 - op_conv_accuracy: 0.8485 - avg_accuracy: 0.8483 - val_loss: 1.7250 - val_op_main_loss: 0.3988 - val_op_conv_loss: 0.4121 - val_avg_loss: 0.3794 - val_op_main_accuracy: 0.8272 - val_op_conv_accuracy: 0.8253 - val_avg_accuracy: 0.8338\n",
      "Epoch 19/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 1.6416 - op_main_loss: 0.4142 - op_conv_loss: 0.3386 - avg_loss: 0.3616 - op_main_accuracy: 0.8195 - op_conv_accuracy: 0.8582 - avg_accuracy: 0.8611\n",
      "Epoch 00019: val_avg_accuracy improved from 0.84325 to 0.86497, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 1.6416 - op_main_loss: 0.4142 - op_conv_loss: 0.3386 - avg_loss: 0.3616 - op_main_accuracy: 0.8195 - op_conv_accuracy: 0.8582 - avg_accuracy: 0.8611 - val_loss: 1.5603 - val_op_main_loss: 0.3871 - val_op_conv_loss: 0.3165 - val_avg_loss: 0.3389 - val_op_main_accuracy: 0.8329 - val_op_conv_accuracy: 0.8659 - val_avg_accuracy: 0.8650\n",
      "Epoch 20/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 1.6120 - op_main_loss: 0.4097 - op_conv_loss: 0.3351 - avg_loss: 0.3568 - op_main_accuracy: 0.8211 - op_conv_accuracy: 0.8593 - avg_accuracy: 0.8581\n",
      "Epoch 00020: val_avg_accuracy did not improve from 0.86497\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 1.6105 - op_main_loss: 0.4095 - op_conv_loss: 0.3344 - avg_loss: 0.3563 - op_main_accuracy: 0.8214 - op_conv_accuracy: 0.8594 - avg_accuracy: 0.8587 - val_loss: 1.5299 - val_op_main_loss: 0.3805 - val_op_conv_loss: 0.3135 - val_avg_loss: 0.3332 - val_op_main_accuracy: 0.8347 - val_op_conv_accuracy: 0.8659 - val_avg_accuracy: 0.8593\n",
      "Epoch 21/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 1.5733 - op_main_loss: 0.4075 - op_conv_loss: 0.3215 - avg_loss: 0.3480 - op_main_accuracy: 0.8241 - op_conv_accuracy: 0.8672 - avg_accuracy: 0.8639\n",
      "Epoch 00021: val_avg_accuracy did not improve from 0.86497\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 1.5731 - op_main_loss: 0.4075 - op_conv_loss: 0.3213 - avg_loss: 0.3479 - op_main_accuracy: 0.8240 - op_conv_accuracy: 0.8672 - avg_accuracy: 0.8639 - val_loss: 1.5685 - val_op_main_loss: 0.3743 - val_op_conv_loss: 0.3603 - val_avg_loss: 0.3435 - val_op_main_accuracy: 0.8404 - val_op_conv_accuracy: 0.8442 - val_avg_accuracy: 0.8527\n",
      "Epoch 22/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 1.5445 - op_main_loss: 0.3977 - op_conv_loss: 0.3181 - avg_loss: 0.3429 - op_main_accuracy: 0.8300 - op_conv_accuracy: 0.8680 - avg_accuracy: 0.8721\n",
      "Epoch 00022: val_avg_accuracy did not improve from 0.86497\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 1.5393 - op_main_loss: 0.3961 - op_conv_loss: 0.3162 - avg_loss: 0.3412 - op_main_accuracy: 0.8313 - op_conv_accuracy: 0.8693 - avg_accuracy: 0.8736 - val_loss: 1.5091 - val_op_main_loss: 0.3879 - val_op_conv_loss: 0.3062 - val_avg_loss: 0.3342 - val_op_main_accuracy: 0.8281 - val_op_conv_accuracy: 0.8640 - val_avg_accuracy: 0.8640\n",
      "Epoch 23/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 1.5031 - op_main_loss: 0.3926 - op_conv_loss: 0.3025 - avg_loss: 0.3314 - op_main_accuracy: 0.8302 - op_conv_accuracy: 0.8765 - avg_accuracy: 0.8697\n",
      "Epoch 00023: val_avg_accuracy did not improve from 0.86497\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 1.5108 - op_main_loss: 0.3948 - op_conv_loss: 0.3056 - avg_loss: 0.3338 - op_main_accuracy: 0.8284 - op_conv_accuracy: 0.8745 - avg_accuracy: 0.8679 - val_loss: 1.4784 - val_op_main_loss: 0.3738 - val_op_conv_loss: 0.3058 - val_avg_loss: 0.3256 - val_op_main_accuracy: 0.8310 - val_op_conv_accuracy: 0.8697 - val_avg_accuracy: 0.8602\n",
      "Epoch 24/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 1.4869 - op_main_loss: 0.3902 - op_conv_loss: 0.2997 - avg_loss: 0.3287 - op_main_accuracy: 0.8355 - op_conv_accuracy: 0.8764 - avg_accuracy: 0.8755\n",
      "Epoch 00024: val_avg_accuracy did not improve from 0.86497\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 1.4869 - op_main_loss: 0.3902 - op_conv_loss: 0.2997 - avg_loss: 0.3287 - op_main_accuracy: 0.8355 - op_conv_accuracy: 0.8764 - avg_accuracy: 0.8755 - val_loss: 1.4809 - val_op_main_loss: 0.3673 - val_op_conv_loss: 0.3216 - val_avg_loss: 0.3273 - val_op_main_accuracy: 0.8357 - val_op_conv_accuracy: 0.8650 - val_avg_accuracy: 0.8621\n",
      "Epoch 25/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 1.4607 - op_main_loss: 0.3862 - op_conv_loss: 0.2917 - avg_loss: 0.3213 - op_main_accuracy: 0.8395 - op_conv_accuracy: 0.8865 - avg_accuracy: 0.8819\n",
      "Epoch 00025: val_avg_accuracy improved from 0.86497 to 0.87441, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 1.4652 - op_main_loss: 0.3874 - op_conv_loss: 0.2935 - avg_loss: 0.3228 - op_main_accuracy: 0.8384 - op_conv_accuracy: 0.8849 - avg_accuracy: 0.8807 - val_loss: 1.3972 - val_op_main_loss: 0.3590 - val_op_conv_loss: 0.2760 - val_avg_loss: 0.3041 - val_op_main_accuracy: 0.8470 - val_op_conv_accuracy: 0.8810 - val_avg_accuracy: 0.8744\n",
      "Epoch 26/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 1.4496 - op_main_loss: 0.3821 - op_conv_loss: 0.2929 - avg_loss: 0.3198 - op_main_accuracy: 0.8391 - op_conv_accuracy: 0.8800 - avg_accuracy: 0.8774\n",
      "Epoch 00026: val_avg_accuracy did not improve from 0.87441\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 1.4496 - op_main_loss: 0.3821 - op_conv_loss: 0.2929 - avg_loss: 0.3198 - op_main_accuracy: 0.8391 - op_conv_accuracy: 0.8800 - avg_accuracy: 0.8774 - val_loss: 1.4171 - val_op_main_loss: 0.3555 - val_op_conv_loss: 0.2995 - val_avg_loss: 0.3105 - val_op_main_accuracy: 0.8508 - val_op_conv_accuracy: 0.8669 - val_avg_accuracy: 0.8631\n",
      "Epoch 27/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 1.4311 - op_main_loss: 0.3767 - op_conv_loss: 0.2891 - avg_loss: 0.3164 - op_main_accuracy: 0.8392 - op_conv_accuracy: 0.8857 - avg_accuracy: 0.8788\n",
      "Epoch 00027: val_avg_accuracy improved from 0.87441 to 0.87724, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 1.4324 - op_main_loss: 0.3775 - op_conv_loss: 0.2892 - avg_loss: 0.3167 - op_main_accuracy: 0.8386 - op_conv_accuracy: 0.8859 - avg_accuracy: 0.8788 - val_loss: 1.3787 - val_op_main_loss: 0.3510 - val_op_conv_loss: 0.2800 - val_avg_loss: 0.3010 - val_op_main_accuracy: 0.8480 - val_op_conv_accuracy: 0.8772 - val_avg_accuracy: 0.8772\n",
      "Epoch 28/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 1.4102 - op_main_loss: 0.3728 - op_conv_loss: 0.2822 - avg_loss: 0.3101 - op_main_accuracy: 0.8404 - op_conv_accuracy: 0.8903 - avg_accuracy: 0.8817\n",
      "Epoch 00028: val_avg_accuracy improved from 0.87724 to 0.88008, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 1.4094 - op_main_loss: 0.3723 - op_conv_loss: 0.2822 - avg_loss: 0.3099 - op_main_accuracy: 0.8407 - op_conv_accuracy: 0.8904 - avg_accuracy: 0.8819 - val_loss: 1.3565 - val_op_main_loss: 0.3485 - val_op_conv_loss: 0.2693 - val_avg_loss: 0.2961 - val_op_main_accuracy: 0.8527 - val_op_conv_accuracy: 0.8839 - val_avg_accuracy: 0.8801\n",
      "Epoch 29/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 1.3854 - op_main_loss: 0.3675 - op_conv_loss: 0.2741 - avg_loss: 0.3038 - op_main_accuracy: 0.8409 - op_conv_accuracy: 0.8883 - avg_accuracy: 0.8880\n",
      "Epoch 00029: val_avg_accuracy did not improve from 0.88008\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 1.3845 - op_main_loss: 0.3672 - op_conv_loss: 0.2738 - avg_loss: 0.3036 - op_main_accuracy: 0.8412 - op_conv_accuracy: 0.8885 - avg_accuracy: 0.8882 - val_loss: 1.3937 - val_op_main_loss: 0.3451 - val_op_conv_loss: 0.3049 - val_avg_loss: 0.3065 - val_op_main_accuracy: 0.8546 - val_op_conv_accuracy: 0.8669 - val_avg_accuracy: 0.8687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 1.3723 - op_main_loss: 0.3605 - op_conv_loss: 0.2763 - avg_loss: 0.2999 - op_main_accuracy: 0.8483 - op_conv_accuracy: 0.8871 - avg_accuracy: 0.8847\n",
      "Epoch 00030: val_avg_accuracy did not improve from 0.88008\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 1.3723 - op_main_loss: 0.3605 - op_conv_loss: 0.2763 - avg_loss: 0.2999 - op_main_accuracy: 0.8483 - op_conv_accuracy: 0.8871 - avg_accuracy: 0.8847 - val_loss: 1.3858 - val_op_main_loss: 0.3623 - val_op_conv_loss: 0.2819 - val_avg_loss: 0.3078 - val_op_main_accuracy: 0.8414 - val_op_conv_accuracy: 0.8716 - val_avg_accuracy: 0.8678\n",
      "Epoch 31/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 1.3581 - op_main_loss: 0.3633 - op_conv_loss: 0.2653 - avg_loss: 0.2974 - op_main_accuracy: 0.8476 - op_conv_accuracy: 0.8932 - avg_accuracy: 0.8929\n",
      "Epoch 00031: val_avg_accuracy did not improve from 0.88008\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 1.3582 - op_main_loss: 0.3638 - op_conv_loss: 0.2648 - avg_loss: 0.2975 - op_main_accuracy: 0.8471 - op_conv_accuracy: 0.8939 - avg_accuracy: 0.8939 - val_loss: 1.3767 - val_op_main_loss: 0.3414 - val_op_conv_loss: 0.3033 - val_avg_loss: 0.3022 - val_op_main_accuracy: 0.8536 - val_op_conv_accuracy: 0.8754 - val_avg_accuracy: 0.8716\n",
      "Epoch 32/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 1.3439 - op_main_loss: 0.3551 - op_conv_loss: 0.2663 - avg_loss: 0.2937 - op_main_accuracy: 0.8511 - op_conv_accuracy: 0.8929 - avg_accuracy: 0.8872\n",
      "Epoch 00032: val_avg_accuracy did not improve from 0.88008\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 1.3419 - op_main_loss: 0.3541 - op_conv_loss: 0.2659 - avg_loss: 0.2930 - op_main_accuracy: 0.8516 - op_conv_accuracy: 0.8934 - avg_accuracy: 0.8873 - val_loss: 1.3520 - val_op_main_loss: 0.3373 - val_op_conv_loss: 0.2931 - val_avg_loss: 0.2947 - val_op_main_accuracy: 0.8536 - val_op_conv_accuracy: 0.8725 - val_avg_accuracy: 0.8763\n",
      "Epoch 33/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 1.3376 - op_main_loss: 0.3582 - op_conv_loss: 0.2621 - avg_loss: 0.2922 - op_main_accuracy: 0.8526 - op_conv_accuracy: 0.8947 - avg_accuracy: 0.8911\n",
      "Epoch 00033: val_avg_accuracy improved from 0.88008 to 0.88196, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 1.3332 - op_main_loss: 0.3574 - op_conv_loss: 0.2599 - avg_loss: 0.2908 - op_main_accuracy: 0.8528 - op_conv_accuracy: 0.8958 - avg_accuracy: 0.8920 - val_loss: 1.3172 - val_op_main_loss: 0.3427 - val_op_conv_loss: 0.2637 - val_avg_loss: 0.2873 - val_op_main_accuracy: 0.8480 - val_op_conv_accuracy: 0.8848 - val_avg_accuracy: 0.8820\n",
      "Epoch 34/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 1.3180 - op_main_loss: 0.3533 - op_conv_loss: 0.2553 - avg_loss: 0.2869 - op_main_accuracy: 0.8485 - op_conv_accuracy: 0.8951 - avg_accuracy: 0.8878\n",
      "Epoch 00034: val_avg_accuracy did not improve from 0.88196\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 1.3185 - op_main_loss: 0.3534 - op_conv_loss: 0.2555 - avg_loss: 0.2871 - op_main_accuracy: 0.8483 - op_conv_accuracy: 0.8951 - avg_accuracy: 0.8880 - val_loss: 1.3020 - val_op_main_loss: 0.3344 - val_op_conv_loss: 0.2632 - val_avg_loss: 0.2842 - val_op_main_accuracy: 0.8602 - val_op_conv_accuracy: 0.8839 - val_avg_accuracy: 0.8820\n",
      "Epoch 35/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 1.3044 - op_main_loss: 0.3468 - op_conv_loss: 0.2550 - avg_loss: 0.2840 - op_main_accuracy: 0.8549 - op_conv_accuracy: 0.9000 - avg_accuracy: 0.8932\n",
      "Epoch 00035: val_avg_accuracy did not improve from 0.88196\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 1.3045 - op_main_loss: 0.3475 - op_conv_loss: 0.2542 - avg_loss: 0.2841 - op_main_accuracy: 0.8544 - op_conv_accuracy: 0.9003 - avg_accuracy: 0.8937 - val_loss: 1.3061 - val_op_main_loss: 0.3308 - val_op_conv_loss: 0.2716 - val_avg_loss: 0.2861 - val_op_main_accuracy: 0.8602 - val_op_conv_accuracy: 0.8763 - val_avg_accuracy: 0.8772\n",
      "Epoch 36/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 1.3033 - op_main_loss: 0.3463 - op_conv_loss: 0.2564 - avg_loss: 0.2841 - op_main_accuracy: 0.8587 - op_conv_accuracy: 0.9003 - avg_accuracy: 0.8984\n",
      "Epoch 00036: val_avg_accuracy did not improve from 0.88196\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 1.3033 - op_main_loss: 0.3463 - op_conv_loss: 0.2564 - avg_loss: 0.2841 - op_main_accuracy: 0.8587 - op_conv_accuracy: 0.9003 - avg_accuracy: 0.8984 - val_loss: 1.3458 - val_op_main_loss: 0.3384 - val_op_conv_loss: 0.2943 - val_avg_loss: 0.2986 - val_op_main_accuracy: 0.8480 - val_op_conv_accuracy: 0.8810 - val_avg_accuracy: 0.8772\n",
      "Epoch 37/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 1.2864 - op_main_loss: 0.3454 - op_conv_loss: 0.2483 - avg_loss: 0.2796 - op_main_accuracy: 0.8587 - op_conv_accuracy: 0.9038 - avg_accuracy: 0.8962\n",
      "Epoch 00037: val_avg_accuracy did not improve from 0.88196\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 1.2857 - op_main_loss: 0.3457 - op_conv_loss: 0.2476 - avg_loss: 0.2793 - op_main_accuracy: 0.8580 - op_conv_accuracy: 0.9043 - avg_accuracy: 0.8967 - val_loss: 1.2718 - val_op_main_loss: 0.3247 - val_op_conv_loss: 0.2575 - val_avg_loss: 0.2775 - val_op_main_accuracy: 0.8650 - val_op_conv_accuracy: 0.8857 - val_avg_accuracy: 0.8820\n",
      "Epoch 38/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 1.2629 - op_main_loss: 0.3352 - op_conv_loss: 0.2437 - avg_loss: 0.2724 - op_main_accuracy: 0.8658 - op_conv_accuracy: 0.8995 - avg_accuracy: 0.9041\n",
      "Epoch 00038: val_avg_accuracy did not improve from 0.88196\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 1.2682 - op_main_loss: 0.3371 - op_conv_loss: 0.2453 - avg_loss: 0.2742 - op_main_accuracy: 0.8639 - op_conv_accuracy: 0.8986 - avg_accuracy: 0.9031 - val_loss: 1.3293 - val_op_main_loss: 0.3257 - val_op_conv_loss: 0.3004 - val_avg_loss: 0.2924 - val_op_main_accuracy: 0.8621 - val_op_conv_accuracy: 0.8725 - val_avg_accuracy: 0.8820\n",
      "Epoch 39/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 1.2771 - op_main_loss: 0.3387 - op_conv_loss: 0.2513 - avg_loss: 0.2774 - op_main_accuracy: 0.8575 - op_conv_accuracy: 0.9013 - avg_accuracy: 0.8989\n",
      "Epoch 00039: val_avg_accuracy did not improve from 0.88196\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 1.2775 - op_main_loss: 0.3387 - op_conv_loss: 0.2515 - avg_loss: 0.2775 - op_main_accuracy: 0.8575 - op_conv_accuracy: 0.9012 - avg_accuracy: 0.8989 - val_loss: 1.3190 - val_op_main_loss: 0.3241 - val_op_conv_loss: 0.2969 - val_avg_loss: 0.2893 - val_op_main_accuracy: 0.8631 - val_op_conv_accuracy: 0.8782 - val_avg_accuracy: 0.8763\n",
      "Epoch 40/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 1.2487 - op_main_loss: 0.3337 - op_conv_loss: 0.2383 - avg_loss: 0.2692 - op_main_accuracy: 0.8661 - op_conv_accuracy: 0.9055 - avg_accuracy: 0.9055\n",
      "Epoch 00040: val_avg_accuracy improved from 0.88196 to 0.88480, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 1.2453 - op_main_loss: 0.3327 - op_conv_loss: 0.2368 - avg_loss: 0.2681 - op_main_accuracy: 0.8670 - op_conv_accuracy: 0.9062 - avg_accuracy: 0.9064 - val_loss: 1.2601 - val_op_main_loss: 0.3188 - val_op_conv_loss: 0.2607 - val_avg_loss: 0.2738 - val_op_main_accuracy: 0.8621 - val_op_conv_accuracy: 0.8857 - val_avg_accuracy: 0.8848\n",
      "Epoch 41/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 1.2524 - op_main_loss: 0.3376 - op_conv_loss: 0.2384 - avg_loss: 0.2711 - op_main_accuracy: 0.8600 - op_conv_accuracy: 0.9027 - avg_accuracy: 0.8989\n",
      "Epoch 00041: val_avg_accuracy did not improve from 0.88480\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 1.2563 - op_main_loss: 0.3383 - op_conv_loss: 0.2404 - avg_loss: 0.2723 - op_main_accuracy: 0.8594 - op_conv_accuracy: 0.9017 - avg_accuracy: 0.8982 - val_loss: 1.2581 - val_op_main_loss: 0.3190 - val_op_conv_loss: 0.2616 - val_avg_loss: 0.2734 - val_op_main_accuracy: 0.8706 - val_op_conv_accuracy: 0.8801 - val_avg_accuracy: 0.8801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 1.2467 - op_main_loss: 0.3332 - op_conv_loss: 0.2413 - avg_loss: 0.2690 - op_main_accuracy: 0.8614 - op_conv_accuracy: 0.9060 - avg_accuracy: 0.9046\n",
      "Epoch 00042: val_avg_accuracy did not improve from 0.88480\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 1.2511 - op_main_loss: 0.3343 - op_conv_loss: 0.2432 - avg_loss: 0.2704 - op_main_accuracy: 0.8601 - op_conv_accuracy: 0.9050 - avg_accuracy: 0.9036 - val_loss: 1.2577 - val_op_main_loss: 0.3158 - val_op_conv_loss: 0.2686 - val_avg_loss: 0.2714 - val_op_main_accuracy: 0.8697 - val_op_conv_accuracy: 0.8820 - val_avg_accuracy: 0.8839\n",
      "Epoch 43/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 1.2224 - op_main_loss: 0.3280 - op_conv_loss: 0.2300 - avg_loss: 0.2632 - op_main_accuracy: 0.8672 - op_conv_accuracy: 0.9119 - avg_accuracy: 0.9100\n",
      "Epoch 00043: val_avg_accuracy did not improve from 0.88480\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 1.2230 - op_main_loss: 0.3282 - op_conv_loss: 0.2302 - avg_loss: 0.2635 - op_main_accuracy: 0.8672 - op_conv_accuracy: 0.9116 - avg_accuracy: 0.9100 - val_loss: 1.2846 - val_op_main_loss: 0.3195 - val_op_conv_loss: 0.2819 - val_avg_loss: 0.2827 - val_op_main_accuracy: 0.8593 - val_op_conv_accuracy: 0.8801 - val_avg_accuracy: 0.8782\n",
      "Epoch 44/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 1.2235 - op_main_loss: 0.3266 - op_conv_loss: 0.2331 - avg_loss: 0.2639 - op_main_accuracy: 0.8695 - op_conv_accuracy: 0.9086 - avg_accuracy: 0.9055\n",
      "Epoch 00044: val_avg_accuracy did not improve from 0.88480\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 1.2242 - op_main_loss: 0.3270 - op_conv_loss: 0.2332 - avg_loss: 0.2642 - op_main_accuracy: 0.8693 - op_conv_accuracy: 0.9083 - avg_accuracy: 0.9057 - val_loss: 1.3391 - val_op_main_loss: 0.3330 - val_op_conv_loss: 0.3080 - val_avg_loss: 0.2990 - val_op_main_accuracy: 0.8470 - val_op_conv_accuracy: 0.8772 - val_avg_accuracy: 0.8763\n",
      "Epoch 45/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 1.2040 - op_main_loss: 0.3191 - op_conv_loss: 0.2285 - avg_loss: 0.2585 - op_main_accuracy: 0.8709 - op_conv_accuracy: 0.9072 - avg_accuracy: 0.9002\n",
      "Epoch 00045: val_avg_accuracy improved from 0.88480 to 0.88763, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 1.2040 - op_main_loss: 0.3198 - op_conv_loss: 0.2279 - avg_loss: 0.2585 - op_main_accuracy: 0.8707 - op_conv_accuracy: 0.9074 - avg_accuracy: 0.9005 - val_loss: 1.2206 - val_op_main_loss: 0.3133 - val_op_conv_loss: 0.2446 - val_avg_loss: 0.2659 - val_op_main_accuracy: 0.8735 - val_op_conv_accuracy: 0.8895 - val_avg_accuracy: 0.8876\n",
      "Epoch 46/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 1.1835 - op_main_loss: 0.3156 - op_conv_loss: 0.2194 - avg_loss: 0.2517 - op_main_accuracy: 0.8757 - op_conv_accuracy: 0.9130 - avg_accuracy: 0.9113\n",
      "Epoch 00046: val_avg_accuracy improved from 0.88763 to 0.88857, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 1.1826 - op_main_loss: 0.3153 - op_conv_loss: 0.2189 - avg_loss: 0.2515 - op_main_accuracy: 0.8759 - op_conv_accuracy: 0.9130 - avg_accuracy: 0.9112 - val_loss: 1.2182 - val_op_main_loss: 0.3078 - val_op_conv_loss: 0.2499 - val_avg_loss: 0.2643 - val_op_main_accuracy: 0.8697 - val_op_conv_accuracy: 0.8971 - val_avg_accuracy: 0.8886\n",
      "Epoch 47/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 1.1939 - op_main_loss: 0.3168 - op_conv_loss: 0.2257 - avg_loss: 0.2561 - op_main_accuracy: 0.8704 - op_conv_accuracy: 0.9115 - avg_accuracy: 0.9084\n",
      "Epoch 00047: val_avg_accuracy did not improve from 0.88857\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 1.1948 - op_main_loss: 0.3171 - op_conv_loss: 0.2259 - avg_loss: 0.2564 - op_main_accuracy: 0.8698 - op_conv_accuracy: 0.9109 - avg_accuracy: 0.9081 - val_loss: 1.2367 - val_op_main_loss: 0.3110 - val_op_conv_loss: 0.2605 - val_avg_loss: 0.2701 - val_op_main_accuracy: 0.8650 - val_op_conv_accuracy: 0.8886 - val_avg_accuracy: 0.8829\n",
      "Epoch 48/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 1.1673 - op_main_loss: 0.3104 - op_conv_loss: 0.2159 - avg_loss: 0.2471 - op_main_accuracy: 0.8736 - op_conv_accuracy: 0.9177 - avg_accuracy: 0.9139\n",
      "Epoch 00048: val_avg_accuracy improved from 0.88857 to 0.89141, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 1.1693 - op_main_loss: 0.3111 - op_conv_loss: 0.2165 - avg_loss: 0.2478 - op_main_accuracy: 0.8733 - op_conv_accuracy: 0.9175 - avg_accuracy: 0.9138 - val_loss: 1.2132 - val_op_main_loss: 0.3053 - val_op_conv_loss: 0.2508 - val_avg_loss: 0.2636 - val_op_main_accuracy: 0.8706 - val_op_conv_accuracy: 0.8895 - val_avg_accuracy: 0.8914\n",
      "Epoch 49/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 1.1713 - op_main_loss: 0.3133 - op_conv_loss: 0.2160 - avg_loss: 0.2491 - op_main_accuracy: 0.8816 - op_conv_accuracy: 0.9167 - avg_accuracy: 0.9129\n",
      "Epoch 00049: val_avg_accuracy did not improve from 0.89141\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 1.1709 - op_main_loss: 0.3131 - op_conv_loss: 0.2160 - avg_loss: 0.2490 - op_main_accuracy: 0.8816 - op_conv_accuracy: 0.9168 - avg_accuracy: 0.9130 - val_loss: 1.2520 - val_op_main_loss: 0.3095 - val_op_conv_loss: 0.2758 - val_avg_loss: 0.2752 - val_op_main_accuracy: 0.8640 - val_op_conv_accuracy: 0.8829 - val_avg_accuracy: 0.8839\n",
      "Epoch 50/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 1.1456 - op_main_loss: 0.3055 - op_conv_loss: 0.2083 - avg_loss: 0.2409 - op_main_accuracy: 0.8767 - op_conv_accuracy: 0.9215 - avg_accuracy: 0.9191\n",
      "Epoch 00050: val_avg_accuracy improved from 0.89141 to 0.89424, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 1.1474 - op_main_loss: 0.3060 - op_conv_loss: 0.2090 - avg_loss: 0.2416 - op_main_accuracy: 0.8762 - op_conv_accuracy: 0.9213 - avg_accuracy: 0.9190 - val_loss: 1.1881 - val_op_main_loss: 0.3005 - val_op_conv_loss: 0.2410 - val_avg_loss: 0.2565 - val_op_main_accuracy: 0.8772 - val_op_conv_accuracy: 0.8971 - val_avg_accuracy: 0.8942\n",
      "Epoch 51/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 1.1427 - op_main_loss: 0.3025 - op_conv_loss: 0.2097 - avg_loss: 0.2407 - op_main_accuracy: 0.8817 - op_conv_accuracy: 0.9182 - avg_accuracy: 0.9203\n",
      "Epoch 00051: val_avg_accuracy did not improve from 0.89424\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 1.1440 - op_main_loss: 0.3023 - op_conv_loss: 0.2110 - avg_loss: 0.2410 - op_main_accuracy: 0.8816 - op_conv_accuracy: 0.9173 - avg_accuracy: 0.9199 - val_loss: 1.2796 - val_op_main_loss: 0.3088 - val_op_conv_loss: 0.2999 - val_avg_loss: 0.2821 - val_op_main_accuracy: 0.8631 - val_op_conv_accuracy: 0.8791 - val_avg_accuracy: 0.8810\n",
      "Epoch 52/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 1.1576 - op_main_loss: 0.3090 - op_conv_loss: 0.2161 - avg_loss: 0.2442 - op_main_accuracy: 0.8793 - op_conv_accuracy: 0.9171 - avg_accuracy: 0.9167\n",
      "Epoch 00052: val_avg_accuracy did not improve from 0.89424\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 1.1569 - op_main_loss: 0.3088 - op_conv_loss: 0.2159 - avg_loss: 0.2440 - op_main_accuracy: 0.8795 - op_conv_accuracy: 0.9173 - avg_accuracy: 0.9168 - val_loss: 1.1841 - val_op_main_loss: 0.2997 - val_op_conv_loss: 0.2410 - val_avg_loss: 0.2561 - val_op_main_accuracy: 0.8772 - val_op_conv_accuracy: 0.8942 - val_avg_accuracy: 0.8876\n",
      "Epoch 53/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 1.1327 - op_main_loss: 0.3007 - op_conv_loss: 0.2054 - avg_loss: 0.2398 - op_main_accuracy: 0.8898 - op_conv_accuracy: 0.9164 - avg_accuracy: 0.9179\n",
      "Epoch 00053: val_avg_accuracy did not improve from 0.89424\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 1.1373 - op_main_loss: 0.3022 - op_conv_loss: 0.2071 - avg_loss: 0.2412 - op_main_accuracy: 0.8887 - op_conv_accuracy: 0.9154 - avg_accuracy: 0.9166 - val_loss: 1.2690 - val_op_main_loss: 0.3197 - val_op_conv_loss: 0.2798 - val_avg_loss: 0.2829 - val_op_main_accuracy: 0.8555 - val_op_conv_accuracy: 0.8895 - val_avg_accuracy: 0.8848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 1.1449 - op_main_loss: 0.3026 - op_conv_loss: 0.2136 - avg_loss: 0.2433 - op_main_accuracy: 0.8764 - op_conv_accuracy: 0.9144 - avg_accuracy: 0.9144\n",
      "Epoch 00054: val_avg_accuracy did not improve from 0.89424\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 1.1437 - op_main_loss: 0.3021 - op_conv_loss: 0.2133 - avg_loss: 0.2429 - op_main_accuracy: 0.8771 - op_conv_accuracy: 0.9145 - avg_accuracy: 0.9147 - val_loss: 1.2857 - val_op_main_loss: 0.3058 - val_op_conv_loss: 0.3104 - val_avg_loss: 0.2844 - val_op_main_accuracy: 0.8593 - val_op_conv_accuracy: 0.8716 - val_avg_accuracy: 0.8763\n",
      "Epoch 55/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 1.1278 - op_main_loss: 0.2959 - op_conv_loss: 0.2098 - avg_loss: 0.2373 - op_main_accuracy: 0.8826 - op_conv_accuracy: 0.9167 - avg_accuracy: 0.9169\n",
      "Epoch 00055: val_avg_accuracy did not improve from 0.89424\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 1.1280 - op_main_loss: 0.2962 - op_conv_loss: 0.2097 - avg_loss: 0.2374 - op_main_accuracy: 0.8823 - op_conv_accuracy: 0.9168 - avg_accuracy: 0.9168 - val_loss: 1.1967 - val_op_main_loss: 0.2973 - val_op_conv_loss: 0.2546 - val_avg_loss: 0.2609 - val_op_main_accuracy: 0.8791 - val_op_conv_accuracy: 0.8924 - val_avg_accuracy: 0.8895\n",
      "Epoch 56/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 1.1110 - op_main_loss: 0.2927 - op_conv_loss: 0.2031 - avg_loss: 0.2320 - op_main_accuracy: 0.8866 - op_conv_accuracy: 0.9197 - avg_accuracy: 0.9205\n",
      "Epoch 00056: val_avg_accuracy did not improve from 0.89424\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 1.1103 - op_main_loss: 0.2925 - op_conv_loss: 0.2029 - avg_loss: 0.2318 - op_main_accuracy: 0.8866 - op_conv_accuracy: 0.9199 - avg_accuracy: 0.9206 - val_loss: 1.2514 - val_op_main_loss: 0.3181 - val_op_conv_loss: 0.2716 - val_avg_loss: 0.2792 - val_op_main_accuracy: 0.8574 - val_op_conv_accuracy: 0.8905 - val_avg_accuracy: 0.8829\n",
      "Epoch 57/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 1.1089 - op_main_loss: 0.2933 - op_conv_loss: 0.2005 - avg_loss: 0.2328 - op_main_accuracy: 0.8841 - op_conv_accuracy: 0.9206 - avg_accuracy: 0.9182\n",
      "Epoch 00057: val_avg_accuracy did not improve from 0.89424\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 1.1103 - op_main_loss: 0.2931 - op_conv_loss: 0.2017 - avg_loss: 0.2332 - op_main_accuracy: 0.8842 - op_conv_accuracy: 0.9204 - avg_accuracy: 0.9180 - val_loss: 1.1866 - val_op_main_loss: 0.3034 - val_op_conv_loss: 0.2437 - val_avg_loss: 0.2576 - val_op_main_accuracy: 0.8659 - val_op_conv_accuracy: 0.8942 - val_avg_accuracy: 0.8876\n",
      "Epoch 58/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 1.1095 - op_main_loss: 0.2903 - op_conv_loss: 0.2046 - avg_loss: 0.2335 - op_main_accuracy: 0.8859 - op_conv_accuracy: 0.9202 - avg_accuracy: 0.9219\n",
      "Epoch 00058: val_avg_accuracy did not improve from 0.89424\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 1.1086 - op_main_loss: 0.2899 - op_conv_loss: 0.2043 - avg_loss: 0.2332 - op_main_accuracy: 0.8861 - op_conv_accuracy: 0.9204 - avg_accuracy: 0.9220 - val_loss: 1.2773 - val_op_main_loss: 0.3005 - val_op_conv_loss: 0.3146 - val_avg_loss: 0.2822 - val_op_main_accuracy: 0.8669 - val_op_conv_accuracy: 0.8744 - val_avg_accuracy: 0.8791\n",
      "Epoch 59/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 1.0953 - op_main_loss: 0.2896 - op_conv_loss: 0.1974 - avg_loss: 0.2289 - op_main_accuracy: 0.8892 - op_conv_accuracy: 0.9261 - avg_accuracy: 0.9212\n",
      "Epoch 00059: val_avg_accuracy did not improve from 0.89424\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 1.0944 - op_main_loss: 0.2893 - op_conv_loss: 0.1971 - avg_loss: 0.2286 - op_main_accuracy: 0.8894 - op_conv_accuracy: 0.9263 - avg_accuracy: 0.9213 - val_loss: 1.2733 - val_op_main_loss: 0.3092 - val_op_conv_loss: 0.3024 - val_avg_loss: 0.2827 - val_op_main_accuracy: 0.8621 - val_op_conv_accuracy: 0.8820 - val_avg_accuracy: 0.8810\n",
      "Epoch 60/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 1.1068 - op_main_loss: 0.2910 - op_conv_loss: 0.2050 - avg_loss: 0.2319 - op_main_accuracy: 0.8842 - op_conv_accuracy: 0.9186 - avg_accuracy: 0.9167\n",
      "Epoch 00060: val_avg_accuracy did not improve from 0.89424\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 1.1065 - op_main_loss: 0.2909 - op_conv_loss: 0.2048 - avg_loss: 0.2318 - op_main_accuracy: 0.8845 - op_conv_accuracy: 0.9187 - avg_accuracy: 0.9168 - val_loss: 1.2761 - val_op_main_loss: 0.2914 - val_op_conv_loss: 0.3304 - val_avg_loss: 0.2755 - val_op_main_accuracy: 0.8791 - val_op_conv_accuracy: 0.8782 - val_avg_accuracy: 0.8820\n",
      "Epoch 61/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 1.0860 - op_main_loss: 0.2818 - op_conv_loss: 0.1994 - avg_loss: 0.2257 - op_main_accuracy: 0.8937 - op_conv_accuracy: 0.9230 - avg_accuracy: 0.9216\n",
      "Epoch 00061: val_avg_accuracy did not improve from 0.89424\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 1.0860 - op_main_loss: 0.2818 - op_conv_loss: 0.1994 - avg_loss: 0.2257 - op_main_accuracy: 0.8937 - op_conv_accuracy: 0.9230 - avg_accuracy: 0.9216 - val_loss: 1.2560 - val_op_main_loss: 0.2909 - val_op_conv_loss: 0.3138 - val_avg_loss: 0.2726 - val_op_main_accuracy: 0.8744 - val_op_conv_accuracy: 0.8763 - val_avg_accuracy: 0.8829\n",
      "Epoch 62/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 1.0675 - op_main_loss: 0.2766 - op_conv_loss: 0.1920 - avg_loss: 0.2209 - op_main_accuracy: 0.8978 - op_conv_accuracy: 0.9254 - avg_accuracy: 0.9237\n",
      "Epoch 00062: val_avg_accuracy did not improve from 0.89424\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 1.0712 - op_main_loss: 0.2776 - op_conv_loss: 0.1935 - avg_loss: 0.2221 - op_main_accuracy: 0.8977 - op_conv_accuracy: 0.9253 - avg_accuracy: 0.9237 - val_loss: 1.2791 - val_op_main_loss: 0.2891 - val_op_conv_loss: 0.3348 - val_avg_loss: 0.2781 - val_op_main_accuracy: 0.8782 - val_op_conv_accuracy: 0.8678 - val_avg_accuracy: 0.8801\n",
      "Epoch 63/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 1.0791 - op_main_loss: 0.2784 - op_conv_loss: 0.1990 - avg_loss: 0.2245 - op_main_accuracy: 0.8918 - op_conv_accuracy: 0.9208 - avg_accuracy: 0.9239\n",
      "Epoch 00063: val_avg_accuracy did not improve from 0.89424\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 1.0791 - op_main_loss: 0.2784 - op_conv_loss: 0.1990 - avg_loss: 0.2245 - op_main_accuracy: 0.8918 - op_conv_accuracy: 0.9208 - avg_accuracy: 0.9239 - val_loss: 1.2003 - val_op_main_loss: 0.2940 - val_op_conv_loss: 0.2649 - val_avg_loss: 0.2643 - val_op_main_accuracy: 0.8687 - val_op_conv_accuracy: 0.8905 - val_avg_accuracy: 0.8857\n",
      "Epoch 64/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 1.0828 - op_main_loss: 0.2849 - op_conv_loss: 0.1950 - avg_loss: 0.2261 - op_main_accuracy: 0.8852 - op_conv_accuracy: 0.9206 - avg_accuracy: 0.9175\n",
      "Epoch 00064: val_avg_accuracy did not improve from 0.89424\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 1.0828 - op_main_loss: 0.2849 - op_conv_loss: 0.1950 - avg_loss: 0.2261 - op_main_accuracy: 0.8852 - op_conv_accuracy: 0.9206 - avg_accuracy: 0.9175 - val_loss: 1.2177 - val_op_main_loss: 0.3048 - val_op_conv_loss: 0.2724 - val_avg_loss: 0.2651 - val_op_main_accuracy: 0.8801 - val_op_conv_accuracy: 0.8952 - val_avg_accuracy: 0.8886\n",
      "Epoch 65/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 1.0632 - op_main_loss: 0.2786 - op_conv_loss: 0.1886 - avg_loss: 0.2205 - op_main_accuracy: 0.8899 - op_conv_accuracy: 0.9266 - avg_accuracy: 0.9219\n",
      "Epoch 00065: val_avg_accuracy did not improve from 0.89424\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 1.0630 - op_main_loss: 0.2786 - op_conv_loss: 0.1885 - avg_loss: 0.2204 - op_main_accuracy: 0.8899 - op_conv_accuracy: 0.9265 - avg_accuracy: 0.9218 - val_loss: 1.3298 - val_op_main_loss: 0.2848 - val_op_conv_loss: 0.3860 - val_avg_loss: 0.2835 - val_op_main_accuracy: 0.8839 - val_op_conv_accuracy: 0.8329 - val_avg_accuracy: 0.8791\n",
      "Epoch 66/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/133 [============================>.] - ETA: 0s - loss: 1.0601 - op_main_loss: 0.2747 - op_conv_loss: 0.1910 - avg_loss: 0.2188 - op_main_accuracy: 0.8913 - op_conv_accuracy: 0.9257 - avg_accuracy: 0.9223\n",
      "Epoch 00066: val_avg_accuracy did not improve from 0.89424\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 1.0612 - op_main_loss: 0.2751 - op_conv_loss: 0.1914 - avg_loss: 0.2191 - op_main_accuracy: 0.8908 - op_conv_accuracy: 0.9251 - avg_accuracy: 0.9218 - val_loss: 1.1843 - val_op_main_loss: 0.2937 - val_op_conv_loss: 0.2556 - val_avg_loss: 0.2601 - val_op_main_accuracy: 0.8820 - val_op_conv_accuracy: 0.8933 - val_avg_accuracy: 0.8886\n",
      "Epoch 67/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 1.0445 - op_main_loss: 0.2722 - op_conv_loss: 0.1832 - avg_loss: 0.2144 - op_main_accuracy: 0.8978 - op_conv_accuracy: 0.9300 - avg_accuracy: 0.9290\n",
      "Epoch 00067: val_avg_accuracy did not improve from 0.89424\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 1.0445 - op_main_loss: 0.2722 - op_conv_loss: 0.1832 - avg_loss: 0.2144 - op_main_accuracy: 0.8972 - op_conv_accuracy: 0.9296 - avg_accuracy: 0.9284 - val_loss: 1.1481 - val_op_main_loss: 0.2825 - val_op_conv_loss: 0.2429 - val_avg_loss: 0.2487 - val_op_main_accuracy: 0.8857 - val_op_conv_accuracy: 0.8914 - val_avg_accuracy: 0.8924\n",
      "Epoch 68/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 1.0251 - op_main_loss: 0.2667 - op_conv_loss: 0.1755 - avg_loss: 0.2088 - op_main_accuracy: 0.8969 - op_conv_accuracy: 0.9318 - avg_accuracy: 0.9294\n",
      "Epoch 00068: val_avg_accuracy did not improve from 0.89424\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 1.0236 - op_main_loss: 0.2661 - op_conv_loss: 0.1750 - avg_loss: 0.2083 - op_main_accuracy: 0.8974 - op_conv_accuracy: 0.9319 - avg_accuracy: 0.9296 - val_loss: 1.1807 - val_op_main_loss: 0.2812 - val_op_conv_loss: 0.2728 - val_avg_loss: 0.2527 - val_op_main_accuracy: 0.8848 - val_op_conv_accuracy: 0.8895 - val_avg_accuracy: 0.8933\n",
      "Epoch 69/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 1.0469 - op_main_loss: 0.2682 - op_conv_loss: 0.1904 - avg_loss: 0.2149 - op_main_accuracy: 0.8954 - op_conv_accuracy: 0.9255 - avg_accuracy: 0.9240\n",
      "Epoch 00069: val_avg_accuracy did not improve from 0.89424\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 1.0463 - op_main_loss: 0.2678 - op_conv_loss: 0.1905 - avg_loss: 0.2146 - op_main_accuracy: 0.8953 - op_conv_accuracy: 0.9258 - avg_accuracy: 0.9244 - val_loss: 1.1463 - val_op_main_loss: 0.2813 - val_op_conv_loss: 0.2449 - val_avg_loss: 0.2475 - val_op_main_accuracy: 0.8867 - val_op_conv_accuracy: 0.8971 - val_avg_accuracy: 0.8914\n",
      "Epoch 70/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 1.0377 - op_main_loss: 0.2684 - op_conv_loss: 0.1846 - avg_loss: 0.2124 - op_main_accuracy: 0.8977 - op_conv_accuracy: 0.9290 - avg_accuracy: 0.9280\n",
      "Epoch 00070: val_avg_accuracy did not improve from 0.89424\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 1.0393 - op_main_loss: 0.2690 - op_conv_loss: 0.1851 - avg_loss: 0.2130 - op_main_accuracy: 0.8974 - op_conv_accuracy: 0.9289 - avg_accuracy: 0.9279 - val_loss: 1.2122 - val_op_main_loss: 0.2791 - val_op_conv_loss: 0.3009 - val_avg_loss: 0.2611 - val_op_main_accuracy: 0.8905 - val_op_conv_accuracy: 0.8820 - val_avg_accuracy: 0.8933\n",
      "Epoch 71/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 1.0332 - op_main_loss: 0.2663 - op_conv_loss: 0.1831 - avg_loss: 0.2129 - op_main_accuracy: 0.9051 - op_conv_accuracy: 0.9299 - avg_accuracy: 0.9309\n",
      "Epoch 00071: val_avg_accuracy improved from 0.89424 to 0.89707, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 3s 19ms/step - loss: 1.0328 - op_main_loss: 0.2662 - op_conv_loss: 0.1829 - avg_loss: 0.2128 - op_main_accuracy: 0.9050 - op_conv_accuracy: 0.9301 - avg_accuracy: 0.9310 - val_loss: 1.1794 - val_op_main_loss: 0.2880 - val_op_conv_loss: 0.2624 - val_avg_loss: 0.2582 - val_op_main_accuracy: 0.8735 - val_op_conv_accuracy: 0.8952 - val_avg_accuracy: 0.8971\n",
      "Epoch 72/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 1.0401 - op_main_loss: 0.2707 - op_conv_loss: 0.1851 - avg_loss: 0.2138 - op_main_accuracy: 0.8970 - op_conv_accuracy: 0.9322 - avg_accuracy: 0.9296\n",
      "Epoch 00072: val_avg_accuracy did not improve from 0.89707\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 1.0401 - op_main_loss: 0.2707 - op_conv_loss: 0.1851 - avg_loss: 0.2138 - op_main_accuracy: 0.8970 - op_conv_accuracy: 0.9322 - avg_accuracy: 0.9296 - val_loss: 1.2032 - val_op_main_loss: 0.2790 - val_op_conv_loss: 0.2932 - val_avg_loss: 0.2608 - val_op_main_accuracy: 0.8839 - val_op_conv_accuracy: 0.8810 - val_avg_accuracy: 0.8876\n",
      "Epoch 73/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 1.0546 - op_main_loss: 0.2743 - op_conv_loss: 0.1922 - avg_loss: 0.2187 - op_main_accuracy: 0.8974 - op_conv_accuracy: 0.9239 - avg_accuracy: 0.9223\n",
      "Epoch 00073: val_avg_accuracy did not improve from 0.89707\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 1.0546 - op_main_loss: 0.2743 - op_conv_loss: 0.1922 - avg_loss: 0.2187 - op_main_accuracy: 0.8974 - op_conv_accuracy: 0.9239 - avg_accuracy: 0.9223 - val_loss: 1.4405 - val_op_main_loss: 0.2820 - val_op_conv_loss: 0.4784 - val_avg_loss: 0.3116 - val_op_main_accuracy: 0.8801 - val_op_conv_accuracy: 0.8263 - val_avg_accuracy: 0.8640\n",
      "Epoch 74/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 1.0229 - op_main_loss: 0.2649 - op_conv_loss: 0.1797 - avg_loss: 0.2102 - op_main_accuracy: 0.9008 - op_conv_accuracy: 0.9303 - avg_accuracy: 0.9284\n",
      "Epoch 00074: val_avg_accuracy did not improve from 0.89707\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 1.0229 - op_main_loss: 0.2649 - op_conv_loss: 0.1797 - avg_loss: 0.2102 - op_main_accuracy: 0.9008 - op_conv_accuracy: 0.9303 - avg_accuracy: 0.9284 - val_loss: 1.1579 - val_op_main_loss: 0.2923 - val_op_conv_loss: 0.2427 - val_avg_loss: 0.2552 - val_op_main_accuracy: 0.8706 - val_op_conv_accuracy: 0.8933 - val_avg_accuracy: 0.8867\n",
      "Epoch 75/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 1.0365 - op_main_loss: 0.2691 - op_conv_loss: 0.1858 - avg_loss: 0.2139 - op_main_accuracy: 0.9012 - op_conv_accuracy: 0.9241 - avg_accuracy: 0.9241\n",
      "Epoch 00075: val_avg_accuracy did not improve from 0.89707\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 1.0365 - op_main_loss: 0.2691 - op_conv_loss: 0.1858 - avg_loss: 0.2139 - op_main_accuracy: 0.9012 - op_conv_accuracy: 0.9241 - avg_accuracy: 0.9241 - val_loss: 1.1183 - val_op_main_loss: 0.2783 - val_op_conv_loss: 0.2339 - val_avg_loss: 0.2389 - val_op_main_accuracy: 0.8857 - val_op_conv_accuracy: 0.8990 - val_avg_accuracy: 0.8971\n",
      "Epoch 76/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 1.0155 - op_main_loss: 0.2646 - op_conv_loss: 0.1764 - avg_loss: 0.2074 - op_main_accuracy: 0.8977 - op_conv_accuracy: 0.9279 - avg_accuracy: 0.9286\n",
      "Epoch 00076: val_avg_accuracy did not improve from 0.89707\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 1.0155 - op_main_loss: 0.2646 - op_conv_loss: 0.1764 - avg_loss: 0.2074 - op_main_accuracy: 0.8977 - op_conv_accuracy: 0.9279 - avg_accuracy: 0.9286 - val_loss: 1.1956 - val_op_main_loss: 0.2857 - val_op_conv_loss: 0.2811 - val_avg_loss: 0.2618 - val_op_main_accuracy: 0.8772 - val_op_conv_accuracy: 0.8895 - val_avg_accuracy: 0.8839\n",
      "Epoch 77/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.9879 - op_main_loss: 0.2537 - op_conv_loss: 0.1681 - avg_loss: 0.1986 - op_main_accuracy: 0.9058 - op_conv_accuracy: 0.9337 - avg_accuracy: 0.9327\n",
      "Epoch 00077: val_avg_accuracy did not improve from 0.89707\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 0.9934 - op_main_loss: 0.2552 - op_conv_loss: 0.1703 - avg_loss: 0.2004 - op_main_accuracy: 0.9055 - op_conv_accuracy: 0.9331 - avg_accuracy: 0.9319 - val_loss: 1.1452 - val_op_main_loss: 0.2808 - val_op_conv_loss: 0.2475 - val_avg_loss: 0.2497 - val_op_main_accuracy: 0.8867 - val_op_conv_accuracy: 0.8999 - val_avg_accuracy: 0.8933\n",
      "Epoch 78/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/133 [============================>.] - ETA: 0s - loss: 1.0351 - op_main_loss: 0.2659 - op_conv_loss: 0.1896 - avg_loss: 0.2126 - op_main_accuracy: 0.8963 - op_conv_accuracy: 0.9254 - avg_accuracy: 0.9231\n",
      "Epoch 00078: val_avg_accuracy did not improve from 0.89707\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 1.0348 - op_main_loss: 0.2657 - op_conv_loss: 0.1896 - avg_loss: 0.2125 - op_main_accuracy: 0.8965 - op_conv_accuracy: 0.9256 - avg_accuracy: 0.9232 - val_loss: 1.2294 - val_op_main_loss: 0.3039 - val_op_conv_loss: 0.2821 - val_avg_loss: 0.2775 - val_op_main_accuracy: 0.8640 - val_op_conv_accuracy: 0.8876 - val_avg_accuracy: 0.8810\n",
      "Epoch 79/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9956 - op_main_loss: 0.2535 - op_conv_loss: 0.1747 - avg_loss: 0.2016 - op_main_accuracy: 0.9088 - op_conv_accuracy: 0.9301 - avg_accuracy: 0.9303\n",
      "Epoch 00079: val_avg_accuracy did not improve from 0.89707\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.9956 - op_main_loss: 0.2535 - op_conv_loss: 0.1747 - avg_loss: 0.2016 - op_main_accuracy: 0.9088 - op_conv_accuracy: 0.9301 - avg_accuracy: 0.9303 - val_loss: 1.1365 - val_op_main_loss: 0.2728 - val_op_conv_loss: 0.2532 - val_avg_loss: 0.2441 - val_op_main_accuracy: 0.8829 - val_op_conv_accuracy: 0.8980 - val_avg_accuracy: 0.8971\n",
      "Epoch 80/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9995 - op_main_loss: 0.2602 - op_conv_loss: 0.1703 - avg_loss: 0.2018 - op_main_accuracy: 0.9048 - op_conv_accuracy: 0.9341 - avg_accuracy: 0.9341\n",
      "Epoch 00080: val_avg_accuracy did not improve from 0.89707\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.9995 - op_main_loss: 0.2602 - op_conv_loss: 0.1703 - avg_loss: 0.2018 - op_main_accuracy: 0.9048 - op_conv_accuracy: 0.9341 - avg_accuracy: 0.9341 - val_loss: 1.1380 - val_op_main_loss: 0.2767 - val_op_conv_loss: 0.2474 - val_avg_loss: 0.2468 - val_op_main_accuracy: 0.8791 - val_op_conv_accuracy: 0.8924 - val_avg_accuracy: 0.8952\n",
      "Epoch 81/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9855 - op_main_loss: 0.2492 - op_conv_loss: 0.1718 - avg_loss: 0.1985 - op_main_accuracy: 0.9086 - op_conv_accuracy: 0.9331 - avg_accuracy: 0.9322\n",
      "Epoch 00081: val_avg_accuracy improved from 0.89707 to 0.90179, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 3s 19ms/step - loss: 0.9855 - op_main_loss: 0.2492 - op_conv_loss: 0.1718 - avg_loss: 0.1985 - op_main_accuracy: 0.9086 - op_conv_accuracy: 0.9331 - avg_accuracy: 0.9322 - val_loss: 1.1351 - val_op_main_loss: 0.2725 - val_op_conv_loss: 0.2514 - val_avg_loss: 0.2457 - val_op_main_accuracy: 0.8820 - val_op_conv_accuracy: 0.9008 - val_avg_accuracy: 0.9018\n",
      "Epoch 82/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9729 - op_main_loss: 0.2479 - op_conv_loss: 0.1660 - avg_loss: 0.1938 - op_main_accuracy: 0.9083 - op_conv_accuracy: 0.9310 - avg_accuracy: 0.9345\n",
      "Epoch 00082: val_avg_accuracy did not improve from 0.90179\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.9729 - op_main_loss: 0.2479 - op_conv_loss: 0.1660 - avg_loss: 0.1938 - op_main_accuracy: 0.9083 - op_conv_accuracy: 0.9310 - avg_accuracy: 0.9345 - val_loss: 1.1806 - val_op_main_loss: 0.2754 - val_op_conv_loss: 0.2855 - val_avg_loss: 0.2548 - val_op_main_accuracy: 0.8876 - val_op_conv_accuracy: 0.8933 - val_avg_accuracy: 0.8952\n",
      "Epoch 83/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9896 - op_main_loss: 0.2558 - op_conv_loss: 0.1696 - avg_loss: 0.1999 - op_main_accuracy: 0.9062 - op_conv_accuracy: 0.9298 - avg_accuracy: 0.9275\n",
      "Epoch 00083: val_avg_accuracy did not improve from 0.90179\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 0.9896 - op_main_loss: 0.2558 - op_conv_loss: 0.1696 - avg_loss: 0.1999 - op_main_accuracy: 0.9062 - op_conv_accuracy: 0.9298 - avg_accuracy: 0.9275 - val_loss: 1.2223 - val_op_main_loss: 0.2762 - val_op_conv_loss: 0.3182 - val_avg_loss: 0.2640 - val_op_main_accuracy: 0.8848 - val_op_conv_accuracy: 0.8867 - val_avg_accuracy: 0.8914\n",
      "Epoch 84/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9857 - op_main_loss: 0.2513 - op_conv_loss: 0.1718 - avg_loss: 0.1989 - op_main_accuracy: 0.9069 - op_conv_accuracy: 0.9331 - avg_accuracy: 0.9324\n",
      "Epoch 00084: val_avg_accuracy did not improve from 0.90179\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.9857 - op_main_loss: 0.2513 - op_conv_loss: 0.1718 - avg_loss: 0.1989 - op_main_accuracy: 0.9069 - op_conv_accuracy: 0.9331 - avg_accuracy: 0.9324 - val_loss: 1.1988 - val_op_main_loss: 0.2963 - val_op_conv_loss: 0.2797 - val_avg_loss: 0.2593 - val_op_main_accuracy: 0.8735 - val_op_conv_accuracy: 0.8980 - val_avg_accuracy: 0.8990\n",
      "Epoch 85/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9917 - op_main_loss: 0.2555 - op_conv_loss: 0.1724 - avg_loss: 0.2011 - op_main_accuracy: 0.9019 - op_conv_accuracy: 0.9319 - avg_accuracy: 0.9282\n",
      "Epoch 00085: val_avg_accuracy did not improve from 0.90179\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.9917 - op_main_loss: 0.2555 - op_conv_loss: 0.1724 - avg_loss: 0.2011 - op_main_accuracy: 0.9019 - op_conv_accuracy: 0.9319 - avg_accuracy: 0.9282 - val_loss: 1.6024 - val_op_main_loss: 0.3344 - val_op_conv_loss: 0.5337 - val_avg_loss: 0.3718 - val_op_main_accuracy: 0.8546 - val_op_conv_accuracy: 0.8263 - val_avg_accuracy: 0.8423\n",
      "Epoch 86/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9567 - op_main_loss: 0.2443 - op_conv_loss: 0.1597 - avg_loss: 0.1900 - op_main_accuracy: 0.9074 - op_conv_accuracy: 0.9371 - avg_accuracy: 0.9379\n",
      "Epoch 00086: val_avg_accuracy did not improve from 0.90179\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.9567 - op_main_loss: 0.2443 - op_conv_loss: 0.1597 - avg_loss: 0.1900 - op_main_accuracy: 0.9074 - op_conv_accuracy: 0.9371 - avg_accuracy: 0.9379 - val_loss: 1.2944 - val_op_main_loss: 0.3142 - val_op_conv_loss: 0.3210 - val_avg_loss: 0.2962 - val_op_main_accuracy: 0.8697 - val_op_conv_accuracy: 0.8839 - val_avg_accuracy: 0.8857\n",
      "Epoch 87/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9870 - op_main_loss: 0.2538 - op_conv_loss: 0.1718 - avg_loss: 0.1996 - op_main_accuracy: 0.9012 - op_conv_accuracy: 0.9350 - avg_accuracy: 0.9289\n",
      "Epoch 00087: val_avg_accuracy did not improve from 0.90179\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.9870 - op_main_loss: 0.2538 - op_conv_loss: 0.1718 - avg_loss: 0.1996 - op_main_accuracy: 0.9012 - op_conv_accuracy: 0.9350 - avg_accuracy: 0.9289 - val_loss: 1.3111 - val_op_main_loss: 0.2850 - val_op_conv_loss: 0.3758 - val_avg_loss: 0.2894 - val_op_main_accuracy: 0.8735 - val_op_conv_accuracy: 0.8631 - val_avg_accuracy: 0.8763\n",
      "Epoch 88/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9725 - op_main_loss: 0.2468 - op_conv_loss: 0.1689 - avg_loss: 0.1963 - op_main_accuracy: 0.9114 - op_conv_accuracy: 0.9353 - avg_accuracy: 0.9327\n",
      "Epoch 00088: val_avg_accuracy did not improve from 0.90179\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.9725 - op_main_loss: 0.2468 - op_conv_loss: 0.1689 - avg_loss: 0.1963 - op_main_accuracy: 0.9114 - op_conv_accuracy: 0.9353 - avg_accuracy: 0.9327 - val_loss: 1.1525 - val_op_main_loss: 0.2744 - val_op_conv_loss: 0.2693 - val_avg_loss: 0.2487 - val_op_main_accuracy: 0.8829 - val_op_conv_accuracy: 0.8990 - val_avg_accuracy: 0.8961\n",
      "Epoch 89/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9773 - op_main_loss: 0.2462 - op_conv_loss: 0.1733 - avg_loss: 0.1977 - op_main_accuracy: 0.9121 - op_conv_accuracy: 0.9312 - avg_accuracy: 0.9298\n",
      "Epoch 00089: val_avg_accuracy did not improve from 0.90179\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.9773 - op_main_loss: 0.2462 - op_conv_loss: 0.1733 - avg_loss: 0.1977 - op_main_accuracy: 0.9121 - op_conv_accuracy: 0.9312 - avg_accuracy: 0.9298 - val_loss: 1.1290 - val_op_main_loss: 0.2712 - val_op_conv_loss: 0.2537 - val_avg_loss: 0.2448 - val_op_main_accuracy: 0.8810 - val_op_conv_accuracy: 0.9008 - val_avg_accuracy: 0.8971\n",
      "Epoch 90/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - ETA: 0s - loss: 0.9454 - op_main_loss: 0.2400 - op_conv_loss: 0.1587 - avg_loss: 0.1876 - op_main_accuracy: 0.9102 - op_conv_accuracy: 0.9379 - avg_accuracy: 0.9357\n",
      "Epoch 00090: val_avg_accuracy did not improve from 0.90179\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.9454 - op_main_loss: 0.2400 - op_conv_loss: 0.1587 - avg_loss: 0.1876 - op_main_accuracy: 0.9102 - op_conv_accuracy: 0.9379 - avg_accuracy: 0.9357 - val_loss: 1.1700 - val_op_main_loss: 0.2664 - val_op_conv_loss: 0.2925 - val_avg_loss: 0.2526 - val_op_main_accuracy: 0.8848 - val_op_conv_accuracy: 0.8876 - val_avg_accuracy: 0.8886\n",
      "Epoch 91/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9313 - op_main_loss: 0.2368 - op_conv_loss: 0.1520 - avg_loss: 0.1837 - op_main_accuracy: 0.9116 - op_conv_accuracy: 0.9419 - avg_accuracy: 0.9376\n",
      "Epoch 00091: val_avg_accuracy did not improve from 0.90179\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.9313 - op_main_loss: 0.2368 - op_conv_loss: 0.1520 - avg_loss: 0.1837 - op_main_accuracy: 0.9116 - op_conv_accuracy: 0.9419 - avg_accuracy: 0.9376 - val_loss: 1.1473 - val_op_main_loss: 0.2734 - val_op_conv_loss: 0.2664 - val_avg_loss: 0.2491 - val_op_main_accuracy: 0.8820 - val_op_conv_accuracy: 0.8952 - val_avg_accuracy: 0.8933\n",
      "Epoch 92/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9690 - op_main_loss: 0.2444 - op_conv_loss: 0.1713 - avg_loss: 0.1953 - op_main_accuracy: 0.9107 - op_conv_accuracy: 0.9319 - avg_accuracy: 0.9329\n",
      "Epoch 00092: val_avg_accuracy did not improve from 0.90179\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.9690 - op_main_loss: 0.2444 - op_conv_loss: 0.1713 - avg_loss: 0.1953 - op_main_accuracy: 0.9107 - op_conv_accuracy: 0.9319 - avg_accuracy: 0.9329 - val_loss: 1.2299 - val_op_main_loss: 0.2792 - val_op_conv_loss: 0.3208 - val_avg_loss: 0.2718 - val_op_main_accuracy: 0.8810 - val_op_conv_accuracy: 0.8848 - val_avg_accuracy: 0.8886\n",
      "Epoch 93/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9381 - op_main_loss: 0.2406 - op_conv_loss: 0.1541 - avg_loss: 0.1853 - op_main_accuracy: 0.9095 - op_conv_accuracy: 0.9438 - avg_accuracy: 0.9371\n",
      "Epoch 00093: val_avg_accuracy did not improve from 0.90179\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 0.9381 - op_main_loss: 0.2406 - op_conv_loss: 0.1541 - avg_loss: 0.1853 - op_main_accuracy: 0.9095 - op_conv_accuracy: 0.9438 - avg_accuracy: 0.9371 - val_loss: 1.3653 - val_op_main_loss: 0.3113 - val_op_conv_loss: 0.3822 - val_avg_loss: 0.3136 - val_op_main_accuracy: 0.8678 - val_op_conv_accuracy: 0.8706 - val_avg_accuracy: 0.8744\n",
      "Epoch 94/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9443 - op_main_loss: 0.2363 - op_conv_loss: 0.1629 - avg_loss: 0.1881 - op_main_accuracy: 0.9152 - op_conv_accuracy: 0.9386 - avg_accuracy: 0.9357\n",
      "Epoch 00094: val_avg_accuracy did not improve from 0.90179\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.9443 - op_main_loss: 0.2363 - op_conv_loss: 0.1629 - avg_loss: 0.1881 - op_main_accuracy: 0.9152 - op_conv_accuracy: 0.9386 - avg_accuracy: 0.9357 - val_loss: 1.1351 - val_op_main_loss: 0.2676 - val_op_conv_loss: 0.2655 - val_avg_loss: 0.2454 - val_op_main_accuracy: 0.8876 - val_op_conv_accuracy: 0.8971 - val_avg_accuracy: 0.8933\n",
      "Epoch 95/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9135 - op_main_loss: 0.2314 - op_conv_loss: 0.1465 - avg_loss: 0.1790 - op_main_accuracy: 0.9178 - op_conv_accuracy: 0.9423 - avg_accuracy: 0.9421\n",
      "Epoch 00095: val_avg_accuracy did not improve from 0.90179\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.9135 - op_main_loss: 0.2314 - op_conv_loss: 0.1465 - avg_loss: 0.1790 - op_main_accuracy: 0.9178 - op_conv_accuracy: 0.9423 - avg_accuracy: 0.9421 - val_loss: 1.1438 - val_op_main_loss: 0.2666 - val_op_conv_loss: 0.2737 - val_avg_loss: 0.2471 - val_op_main_accuracy: 0.8839 - val_op_conv_accuracy: 0.9018 - val_avg_accuracy: 0.8961\n",
      "Epoch 96/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9485 - op_main_loss: 0.2386 - op_conv_loss: 0.1639 - avg_loss: 0.1897 - op_main_accuracy: 0.9121 - op_conv_accuracy: 0.9355 - avg_accuracy: 0.9338\n",
      "Epoch 00096: val_avg_accuracy did not improve from 0.90179\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.9485 - op_main_loss: 0.2386 - op_conv_loss: 0.1639 - avg_loss: 0.1897 - op_main_accuracy: 0.9121 - op_conv_accuracy: 0.9355 - avg_accuracy: 0.9338 - val_loss: 1.3350 - val_op_main_loss: 0.2950 - val_op_conv_loss: 0.3810 - val_avg_loss: 0.3031 - val_op_main_accuracy: 0.8735 - val_op_conv_accuracy: 0.8621 - val_avg_accuracy: 0.8716\n",
      "Epoch 97/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9375 - op_main_loss: 0.2404 - op_conv_loss: 0.1546 - avg_loss: 0.1868 - op_main_accuracy: 0.9050 - op_conv_accuracy: 0.9390 - avg_accuracy: 0.9336\n",
      "Epoch 00097: val_avg_accuracy did not improve from 0.90179\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.9375 - op_main_loss: 0.2404 - op_conv_loss: 0.1546 - avg_loss: 0.1868 - op_main_accuracy: 0.9050 - op_conv_accuracy: 0.9390 - avg_accuracy: 0.9336 - val_loss: 1.1095 - val_op_main_loss: 0.2664 - val_op_conv_loss: 0.2473 - val_avg_loss: 0.2402 - val_op_main_accuracy: 0.8857 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.8999\n",
      "Epoch 98/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9451 - op_main_loss: 0.2424 - op_conv_loss: 0.1584 - avg_loss: 0.1889 - op_main_accuracy: 0.9130 - op_conv_accuracy: 0.9374 - avg_accuracy: 0.9369\n",
      "Epoch 00098: val_avg_accuracy did not improve from 0.90179\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.9451 - op_main_loss: 0.2424 - op_conv_loss: 0.1584 - avg_loss: 0.1889 - op_main_accuracy: 0.9130 - op_conv_accuracy: 0.9374 - avg_accuracy: 0.9369 - val_loss: 1.1218 - val_op_main_loss: 0.2637 - val_op_conv_loss: 0.2596 - val_avg_loss: 0.2428 - val_op_main_accuracy: 0.8857 - val_op_conv_accuracy: 0.8980 - val_avg_accuracy: 0.9008\n",
      "Epoch 99/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9112 - op_main_loss: 0.2258 - op_conv_loss: 0.1518 - avg_loss: 0.1782 - op_main_accuracy: 0.9204 - op_conv_accuracy: 0.9390 - avg_accuracy: 0.9388\n",
      "Epoch 00099: val_avg_accuracy did not improve from 0.90179\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.9112 - op_main_loss: 0.2258 - op_conv_loss: 0.1518 - avg_loss: 0.1782 - op_main_accuracy: 0.9204 - op_conv_accuracy: 0.9390 - avg_accuracy: 0.9388 - val_loss: 1.2266 - val_op_main_loss: 0.2907 - val_op_conv_loss: 0.3048 - val_avg_loss: 0.2759 - val_op_main_accuracy: 0.8744 - val_op_conv_accuracy: 0.8942 - val_avg_accuracy: 0.8942\n",
      "Epoch 100/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9033 - op_main_loss: 0.2275 - op_conv_loss: 0.1456 - avg_loss: 0.1749 - op_main_accuracy: 0.9152 - op_conv_accuracy: 0.9433 - avg_accuracy: 0.9426\n",
      "Epoch 00100: val_avg_accuracy did not improve from 0.90179\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.9033 - op_main_loss: 0.2275 - op_conv_loss: 0.1456 - avg_loss: 0.1749 - op_main_accuracy: 0.9152 - op_conv_accuracy: 0.9433 - avg_accuracy: 0.9426 - val_loss: 1.2067 - val_op_main_loss: 0.2897 - val_op_conv_loss: 0.2924 - val_avg_loss: 0.2698 - val_op_main_accuracy: 0.8791 - val_op_conv_accuracy: 0.8924 - val_avg_accuracy: 0.8857\n",
      "Epoch 101/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9292 - op_main_loss: 0.2374 - op_conv_loss: 0.1544 - avg_loss: 0.1838 - op_main_accuracy: 0.9133 - op_conv_accuracy: 0.9428 - avg_accuracy: 0.9419\n",
      "Epoch 00101: val_avg_accuracy did not improve from 0.90179\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.9292 - op_main_loss: 0.2374 - op_conv_loss: 0.1544 - avg_loss: 0.1838 - op_main_accuracy: 0.9133 - op_conv_accuracy: 0.9428 - avg_accuracy: 0.9419 - val_loss: 1.1045 - val_op_main_loss: 0.2611 - val_op_conv_loss: 0.2511 - val_avg_loss: 0.2398 - val_op_main_accuracy: 0.8839 - val_op_conv_accuracy: 0.8933 - val_avg_accuracy: 0.8961\n",
      "Epoch 102/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - ETA: 0s - loss: 0.9131 - op_main_loss: 0.2325 - op_conv_loss: 0.1492 - avg_loss: 0.1790 - op_main_accuracy: 0.9121 - op_conv_accuracy: 0.9397 - avg_accuracy: 0.9407\n",
      "Epoch 00102: val_avg_accuracy did not improve from 0.90179\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.9131 - op_main_loss: 0.2325 - op_conv_loss: 0.1492 - avg_loss: 0.1790 - op_main_accuracy: 0.9121 - op_conv_accuracy: 0.9397 - avg_accuracy: 0.9407 - val_loss: 1.1204 - val_op_main_loss: 0.2612 - val_op_conv_loss: 0.2635 - val_avg_loss: 0.2429 - val_op_main_accuracy: 0.8895 - val_op_conv_accuracy: 0.8961 - val_avg_accuracy: 0.9008\n",
      "Epoch 103/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9154 - op_main_loss: 0.2284 - op_conv_loss: 0.1540 - avg_loss: 0.1801 - op_main_accuracy: 0.9192 - op_conv_accuracy: 0.9428 - avg_accuracy: 0.9395\n",
      "Epoch 00103: val_avg_accuracy improved from 0.90179 to 0.90368, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 3s 19ms/step - loss: 0.9154 - op_main_loss: 0.2284 - op_conv_loss: 0.1540 - avg_loss: 0.1801 - op_main_accuracy: 0.9192 - op_conv_accuracy: 0.9428 - avg_accuracy: 0.9395 - val_loss: 1.1371 - val_op_main_loss: 0.2605 - val_op_conv_loss: 0.2808 - val_avg_loss: 0.2433 - val_op_main_accuracy: 0.8857 - val_op_conv_accuracy: 0.8999 - val_avg_accuracy: 0.9037\n",
      "Epoch 104/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9058 - op_main_loss: 0.2254 - op_conv_loss: 0.1517 - avg_loss: 0.1767 - op_main_accuracy: 0.9178 - op_conv_accuracy: 0.9421 - avg_accuracy: 0.9400\n",
      "Epoch 00104: val_avg_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.9058 - op_main_loss: 0.2254 - op_conv_loss: 0.1517 - avg_loss: 0.1767 - op_main_accuracy: 0.9178 - op_conv_accuracy: 0.9421 - avg_accuracy: 0.9400 - val_loss: 1.1860 - val_op_main_loss: 0.2586 - val_op_conv_loss: 0.3213 - val_avg_loss: 0.2550 - val_op_main_accuracy: 0.8839 - val_op_conv_accuracy: 0.8820 - val_avg_accuracy: 0.8895\n",
      "Epoch 105/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8983 - op_main_loss: 0.2276 - op_conv_loss: 0.1445 - avg_loss: 0.1750 - op_main_accuracy: 0.9180 - op_conv_accuracy: 0.9421 - avg_accuracy: 0.9409\n",
      "Epoch 00105: val_avg_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8983 - op_main_loss: 0.2276 - op_conv_loss: 0.1445 - avg_loss: 0.1750 - op_main_accuracy: 0.9180 - op_conv_accuracy: 0.9421 - avg_accuracy: 0.9409 - val_loss: 1.2173 - val_op_main_loss: 0.2601 - val_op_conv_loss: 0.3452 - val_avg_loss: 0.2612 - val_op_main_accuracy: 0.8829 - val_op_conv_accuracy: 0.8810 - val_avg_accuracy: 0.8905\n",
      "Epoch 106/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8972 - op_main_loss: 0.2230 - op_conv_loss: 0.1483 - avg_loss: 0.1749 - op_main_accuracy: 0.9173 - op_conv_accuracy: 0.9447 - avg_accuracy: 0.9442\n",
      "Epoch 00106: val_avg_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8972 - op_main_loss: 0.2230 - op_conv_loss: 0.1483 - avg_loss: 0.1749 - op_main_accuracy: 0.9173 - op_conv_accuracy: 0.9447 - avg_accuracy: 0.9442 - val_loss: 1.1224 - val_op_main_loss: 0.2615 - val_op_conv_loss: 0.2659 - val_avg_loss: 0.2437 - val_op_main_accuracy: 0.8857 - val_op_conv_accuracy: 0.9018 - val_avg_accuracy: 0.8961\n",
      "Epoch 107/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9258 - op_main_loss: 0.2402 - op_conv_loss: 0.1545 - avg_loss: 0.1821 - op_main_accuracy: 0.9123 - op_conv_accuracy: 0.9397 - avg_accuracy: 0.9416\n",
      "Epoch 00107: val_avg_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.9258 - op_main_loss: 0.2402 - op_conv_loss: 0.1545 - avg_loss: 0.1821 - op_main_accuracy: 0.9123 - op_conv_accuracy: 0.9397 - avg_accuracy: 0.9416 - val_loss: 1.2871 - val_op_main_loss: 0.2717 - val_op_conv_loss: 0.3809 - val_avg_loss: 0.2853 - val_op_main_accuracy: 0.8810 - val_op_conv_accuracy: 0.8612 - val_avg_accuracy: 0.8801\n",
      "Epoch 108/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.9120 - op_main_loss: 0.2325 - op_conv_loss: 0.1508 - avg_loss: 0.1794 - op_main_accuracy: 0.9102 - op_conv_accuracy: 0.9431 - avg_accuracy: 0.9433\n",
      "Epoch 00108: val_avg_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.9120 - op_main_loss: 0.2325 - op_conv_loss: 0.1508 - avg_loss: 0.1794 - op_main_accuracy: 0.9102 - op_conv_accuracy: 0.9431 - avg_accuracy: 0.9433 - val_loss: 1.1646 - val_op_main_loss: 0.2630 - val_op_conv_loss: 0.3048 - val_avg_loss: 0.2474 - val_op_main_accuracy: 0.8848 - val_op_conv_accuracy: 0.8905 - val_avg_accuracy: 0.9027\n",
      "Epoch 109/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8837 - op_main_loss: 0.2209 - op_conv_loss: 0.1418 - avg_loss: 0.1716 - op_main_accuracy: 0.9175 - op_conv_accuracy: 0.9428 - avg_accuracy: 0.9405\n",
      "Epoch 00109: val_avg_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8837 - op_main_loss: 0.2209 - op_conv_loss: 0.1418 - avg_loss: 0.1716 - op_main_accuracy: 0.9175 - op_conv_accuracy: 0.9428 - avg_accuracy: 0.9405 - val_loss: 1.2299 - val_op_main_loss: 0.2807 - val_op_conv_loss: 0.3239 - val_avg_loss: 0.2759 - val_op_main_accuracy: 0.8791 - val_op_conv_accuracy: 0.8895 - val_avg_accuracy: 0.8942\n",
      "Epoch 110/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8907 - op_main_loss: 0.2199 - op_conv_loss: 0.1485 - avg_loss: 0.1733 - op_main_accuracy: 0.9218 - op_conv_accuracy: 0.9438 - avg_accuracy: 0.9412\n",
      "Epoch 00110: val_avg_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8907 - op_main_loss: 0.2199 - op_conv_loss: 0.1485 - avg_loss: 0.1733 - op_main_accuracy: 0.9218 - op_conv_accuracy: 0.9438 - avg_accuracy: 0.9412 - val_loss: 1.3865 - val_op_main_loss: 0.2800 - val_op_conv_loss: 0.4518 - val_avg_loss: 0.3062 - val_op_main_accuracy: 0.8810 - val_op_conv_accuracy: 0.8555 - val_avg_accuracy: 0.8716\n",
      "Epoch 111/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.8690 - op_main_loss: 0.2163 - op_conv_loss: 0.1378 - avg_loss: 0.1666 - op_main_accuracy: 0.9209 - op_conv_accuracy: 0.9474 - avg_accuracy: 0.9451\n",
      "Epoch 00111: val_avg_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8696 - op_main_loss: 0.2162 - op_conv_loss: 0.1383 - avg_loss: 0.1668 - op_main_accuracy: 0.9208 - op_conv_accuracy: 0.9473 - avg_accuracy: 0.9449 - val_loss: 1.1474 - val_op_main_loss: 0.2656 - val_op_conv_loss: 0.2824 - val_avg_loss: 0.2510 - val_op_main_accuracy: 0.8857 - val_op_conv_accuracy: 0.9027 - val_avg_accuracy: 0.8990\n",
      "Epoch 112/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8812 - op_main_loss: 0.2191 - op_conv_loss: 0.1430 - avg_loss: 0.1712 - op_main_accuracy: 0.9225 - op_conv_accuracy: 0.9445 - avg_accuracy: 0.9431\n",
      "Epoch 00112: val_avg_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8812 - op_main_loss: 0.2191 - op_conv_loss: 0.1430 - avg_loss: 0.1712 - op_main_accuracy: 0.9225 - op_conv_accuracy: 0.9445 - avg_accuracy: 0.9431 - val_loss: 1.1156 - val_op_main_loss: 0.2560 - val_op_conv_loss: 0.2714 - val_avg_loss: 0.2403 - val_op_main_accuracy: 0.8905 - val_op_conv_accuracy: 0.8990 - val_avg_accuracy: 0.8961\n",
      "Epoch 113/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8764 - op_main_loss: 0.2191 - op_conv_loss: 0.1404 - avg_loss: 0.1692 - op_main_accuracy: 0.9187 - op_conv_accuracy: 0.9442 - avg_accuracy: 0.9416\n",
      "Epoch 00113: val_avg_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8764 - op_main_loss: 0.2191 - op_conv_loss: 0.1404 - avg_loss: 0.1692 - op_main_accuracy: 0.9187 - op_conv_accuracy: 0.9442 - avg_accuracy: 0.9416 - val_loss: 1.4733 - val_op_main_loss: 0.2805 - val_op_conv_loss: 0.5228 - val_avg_loss: 0.3228 - val_op_main_accuracy: 0.8754 - val_op_conv_accuracy: 0.8366 - val_avg_accuracy: 0.8669\n",
      "Epoch 114/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - ETA: 0s - loss: 0.8771 - op_main_loss: 0.2219 - op_conv_loss: 0.1387 - avg_loss: 0.1701 - op_main_accuracy: 0.9171 - op_conv_accuracy: 0.9449 - avg_accuracy: 0.9438\n",
      "Epoch 00114: val_avg_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8771 - op_main_loss: 0.2219 - op_conv_loss: 0.1387 - avg_loss: 0.1701 - op_main_accuracy: 0.9171 - op_conv_accuracy: 0.9449 - avg_accuracy: 0.9438 - val_loss: 1.2747 - val_op_main_loss: 0.2858 - val_op_conv_loss: 0.3533 - val_avg_loss: 0.2888 - val_op_main_accuracy: 0.8772 - val_op_conv_accuracy: 0.8735 - val_avg_accuracy: 0.8839\n",
      "Epoch 115/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8691 - op_main_loss: 0.2173 - op_conv_loss: 0.1384 - avg_loss: 0.1668 - op_main_accuracy: 0.9173 - op_conv_accuracy: 0.9504 - avg_accuracy: 0.9471\n",
      "Epoch 00115: val_avg_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8691 - op_main_loss: 0.2173 - op_conv_loss: 0.1384 - avg_loss: 0.1668 - op_main_accuracy: 0.9173 - op_conv_accuracy: 0.9504 - avg_accuracy: 0.9471 - val_loss: 1.4137 - val_op_main_loss: 0.2812 - val_op_conv_loss: 0.4745 - val_avg_loss: 0.3121 - val_op_main_accuracy: 0.8848 - val_op_conv_accuracy: 0.8385 - val_avg_accuracy: 0.8612\n",
      "Epoch 116/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8716 - op_main_loss: 0.2190 - op_conv_loss: 0.1384 - avg_loss: 0.1688 - op_main_accuracy: 0.9258 - op_conv_accuracy: 0.9447 - avg_accuracy: 0.9480\n",
      "Epoch 00116: val_avg_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8716 - op_main_loss: 0.2190 - op_conv_loss: 0.1384 - avg_loss: 0.1688 - op_main_accuracy: 0.9258 - op_conv_accuracy: 0.9447 - avg_accuracy: 0.9480 - val_loss: 1.1912 - val_op_main_loss: 0.2629 - val_op_conv_loss: 0.3207 - val_avg_loss: 0.2623 - val_op_main_accuracy: 0.8848 - val_op_conv_accuracy: 0.8839 - val_avg_accuracy: 0.8895\n",
      "Epoch 117/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8843 - op_main_loss: 0.2199 - op_conv_loss: 0.1468 - avg_loss: 0.1728 - op_main_accuracy: 0.9173 - op_conv_accuracy: 0.9419 - avg_accuracy: 0.9431\n",
      "Epoch 00117: val_avg_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8843 - op_main_loss: 0.2199 - op_conv_loss: 0.1468 - avg_loss: 0.1728 - op_main_accuracy: 0.9173 - op_conv_accuracy: 0.9419 - avg_accuracy: 0.9431 - val_loss: 1.0875 - val_op_main_loss: 0.2559 - val_op_conv_loss: 0.2511 - val_avg_loss: 0.2361 - val_op_main_accuracy: 0.8905 - val_op_conv_accuracy: 0.8971 - val_avg_accuracy: 0.8980\n",
      "Epoch 118/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.8600 - op_main_loss: 0.2108 - op_conv_loss: 0.1385 - avg_loss: 0.1661 - op_main_accuracy: 0.9233 - op_conv_accuracy: 0.9435 - avg_accuracy: 0.9476\n",
      "Epoch 00118: val_avg_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 19ms/step - loss: 0.8586 - op_main_loss: 0.2106 - op_conv_loss: 0.1377 - avg_loss: 0.1656 - op_main_accuracy: 0.9234 - op_conv_accuracy: 0.9440 - avg_accuracy: 0.9480 - val_loss: 1.1115 - val_op_main_loss: 0.2544 - val_op_conv_loss: 0.2711 - val_avg_loss: 0.2415 - val_op_main_accuracy: 0.8895 - val_op_conv_accuracy: 0.8999 - val_avg_accuracy: 0.9008\n",
      "Epoch 119/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8396 - op_main_loss: 0.2073 - op_conv_loss: 0.1287 - avg_loss: 0.1594 - op_main_accuracy: 0.9296 - op_conv_accuracy: 0.9501 - avg_accuracy: 0.9501\n",
      "Epoch 00119: val_avg_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8396 - op_main_loss: 0.2073 - op_conv_loss: 0.1287 - avg_loss: 0.1594 - op_main_accuracy: 0.9296 - op_conv_accuracy: 0.9501 - avg_accuracy: 0.9501 - val_loss: 1.1998 - val_op_main_loss: 0.2701 - val_op_conv_loss: 0.3194 - val_avg_loss: 0.2660 - val_op_main_accuracy: 0.8839 - val_op_conv_accuracy: 0.8895 - val_avg_accuracy: 0.8933\n",
      "Epoch 120/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.8662 - op_main_loss: 0.2203 - op_conv_loss: 0.1348 - avg_loss: 0.1673 - op_main_accuracy: 0.9212 - op_conv_accuracy: 0.9457 - avg_accuracy: 0.9421\n",
      "Epoch 00120: val_avg_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 0.8636 - op_main_loss: 0.2193 - op_conv_loss: 0.1341 - avg_loss: 0.1665 - op_main_accuracy: 0.9220 - op_conv_accuracy: 0.9459 - avg_accuracy: 0.9426 - val_loss: 1.0688 - val_op_main_loss: 0.2501 - val_op_conv_loss: 0.2457 - val_avg_loss: 0.2298 - val_op_main_accuracy: 0.8914 - val_op_conv_accuracy: 0.9008 - val_avg_accuracy: 0.9037\n",
      "Epoch 121/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8566 - op_main_loss: 0.2139 - op_conv_loss: 0.1349 - avg_loss: 0.1648 - op_main_accuracy: 0.9216 - op_conv_accuracy: 0.9459 - avg_accuracy: 0.9423\n",
      "Epoch 00121: val_avg_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8566 - op_main_loss: 0.2139 - op_conv_loss: 0.1349 - avg_loss: 0.1648 - op_main_accuracy: 0.9216 - op_conv_accuracy: 0.9459 - avg_accuracy: 0.9423 - val_loss: 1.1178 - val_op_main_loss: 0.2601 - val_op_conv_loss: 0.2715 - val_avg_loss: 0.2434 - val_op_main_accuracy: 0.8905 - val_op_conv_accuracy: 0.9093 - val_avg_accuracy: 0.9018\n",
      "Epoch 122/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8671 - op_main_loss: 0.2137 - op_conv_loss: 0.1425 - avg_loss: 0.1684 - op_main_accuracy: 0.9234 - op_conv_accuracy: 0.9428 - avg_accuracy: 0.9400\n",
      "Epoch 00122: val_avg_accuracy improved from 0.90368 to 0.90840, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 19ms/step - loss: 0.8671 - op_main_loss: 0.2137 - op_conv_loss: 0.1425 - avg_loss: 0.1684 - op_main_accuracy: 0.9234 - op_conv_accuracy: 0.9428 - avg_accuracy: 0.9400 - val_loss: 1.0902 - val_op_main_loss: 0.2591 - val_op_conv_loss: 0.2508 - val_avg_loss: 0.2385 - val_op_main_accuracy: 0.8848 - val_op_conv_accuracy: 0.9112 - val_avg_accuracy: 0.9084\n",
      "Epoch 123/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8528 - op_main_loss: 0.2141 - op_conv_loss: 0.1322 - avg_loss: 0.1649 - op_main_accuracy: 0.9213 - op_conv_accuracy: 0.9483 - avg_accuracy: 0.9423\n",
      "Epoch 00123: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 0.8528 - op_main_loss: 0.2141 - op_conv_loss: 0.1322 - avg_loss: 0.1649 - op_main_accuracy: 0.9213 - op_conv_accuracy: 0.9483 - avg_accuracy: 0.9423 - val_loss: 1.1021 - val_op_main_loss: 0.2524 - val_op_conv_loss: 0.2697 - val_avg_loss: 0.2385 - val_op_main_accuracy: 0.8857 - val_op_conv_accuracy: 0.8999 - val_avg_accuracy: 0.9056\n",
      "Epoch 124/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8420 - op_main_loss: 0.2111 - op_conv_loss: 0.1288 - avg_loss: 0.1605 - op_main_accuracy: 0.9265 - op_conv_accuracy: 0.9497 - avg_accuracy: 0.9478\n",
      "Epoch 00124: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 19ms/step - loss: 0.8420 - op_main_loss: 0.2111 - op_conv_loss: 0.1288 - avg_loss: 0.1605 - op_main_accuracy: 0.9265 - op_conv_accuracy: 0.9497 - avg_accuracy: 0.9478 - val_loss: 1.3396 - val_op_main_loss: 0.2681 - val_op_conv_loss: 0.4425 - val_avg_loss: 0.2875 - val_op_main_accuracy: 0.8886 - val_op_conv_accuracy: 0.8612 - val_avg_accuracy: 0.8791\n",
      "Epoch 125/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8522 - op_main_loss: 0.2151 - op_conv_loss: 0.1319 - avg_loss: 0.1645 - op_main_accuracy: 0.9263 - op_conv_accuracy: 0.9487 - avg_accuracy: 0.9452\n",
      "Epoch 00125: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8522 - op_main_loss: 0.2151 - op_conv_loss: 0.1319 - avg_loss: 0.1645 - op_main_accuracy: 0.9263 - op_conv_accuracy: 0.9487 - avg_accuracy: 0.9452 - val_loss: 1.2377 - val_op_main_loss: 0.2672 - val_op_conv_loss: 0.3570 - val_avg_loss: 0.2725 - val_op_main_accuracy: 0.8829 - val_op_conv_accuracy: 0.8801 - val_avg_accuracy: 0.8895\n",
      "Epoch 126/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - ETA: 0s - loss: 0.8243 - op_main_loss: 0.2086 - op_conv_loss: 0.1198 - avg_loss: 0.1549 - op_main_accuracy: 0.9201 - op_conv_accuracy: 0.9539 - avg_accuracy: 0.9501\n",
      "Epoch 00126: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8243 - op_main_loss: 0.2086 - op_conv_loss: 0.1198 - avg_loss: 0.1549 - op_main_accuracy: 0.9201 - op_conv_accuracy: 0.9539 - avg_accuracy: 0.9501 - val_loss: 1.2556 - val_op_main_loss: 0.2670 - val_op_conv_loss: 0.3707 - val_avg_loss: 0.2773 - val_op_main_accuracy: 0.8839 - val_op_conv_accuracy: 0.8754 - val_avg_accuracy: 0.8857\n",
      "Epoch 127/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8508 - op_main_loss: 0.2113 - op_conv_loss: 0.1355 - avg_loss: 0.1638 - op_main_accuracy: 0.9234 - op_conv_accuracy: 0.9454 - avg_accuracy: 0.9464\n",
      "Epoch 00127: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8508 - op_main_loss: 0.2113 - op_conv_loss: 0.1355 - avg_loss: 0.1638 - op_main_accuracy: 0.9234 - op_conv_accuracy: 0.9454 - avg_accuracy: 0.9464 - val_loss: 1.3323 - val_op_main_loss: 0.2667 - val_op_conv_loss: 0.4348 - val_avg_loss: 0.2912 - val_op_main_accuracy: 0.8772 - val_op_conv_accuracy: 0.8584 - val_avg_accuracy: 0.8754\n",
      "Epoch 128/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8392 - op_main_loss: 0.2101 - op_conv_loss: 0.1296 - avg_loss: 0.1595 - op_main_accuracy: 0.9239 - op_conv_accuracy: 0.9487 - avg_accuracy: 0.9454\n",
      "Epoch 00128: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8392 - op_main_loss: 0.2101 - op_conv_loss: 0.1296 - avg_loss: 0.1595 - op_main_accuracy: 0.9239 - op_conv_accuracy: 0.9487 - avg_accuracy: 0.9454 - val_loss: 1.0866 - val_op_main_loss: 0.2501 - val_op_conv_loss: 0.2634 - val_avg_loss: 0.2336 - val_op_main_accuracy: 0.8905 - val_op_conv_accuracy: 0.9103 - val_avg_accuracy: 0.9084\n",
      "Epoch 129/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8513 - op_main_loss: 0.2145 - op_conv_loss: 0.1339 - avg_loss: 0.1638 - op_main_accuracy: 0.9211 - op_conv_accuracy: 0.9445 - avg_accuracy: 0.9452\n",
      "Epoch 00129: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8513 - op_main_loss: 0.2145 - op_conv_loss: 0.1339 - avg_loss: 0.1638 - op_main_accuracy: 0.9211 - op_conv_accuracy: 0.9445 - avg_accuracy: 0.9452 - val_loss: 1.1887 - val_op_main_loss: 0.2761 - val_op_conv_loss: 0.3135 - val_avg_loss: 0.2603 - val_op_main_accuracy: 0.8905 - val_op_conv_accuracy: 0.8999 - val_avg_accuracy: 0.8961\n",
      "Epoch 130/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.8307 - op_main_loss: 0.2084 - op_conv_loss: 0.1256 - avg_loss: 0.1579 - op_main_accuracy: 0.9238 - op_conv_accuracy: 0.9498 - avg_accuracy: 0.9444\n",
      "Epoch 00130: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8302 - op_main_loss: 0.2082 - op_conv_loss: 0.1255 - avg_loss: 0.1578 - op_main_accuracy: 0.9239 - op_conv_accuracy: 0.9499 - avg_accuracy: 0.9445 - val_loss: 1.3858 - val_op_main_loss: 0.3159 - val_op_conv_loss: 0.4059 - val_avg_loss: 0.3255 - val_op_main_accuracy: 0.8678 - val_op_conv_accuracy: 0.8725 - val_avg_accuracy: 0.8772\n",
      "Epoch 131/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8341 - op_main_loss: 0.2100 - op_conv_loss: 0.1266 - avg_loss: 0.1592 - op_main_accuracy: 0.9251 - op_conv_accuracy: 0.9487 - avg_accuracy: 0.9494\n",
      "Epoch 00131: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8341 - op_main_loss: 0.2100 - op_conv_loss: 0.1266 - avg_loss: 0.1592 - op_main_accuracy: 0.9251 - op_conv_accuracy: 0.9487 - avg_accuracy: 0.9494 - val_loss: 1.0981 - val_op_main_loss: 0.2525 - val_op_conv_loss: 0.2711 - val_avg_loss: 0.2369 - val_op_main_accuracy: 0.8905 - val_op_conv_accuracy: 0.8999 - val_avg_accuracy: 0.9027\n",
      "Epoch 132/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8404 - op_main_loss: 0.2114 - op_conv_loss: 0.1304 - avg_loss: 0.1607 - op_main_accuracy: 0.9241 - op_conv_accuracy: 0.9499 - avg_accuracy: 0.9447\n",
      "Epoch 00132: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8404 - op_main_loss: 0.2114 - op_conv_loss: 0.1304 - avg_loss: 0.1607 - op_main_accuracy: 0.9241 - op_conv_accuracy: 0.9499 - avg_accuracy: 0.9447 - val_loss: 1.1121 - val_op_main_loss: 0.2569 - val_op_conv_loss: 0.2746 - val_avg_loss: 0.2426 - val_op_main_accuracy: 0.8839 - val_op_conv_accuracy: 0.9027 - val_avg_accuracy: 0.9037\n",
      "Epoch 133/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8139 - op_main_loss: 0.1982 - op_conv_loss: 0.1249 - avg_loss: 0.1526 - op_main_accuracy: 0.9315 - op_conv_accuracy: 0.9490 - avg_accuracy: 0.9487\n",
      "Epoch 00133: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8139 - op_main_loss: 0.1982 - op_conv_loss: 0.1249 - avg_loss: 0.1526 - op_main_accuracy: 0.9315 - op_conv_accuracy: 0.9490 - avg_accuracy: 0.9487 - val_loss: 1.2613 - val_op_main_loss: 0.2588 - val_op_conv_loss: 0.3910 - val_avg_loss: 0.2739 - val_op_main_accuracy: 0.8876 - val_op_conv_accuracy: 0.8791 - val_avg_accuracy: 0.8895\n",
      "Epoch 134/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.8360 - op_main_loss: 0.2107 - op_conv_loss: 0.1279 - avg_loss: 0.1601 - op_main_accuracy: 0.9221 - op_conv_accuracy: 0.9500 - avg_accuracy: 0.9455\n",
      "Epoch 00134: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 0.8352 - op_main_loss: 0.2104 - op_conv_loss: 0.1277 - avg_loss: 0.1599 - op_main_accuracy: 0.9223 - op_conv_accuracy: 0.9501 - avg_accuracy: 0.9457 - val_loss: 1.2168 - val_op_main_loss: 0.2819 - val_op_conv_loss: 0.3225 - val_avg_loss: 0.2758 - val_op_main_accuracy: 0.8791 - val_op_conv_accuracy: 0.8876 - val_avg_accuracy: 0.8867\n",
      "Epoch 135/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8184 - op_main_loss: 0.2038 - op_conv_loss: 0.1229 - avg_loss: 0.1547 - op_main_accuracy: 0.9284 - op_conv_accuracy: 0.9534 - avg_accuracy: 0.9525\n",
      "Epoch 00135: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8184 - op_main_loss: 0.2038 - op_conv_loss: 0.1229 - avg_loss: 0.1547 - op_main_accuracy: 0.9284 - op_conv_accuracy: 0.9534 - avg_accuracy: 0.9525 - val_loss: 1.3313 - val_op_main_loss: 0.2938 - val_op_conv_loss: 0.3937 - val_avg_loss: 0.3070 - val_op_main_accuracy: 0.8735 - val_op_conv_accuracy: 0.8725 - val_avg_accuracy: 0.8744\n",
      "Epoch 136/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8284 - op_main_loss: 0.2036 - op_conv_loss: 0.1311 - avg_loss: 0.1573 - op_main_accuracy: 0.9267 - op_conv_accuracy: 0.9485 - avg_accuracy: 0.9471\n",
      "Epoch 00136: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8284 - op_main_loss: 0.2036 - op_conv_loss: 0.1311 - avg_loss: 0.1573 - op_main_accuracy: 0.9267 - op_conv_accuracy: 0.9485 - avg_accuracy: 0.9471 - val_loss: 1.0950 - val_op_main_loss: 0.2498 - val_op_conv_loss: 0.2714 - val_avg_loss: 0.2377 - val_op_main_accuracy: 0.8914 - val_op_conv_accuracy: 0.8999 - val_avg_accuracy: 0.8999\n",
      "Epoch 137/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.8175 - op_main_loss: 0.2035 - op_conv_loss: 0.1236 - avg_loss: 0.1547 - op_main_accuracy: 0.9278 - op_conv_accuracy: 0.9538 - avg_accuracy: 0.9482\n",
      "Epoch 00137: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 0.8173 - op_main_loss: 0.2034 - op_conv_loss: 0.1236 - avg_loss: 0.1546 - op_main_accuracy: 0.9279 - op_conv_accuracy: 0.9539 - avg_accuracy: 0.9483 - val_loss: 1.1012 - val_op_main_loss: 0.2492 - val_op_conv_loss: 0.2794 - val_avg_loss: 0.2370 - val_op_main_accuracy: 0.8914 - val_op_conv_accuracy: 0.9027 - val_avg_accuracy: 0.8990\n",
      "Epoch 138/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/133 [============================>.] - ETA: 0s - loss: 0.8083 - op_main_loss: 0.2017 - op_conv_loss: 0.1189 - avg_loss: 0.1520 - op_main_accuracy: 0.9281 - op_conv_accuracy: 0.9502 - avg_accuracy: 0.9483\n",
      "Epoch 00138: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 0.8076 - op_main_loss: 0.2014 - op_conv_loss: 0.1185 - avg_loss: 0.1518 - op_main_accuracy: 0.9289 - op_conv_accuracy: 0.9509 - avg_accuracy: 0.9487 - val_loss: 1.0939 - val_op_main_loss: 0.2476 - val_op_conv_loss: 0.2765 - val_avg_loss: 0.2338 - val_op_main_accuracy: 0.8933 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9027\n",
      "Epoch 139/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7951 - op_main_loss: 0.1966 - op_conv_loss: 0.1161 - avg_loss: 0.1469 - op_main_accuracy: 0.9308 - op_conv_accuracy: 0.9563 - avg_accuracy: 0.9544\n",
      "Epoch 00139: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7951 - op_main_loss: 0.1966 - op_conv_loss: 0.1161 - avg_loss: 0.1469 - op_main_accuracy: 0.9308 - op_conv_accuracy: 0.9563 - avg_accuracy: 0.9544 - val_loss: 1.1445 - val_op_main_loss: 0.2533 - val_op_conv_loss: 0.3072 - val_avg_loss: 0.2490 - val_op_main_accuracy: 0.8905 - val_op_conv_accuracy: 0.8914 - val_avg_accuracy: 0.8999\n",
      "Epoch 140/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7929 - op_main_loss: 0.1954 - op_conv_loss: 0.1152 - avg_loss: 0.1469 - op_main_accuracy: 0.9319 - op_conv_accuracy: 0.9575 - avg_accuracy: 0.9546\n",
      "Epoch 00140: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7929 - op_main_loss: 0.1954 - op_conv_loss: 0.1152 - avg_loss: 0.1469 - op_main_accuracy: 0.9319 - op_conv_accuracy: 0.9575 - avg_accuracy: 0.9546 - val_loss: 1.2478 - val_op_main_loss: 0.3045 - val_op_conv_loss: 0.3191 - val_avg_loss: 0.2897 - val_op_main_accuracy: 0.8754 - val_op_conv_accuracy: 0.8914 - val_avg_accuracy: 0.8857\n",
      "Epoch 141/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8140 - op_main_loss: 0.2033 - op_conv_loss: 0.1222 - avg_loss: 0.1541 - op_main_accuracy: 0.9284 - op_conv_accuracy: 0.9534 - avg_accuracy: 0.9483\n",
      "Epoch 00141: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8140 - op_main_loss: 0.2033 - op_conv_loss: 0.1222 - avg_loss: 0.1541 - op_main_accuracy: 0.9284 - op_conv_accuracy: 0.9534 - avg_accuracy: 0.9483 - val_loss: 1.1505 - val_op_main_loss: 0.2596 - val_op_conv_loss: 0.3081 - val_avg_loss: 0.2480 - val_op_main_accuracy: 0.8867 - val_op_conv_accuracy: 0.8971 - val_avg_accuracy: 0.9008\n",
      "Epoch 142/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.8419 - op_main_loss: 0.2112 - op_conv_loss: 0.1340 - avg_loss: 0.1623 - op_main_accuracy: 0.9195 - op_conv_accuracy: 0.9474 - avg_accuracy: 0.9433\n",
      "Epoch 00142: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 0.8440 - op_main_loss: 0.2120 - op_conv_loss: 0.1346 - avg_loss: 0.1630 - op_main_accuracy: 0.9190 - op_conv_accuracy: 0.9475 - avg_accuracy: 0.9426 - val_loss: 1.2128 - val_op_main_loss: 0.3034 - val_op_conv_loss: 0.3026 - val_avg_loss: 0.2726 - val_op_main_accuracy: 0.8801 - val_op_conv_accuracy: 0.8895 - val_avg_accuracy: 0.8924\n",
      "Epoch 143/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7953 - op_main_loss: 0.1971 - op_conv_loss: 0.1156 - avg_loss: 0.1480 - op_main_accuracy: 0.9303 - op_conv_accuracy: 0.9518 - avg_accuracy: 0.9513\n",
      "Epoch 00143: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7953 - op_main_loss: 0.1971 - op_conv_loss: 0.1156 - avg_loss: 0.1480 - op_main_accuracy: 0.9303 - op_conv_accuracy: 0.9518 - avg_accuracy: 0.9513 - val_loss: 1.2037 - val_op_main_loss: 0.2488 - val_op_conv_loss: 0.3664 - val_avg_loss: 0.2537 - val_op_main_accuracy: 0.8961 - val_op_conv_accuracy: 0.8782 - val_avg_accuracy: 0.9008\n",
      "Epoch 144/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7900 - op_main_loss: 0.1990 - op_conv_loss: 0.1110 - avg_loss: 0.1458 - op_main_accuracy: 0.9258 - op_conv_accuracy: 0.9598 - avg_accuracy: 0.9534\n",
      "Epoch 00144: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7900 - op_main_loss: 0.1990 - op_conv_loss: 0.1110 - avg_loss: 0.1458 - op_main_accuracy: 0.9258 - op_conv_accuracy: 0.9598 - avg_accuracy: 0.9534 - val_loss: 1.1084 - val_op_main_loss: 0.2506 - val_op_conv_loss: 0.2846 - val_avg_loss: 0.2393 - val_op_main_accuracy: 0.8933 - val_op_conv_accuracy: 0.9008 - val_avg_accuracy: 0.8999\n",
      "Epoch 145/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7946 - op_main_loss: 0.1945 - op_conv_loss: 0.1184 - avg_loss: 0.1477 - op_main_accuracy: 0.9348 - op_conv_accuracy: 0.9509 - avg_accuracy: 0.9513\n",
      "Epoch 00145: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7946 - op_main_loss: 0.1945 - op_conv_loss: 0.1184 - avg_loss: 0.1477 - op_main_accuracy: 0.9348 - op_conv_accuracy: 0.9509 - avg_accuracy: 0.9513 - val_loss: 1.1199 - val_op_main_loss: 0.2505 - val_op_conv_loss: 0.2975 - val_avg_loss: 0.2390 - val_op_main_accuracy: 0.8895 - val_op_conv_accuracy: 0.9008 - val_avg_accuracy: 0.9037\n",
      "Epoch 146/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8078 - op_main_loss: 0.2000 - op_conv_loss: 0.1225 - avg_loss: 0.1524 - op_main_accuracy: 0.9279 - op_conv_accuracy: 0.9497 - avg_accuracy: 0.9452\n",
      "Epoch 00146: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.8078 - op_main_loss: 0.2000 - op_conv_loss: 0.1225 - avg_loss: 0.1524 - op_main_accuracy: 0.9279 - op_conv_accuracy: 0.9497 - avg_accuracy: 0.9452 - val_loss: 1.3608 - val_op_main_loss: 0.2556 - val_op_conv_loss: 0.4819 - val_avg_loss: 0.2901 - val_op_main_accuracy: 0.8886 - val_op_conv_accuracy: 0.8508 - val_avg_accuracy: 0.8791\n",
      "Epoch 147/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8203 - op_main_loss: 0.2038 - op_conv_loss: 0.1278 - avg_loss: 0.1555 - op_main_accuracy: 0.9275 - op_conv_accuracy: 0.9534 - avg_accuracy: 0.9487\n",
      "Epoch 00147: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 0.8203 - op_main_loss: 0.2038 - op_conv_loss: 0.1278 - avg_loss: 0.1555 - op_main_accuracy: 0.9275 - op_conv_accuracy: 0.9534 - avg_accuracy: 0.9487 - val_loss: 1.1267 - val_op_main_loss: 0.2681 - val_op_conv_loss: 0.2749 - val_avg_loss: 0.2508 - val_op_main_accuracy: 0.8857 - val_op_conv_accuracy: 0.8980 - val_avg_accuracy: 0.8990\n",
      "Epoch 148/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7942 - op_main_loss: 0.1957 - op_conv_loss: 0.1176 - avg_loss: 0.1478 - op_main_accuracy: 0.9334 - op_conv_accuracy: 0.9520 - avg_accuracy: 0.9530\n",
      "Epoch 00148: val_avg_accuracy did not improve from 0.90840\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7942 - op_main_loss: 0.1957 - op_conv_loss: 0.1176 - avg_loss: 0.1478 - op_main_accuracy: 0.9334 - op_conv_accuracy: 0.9520 - avg_accuracy: 0.9530 - val_loss: 1.2502 - val_op_main_loss: 0.2976 - val_op_conv_loss: 0.3377 - val_avg_loss: 0.2819 - val_op_main_accuracy: 0.8848 - val_op_conv_accuracy: 0.8914 - val_avg_accuracy: 0.8895\n",
      "Epoch 149/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.8014 - op_main_loss: 0.1979 - op_conv_loss: 0.1213 - avg_loss: 0.1497 - op_main_accuracy: 0.9279 - op_conv_accuracy: 0.9539 - avg_accuracy: 0.9518\n",
      "Epoch 00149: val_avg_accuracy improved from 0.90840 to 0.91029, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 19ms/step - loss: 0.8014 - op_main_loss: 0.1979 - op_conv_loss: 0.1213 - avg_loss: 0.1497 - op_main_accuracy: 0.9279 - op_conv_accuracy: 0.9539 - avg_accuracy: 0.9518 - val_loss: 1.0894 - val_op_main_loss: 0.2492 - val_op_conv_loss: 0.2770 - val_avg_loss: 0.2307 - val_op_main_accuracy: 0.8895 - val_op_conv_accuracy: 0.9065 - val_avg_accuracy: 0.9103\n",
      "Epoch 150/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - ETA: 0s - loss: 0.7957 - op_main_loss: 0.1957 - op_conv_loss: 0.1186 - avg_loss: 0.1492 - op_main_accuracy: 0.9312 - op_conv_accuracy: 0.9579 - avg_accuracy: 0.9525\n",
      "Epoch 00150: val_avg_accuracy did not improve from 0.91029\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7957 - op_main_loss: 0.1957 - op_conv_loss: 0.1186 - avg_loss: 0.1492 - op_main_accuracy: 0.9312 - op_conv_accuracy: 0.9579 - avg_accuracy: 0.9525 - val_loss: 1.0905 - val_op_main_loss: 0.2483 - val_op_conv_loss: 0.2786 - val_avg_loss: 0.2319 - val_op_main_accuracy: 0.8895 - val_op_conv_accuracy: 0.9037 - val_avg_accuracy: 0.9065\n",
      "Epoch 151/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7828 - op_main_loss: 0.1948 - op_conv_loss: 0.1118 - avg_loss: 0.1448 - op_main_accuracy: 0.9319 - op_conv_accuracy: 0.9582 - avg_accuracy: 0.9586\n",
      "Epoch 00151: val_avg_accuracy improved from 0.91029 to 0.91124, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 19ms/step - loss: 0.7828 - op_main_loss: 0.1948 - op_conv_loss: 0.1118 - avg_loss: 0.1448 - op_main_accuracy: 0.9319 - op_conv_accuracy: 0.9582 - avg_accuracy: 0.9586 - val_loss: 1.0887 - val_op_main_loss: 0.2474 - val_op_conv_loss: 0.2760 - val_avg_loss: 0.2343 - val_op_main_accuracy: 0.8895 - val_op_conv_accuracy: 0.9084 - val_avg_accuracy: 0.9112\n",
      "Epoch 152/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7963 - op_main_loss: 0.1955 - op_conv_loss: 0.1203 - avg_loss: 0.1494 - op_main_accuracy: 0.9298 - op_conv_accuracy: 0.9520 - avg_accuracy: 0.9475\n",
      "Epoch 00152: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7963 - op_main_loss: 0.1955 - op_conv_loss: 0.1203 - avg_loss: 0.1494 - op_main_accuracy: 0.9298 - op_conv_accuracy: 0.9520 - avg_accuracy: 0.9475 - val_loss: 1.1501 - val_op_main_loss: 0.2541 - val_op_conv_loss: 0.3162 - val_avg_loss: 0.2486 - val_op_main_accuracy: 0.8924 - val_op_conv_accuracy: 0.9008 - val_avg_accuracy: 0.8971\n",
      "Epoch 153/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7714 - op_main_loss: 0.1903 - op_conv_loss: 0.1087 - avg_loss: 0.1414 - op_main_accuracy: 0.9329 - op_conv_accuracy: 0.9572 - avg_accuracy: 0.9518\n",
      "Epoch 00153: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7714 - op_main_loss: 0.1903 - op_conv_loss: 0.1087 - avg_loss: 0.1414 - op_main_accuracy: 0.9329 - op_conv_accuracy: 0.9572 - avg_accuracy: 0.9518 - val_loss: 1.0972 - val_op_main_loss: 0.2549 - val_op_conv_loss: 0.2728 - val_avg_loss: 0.2390 - val_op_main_accuracy: 0.8857 - val_op_conv_accuracy: 0.9037 - val_avg_accuracy: 0.9027\n",
      "Epoch 154/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7782 - op_main_loss: 0.1941 - op_conv_loss: 0.1107 - avg_loss: 0.1428 - op_main_accuracy: 0.9293 - op_conv_accuracy: 0.9553 - avg_accuracy: 0.9544\n",
      "Epoch 00154: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7782 - op_main_loss: 0.1941 - op_conv_loss: 0.1107 - avg_loss: 0.1428 - op_main_accuracy: 0.9293 - op_conv_accuracy: 0.9553 - avg_accuracy: 0.9544 - val_loss: 1.2129 - val_op_main_loss: 0.2636 - val_op_conv_loss: 0.3498 - val_avg_loss: 0.2692 - val_op_main_accuracy: 0.8857 - val_op_conv_accuracy: 0.8933 - val_avg_accuracy: 0.8942\n",
      "Epoch 155/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7748 - op_main_loss: 0.1870 - op_conv_loss: 0.1155 - avg_loss: 0.1424 - op_main_accuracy: 0.9348 - op_conv_accuracy: 0.9546 - avg_accuracy: 0.9530\n",
      "Epoch 00155: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7748 - op_main_loss: 0.1870 - op_conv_loss: 0.1155 - avg_loss: 0.1424 - op_main_accuracy: 0.9348 - op_conv_accuracy: 0.9546 - avg_accuracy: 0.9530 - val_loss: 1.0903 - val_op_main_loss: 0.2466 - val_op_conv_loss: 0.2782 - val_avg_loss: 0.2363 - val_op_main_accuracy: 0.8905 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9008\n",
      "Epoch 156/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.7577 - op_main_loss: 0.1858 - op_conv_loss: 0.1053 - avg_loss: 0.1377 - op_main_accuracy: 0.9384 - op_conv_accuracy: 0.9590 - avg_accuracy: 0.9576\n",
      "Epoch 00156: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7569 - op_main_loss: 0.1855 - op_conv_loss: 0.1051 - avg_loss: 0.1374 - op_main_accuracy: 0.9386 - op_conv_accuracy: 0.9591 - avg_accuracy: 0.9577 - val_loss: 1.1115 - val_op_main_loss: 0.2560 - val_op_conv_loss: 0.2871 - val_avg_loss: 0.2393 - val_op_main_accuracy: 0.8886 - val_op_conv_accuracy: 0.9103 - val_avg_accuracy: 0.9056\n",
      "Epoch 157/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7670 - op_main_loss: 0.1902 - op_conv_loss: 0.1076 - avg_loss: 0.1405 - op_main_accuracy: 0.9364 - op_conv_accuracy: 0.9584 - avg_accuracy: 0.9577\n",
      "Epoch 00157: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7670 - op_main_loss: 0.1902 - op_conv_loss: 0.1076 - avg_loss: 0.1405 - op_main_accuracy: 0.9364 - op_conv_accuracy: 0.9584 - avg_accuracy: 0.9577 - val_loss: 1.1172 - val_op_main_loss: 0.2517 - val_op_conv_loss: 0.2945 - val_avg_loss: 0.2428 - val_op_main_accuracy: 0.8961 - val_op_conv_accuracy: 0.8990 - val_avg_accuracy: 0.8990\n",
      "Epoch 158/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7924 - op_main_loss: 0.2022 - op_conv_loss: 0.1147 - avg_loss: 0.1471 - op_main_accuracy: 0.9237 - op_conv_accuracy: 0.9568 - avg_accuracy: 0.9492\n",
      "Epoch 00158: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7924 - op_main_loss: 0.2022 - op_conv_loss: 0.1147 - avg_loss: 0.1471 - op_main_accuracy: 0.9237 - op_conv_accuracy: 0.9568 - avg_accuracy: 0.9492 - val_loss: 1.2381 - val_op_main_loss: 0.2512 - val_op_conv_loss: 0.3938 - val_avg_loss: 0.2642 - val_op_main_accuracy: 0.8886 - val_op_conv_accuracy: 0.8801 - val_avg_accuracy: 0.8905\n",
      "Epoch 159/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7608 - op_main_loss: 0.1884 - op_conv_loss: 0.1053 - avg_loss: 0.1385 - op_main_accuracy: 0.9317 - op_conv_accuracy: 0.9582 - avg_accuracy: 0.9568\n",
      "Epoch 00159: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7608 - op_main_loss: 0.1884 - op_conv_loss: 0.1053 - avg_loss: 0.1385 - op_main_accuracy: 0.9317 - op_conv_accuracy: 0.9582 - avg_accuracy: 0.9568 - val_loss: 1.4885 - val_op_main_loss: 0.2865 - val_op_conv_loss: 0.5448 - val_avg_loss: 0.3287 - val_op_main_accuracy: 0.8810 - val_op_conv_accuracy: 0.8489 - val_avg_accuracy: 0.8640\n",
      "Epoch 160/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.7830 - op_main_loss: 0.1878 - op_conv_loss: 0.1212 - avg_loss: 0.1454 - op_main_accuracy: 0.9358 - op_conv_accuracy: 0.9507 - avg_accuracy: 0.9502\n",
      "Epoch 00160: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 0.7820 - op_main_loss: 0.1877 - op_conv_loss: 0.1207 - avg_loss: 0.1451 - op_main_accuracy: 0.9357 - op_conv_accuracy: 0.9509 - avg_accuracy: 0.9501 - val_loss: 1.1119 - val_op_main_loss: 0.2528 - val_op_conv_loss: 0.2882 - val_avg_loss: 0.2428 - val_op_main_accuracy: 0.8895 - val_op_conv_accuracy: 0.9008 - val_avg_accuracy: 0.9037\n",
      "Epoch 161/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7657 - op_main_loss: 0.1859 - op_conv_loss: 0.1114 - avg_loss: 0.1403 - op_main_accuracy: 0.9341 - op_conv_accuracy: 0.9546 - avg_accuracy: 0.9542\n",
      "Epoch 00161: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7657 - op_main_loss: 0.1859 - op_conv_loss: 0.1114 - avg_loss: 0.1403 - op_main_accuracy: 0.9341 - op_conv_accuracy: 0.9546 - avg_accuracy: 0.9542 - val_loss: 1.2079 - val_op_main_loss: 0.2462 - val_op_conv_loss: 0.3806 - val_avg_loss: 0.2534 - val_op_main_accuracy: 0.8952 - val_op_conv_accuracy: 0.8697 - val_avg_accuracy: 0.8980\n",
      "Epoch 162/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - ETA: 0s - loss: 0.7619 - op_main_loss: 0.1852 - op_conv_loss: 0.1098 - avg_loss: 0.1395 - op_main_accuracy: 0.9374 - op_conv_accuracy: 0.9589 - avg_accuracy: 0.9586\n",
      "Epoch 00162: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7619 - op_main_loss: 0.1852 - op_conv_loss: 0.1098 - avg_loss: 0.1395 - op_main_accuracy: 0.9374 - op_conv_accuracy: 0.9589 - avg_accuracy: 0.9586 - val_loss: 1.1117 - val_op_main_loss: 0.2606 - val_op_conv_loss: 0.2787 - val_avg_loss: 0.2459 - val_op_main_accuracy: 0.8857 - val_op_conv_accuracy: 0.9008 - val_avg_accuracy: 0.8980\n",
      "Epoch 163/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7605 - op_main_loss: 0.1891 - op_conv_loss: 0.1059 - avg_loss: 0.1389 - op_main_accuracy: 0.9350 - op_conv_accuracy: 0.9603 - avg_accuracy: 0.9565\n",
      "Epoch 00163: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7605 - op_main_loss: 0.1891 - op_conv_loss: 0.1059 - avg_loss: 0.1389 - op_main_accuracy: 0.9350 - op_conv_accuracy: 0.9603 - avg_accuracy: 0.9565 - val_loss: 1.3044 - val_op_main_loss: 0.2842 - val_op_conv_loss: 0.4060 - val_avg_loss: 0.2882 - val_op_main_accuracy: 0.8867 - val_op_conv_accuracy: 0.8857 - val_avg_accuracy: 0.8876\n",
      "Epoch 164/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.7695 - op_main_loss: 0.1915 - op_conv_loss: 0.1095 - avg_loss: 0.1422 - op_main_accuracy: 0.9315 - op_conv_accuracy: 0.9568 - avg_accuracy: 0.9547\n",
      "Epoch 00164: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 0.7713 - op_main_loss: 0.1922 - op_conv_loss: 0.1100 - avg_loss: 0.1428 - op_main_accuracy: 0.9310 - op_conv_accuracy: 0.9565 - avg_accuracy: 0.9542 - val_loss: 1.1654 - val_op_main_loss: 0.2616 - val_op_conv_loss: 0.3174 - val_avg_loss: 0.2596 - val_op_main_accuracy: 0.8895 - val_op_conv_accuracy: 0.8971 - val_avg_accuracy: 0.8942\n",
      "Epoch 165/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7916 - op_main_loss: 0.1954 - op_conv_loss: 0.1206 - avg_loss: 0.1492 - op_main_accuracy: 0.9331 - op_conv_accuracy: 0.9546 - avg_accuracy: 0.9534\n",
      "Epoch 00165: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7916 - op_main_loss: 0.1954 - op_conv_loss: 0.1206 - avg_loss: 0.1492 - op_main_accuracy: 0.9331 - op_conv_accuracy: 0.9546 - avg_accuracy: 0.9534 - val_loss: 1.1289 - val_op_main_loss: 0.2547 - val_op_conv_loss: 0.2996 - val_avg_loss: 0.2484 - val_op_main_accuracy: 0.8857 - val_op_conv_accuracy: 0.8980 - val_avg_accuracy: 0.8942\n",
      "Epoch 166/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7605 - op_main_loss: 0.1904 - op_conv_loss: 0.1045 - avg_loss: 0.1392 - op_main_accuracy: 0.9336 - op_conv_accuracy: 0.9608 - avg_accuracy: 0.9565\n",
      "Epoch 00166: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7605 - op_main_loss: 0.1904 - op_conv_loss: 0.1045 - avg_loss: 0.1392 - op_main_accuracy: 0.9336 - op_conv_accuracy: 0.9608 - avg_accuracy: 0.9565 - val_loss: 1.0976 - val_op_main_loss: 0.2462 - val_op_conv_loss: 0.2890 - val_avg_loss: 0.2362 - val_op_main_accuracy: 0.8933 - val_op_conv_accuracy: 0.9093 - val_avg_accuracy: 0.9046\n",
      "Epoch 167/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7741 - op_main_loss: 0.1900 - op_conv_loss: 0.1149 - avg_loss: 0.1432 - op_main_accuracy: 0.9324 - op_conv_accuracy: 0.9565 - avg_accuracy: 0.9523\n",
      "Epoch 00167: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7741 - op_main_loss: 0.1900 - op_conv_loss: 0.1149 - avg_loss: 0.1432 - op_main_accuracy: 0.9324 - op_conv_accuracy: 0.9565 - avg_accuracy: 0.9523 - val_loss: 1.1395 - val_op_main_loss: 0.2526 - val_op_conv_loss: 0.3157 - val_avg_loss: 0.2457 - val_op_main_accuracy: 0.8867 - val_op_conv_accuracy: 0.8924 - val_avg_accuracy: 0.8942\n",
      "Epoch 168/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7689 - op_main_loss: 0.1896 - op_conv_loss: 0.1116 - avg_loss: 0.1420 - op_main_accuracy: 0.9329 - op_conv_accuracy: 0.9523 - avg_accuracy: 0.9525\n",
      "Epoch 00168: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7689 - op_main_loss: 0.1896 - op_conv_loss: 0.1116 - avg_loss: 0.1420 - op_main_accuracy: 0.9329 - op_conv_accuracy: 0.9523 - avg_accuracy: 0.9525 - val_loss: 1.1322 - val_op_main_loss: 0.2689 - val_op_conv_loss: 0.2872 - val_avg_loss: 0.2510 - val_op_main_accuracy: 0.8886 - val_op_conv_accuracy: 0.9018 - val_avg_accuracy: 0.8980\n",
      "Epoch 169/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7603 - op_main_loss: 0.1909 - op_conv_loss: 0.1051 - avg_loss: 0.1396 - op_main_accuracy: 0.9341 - op_conv_accuracy: 0.9575 - avg_accuracy: 0.9549\n",
      "Epoch 00169: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7603 - op_main_loss: 0.1909 - op_conv_loss: 0.1051 - avg_loss: 0.1396 - op_main_accuracy: 0.9341 - op_conv_accuracy: 0.9575 - avg_accuracy: 0.9549 - val_loss: 1.1325 - val_op_main_loss: 0.2511 - val_op_conv_loss: 0.3128 - val_avg_loss: 0.2438 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.8942 - val_avg_accuracy: 0.8999\n",
      "Epoch 170/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7596 - op_main_loss: 0.1852 - op_conv_loss: 0.1102 - avg_loss: 0.1396 - op_main_accuracy: 0.9343 - op_conv_accuracy: 0.9516 - avg_accuracy: 0.9539\n",
      "Epoch 00170: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7596 - op_main_loss: 0.1852 - op_conv_loss: 0.1102 - avg_loss: 0.1396 - op_main_accuracy: 0.9343 - op_conv_accuracy: 0.9516 - avg_accuracy: 0.9539 - val_loss: 1.1389 - val_op_main_loss: 0.2440 - val_op_conv_loss: 0.3277 - val_avg_loss: 0.2427 - val_op_main_accuracy: 0.8942 - val_op_conv_accuracy: 0.8895 - val_avg_accuracy: 0.8990\n",
      "Epoch 171/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7451 - op_main_loss: 0.1810 - op_conv_loss: 0.1048 - avg_loss: 0.1347 - op_main_accuracy: 0.9400 - op_conv_accuracy: 0.9577 - avg_accuracy: 0.9577\n",
      "Epoch 00171: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7451 - op_main_loss: 0.1810 - op_conv_loss: 0.1048 - avg_loss: 0.1347 - op_main_accuracy: 0.9400 - op_conv_accuracy: 0.9577 - avg_accuracy: 0.9577 - val_loss: 1.1197 - val_op_main_loss: 0.2490 - val_op_conv_loss: 0.3036 - val_avg_loss: 0.2422 - val_op_main_accuracy: 0.8961 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9018\n",
      "Epoch 172/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7519 - op_main_loss: 0.1829 - op_conv_loss: 0.1076 - avg_loss: 0.1372 - op_main_accuracy: 0.9350 - op_conv_accuracy: 0.9565 - avg_accuracy: 0.9539\n",
      "Epoch 00172: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7519 - op_main_loss: 0.1829 - op_conv_loss: 0.1076 - avg_loss: 0.1372 - op_main_accuracy: 0.9350 - op_conv_accuracy: 0.9565 - avg_accuracy: 0.9539 - val_loss: 1.2811 - val_op_main_loss: 0.2830 - val_op_conv_loss: 0.3812 - val_avg_loss: 0.2931 - val_op_main_accuracy: 0.8782 - val_op_conv_accuracy: 0.8791 - val_avg_accuracy: 0.8801\n",
      "Epoch 173/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7522 - op_main_loss: 0.1863 - op_conv_loss: 0.1051 - avg_loss: 0.1368 - op_main_accuracy: 0.9310 - op_conv_accuracy: 0.9608 - avg_accuracy: 0.9563\n",
      "Epoch 00173: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.7522 - op_main_loss: 0.1863 - op_conv_loss: 0.1051 - avg_loss: 0.1368 - op_main_accuracy: 0.9310 - op_conv_accuracy: 0.9608 - avg_accuracy: 0.9563 - val_loss: 1.0798 - val_op_main_loss: 0.2454 - val_op_conv_loss: 0.2776 - val_avg_loss: 0.2332 - val_op_main_accuracy: 0.8961 - val_op_conv_accuracy: 0.9018 - val_avg_accuracy: 0.9018\n",
      "Epoch 174/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/133 [============================>.] - ETA: 0s - loss: 0.7368 - op_main_loss: 0.1765 - op_conv_loss: 0.1037 - avg_loss: 0.1326 - op_main_accuracy: 0.9358 - op_conv_accuracy: 0.9583 - avg_accuracy: 0.9590\n",
      "Epoch 00174: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7377 - op_main_loss: 0.1767 - op_conv_loss: 0.1042 - avg_loss: 0.1329 - op_main_accuracy: 0.9355 - op_conv_accuracy: 0.9579 - avg_accuracy: 0.9586 - val_loss: 1.1211 - val_op_main_loss: 0.2495 - val_op_conv_loss: 0.3056 - val_avg_loss: 0.2421 - val_op_main_accuracy: 0.8933 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9046\n",
      "Epoch 175/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.7471 - op_main_loss: 0.1843 - op_conv_loss: 0.1028 - avg_loss: 0.1365 - op_main_accuracy: 0.9327 - op_conv_accuracy: 0.9566 - avg_accuracy: 0.9549\n",
      "Epoch 00175: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 0.7496 - op_main_loss: 0.1853 - op_conv_loss: 0.1035 - avg_loss: 0.1373 - op_main_accuracy: 0.9322 - op_conv_accuracy: 0.9563 - avg_accuracy: 0.9544 - val_loss: 1.6885 - val_op_main_loss: 0.3395 - val_op_conv_loss: 0.6322 - val_avg_loss: 0.3933 - val_op_main_accuracy: 0.8678 - val_op_conv_accuracy: 0.8461 - val_avg_accuracy: 0.8517\n",
      "Epoch 176/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7762 - op_main_loss: 0.1904 - op_conv_loss: 0.1179 - avg_loss: 0.1450 - op_main_accuracy: 0.9286 - op_conv_accuracy: 0.9497 - avg_accuracy: 0.9480\n",
      "Epoch 00176: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7762 - op_main_loss: 0.1904 - op_conv_loss: 0.1179 - avg_loss: 0.1450 - op_main_accuracy: 0.9286 - op_conv_accuracy: 0.9497 - avg_accuracy: 0.9480 - val_loss: 1.1806 - val_op_main_loss: 0.2528 - val_op_conv_loss: 0.3460 - val_avg_loss: 0.2601 - val_op_main_accuracy: 0.8886 - val_op_conv_accuracy: 0.8820 - val_avg_accuracy: 0.8942\n",
      "Epoch 177/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7415 - op_main_loss: 0.1786 - op_conv_loss: 0.1060 - avg_loss: 0.1349 - op_main_accuracy: 0.9386 - op_conv_accuracy: 0.9582 - avg_accuracy: 0.9568\n",
      "Epoch 00177: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7415 - op_main_loss: 0.1786 - op_conv_loss: 0.1060 - avg_loss: 0.1349 - op_main_accuracy: 0.9386 - op_conv_accuracy: 0.9582 - avg_accuracy: 0.9568 - val_loss: 1.1386 - val_op_main_loss: 0.2438 - val_op_conv_loss: 0.3273 - val_avg_loss: 0.2453 - val_op_main_accuracy: 0.8914 - val_op_conv_accuracy: 0.8952 - val_avg_accuracy: 0.8971\n",
      "Epoch 178/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7414 - op_main_loss: 0.1796 - op_conv_loss: 0.1055 - avg_loss: 0.1349 - op_main_accuracy: 0.9374 - op_conv_accuracy: 0.9556 - avg_accuracy: 0.9568\n",
      "Epoch 00178: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7414 - op_main_loss: 0.1796 - op_conv_loss: 0.1055 - avg_loss: 0.1349 - op_main_accuracy: 0.9374 - op_conv_accuracy: 0.9556 - avg_accuracy: 0.9568 - val_loss: 1.0652 - val_op_main_loss: 0.2402 - val_op_conv_loss: 0.2760 - val_avg_loss: 0.2279 - val_op_main_accuracy: 0.8895 - val_op_conv_accuracy: 0.9065 - val_avg_accuracy: 0.9037\n",
      "Epoch 179/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7546 - op_main_loss: 0.1840 - op_conv_loss: 0.1110 - avg_loss: 0.1384 - op_main_accuracy: 0.9348 - op_conv_accuracy: 0.9563 - avg_accuracy: 0.9527\n",
      "Epoch 00179: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7546 - op_main_loss: 0.1840 - op_conv_loss: 0.1110 - avg_loss: 0.1384 - op_main_accuracy: 0.9348 - op_conv_accuracy: 0.9563 - avg_accuracy: 0.9527 - val_loss: 1.1878 - val_op_main_loss: 0.2730 - val_op_conv_loss: 0.3338 - val_avg_loss: 0.2594 - val_op_main_accuracy: 0.8980 - val_op_conv_accuracy: 0.9065 - val_avg_accuracy: 0.8999\n",
      "Epoch 180/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7895 - op_main_loss: 0.1980 - op_conv_loss: 0.1203 - avg_loss: 0.1498 - op_main_accuracy: 0.9324 - op_conv_accuracy: 0.9520 - avg_accuracy: 0.9518\n",
      "Epoch 00180: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7895 - op_main_loss: 0.1980 - op_conv_loss: 0.1203 - avg_loss: 0.1498 - op_main_accuracy: 0.9324 - op_conv_accuracy: 0.9520 - avg_accuracy: 0.9518 - val_loss: 1.0786 - val_op_main_loss: 0.2405 - val_op_conv_loss: 0.2834 - val_avg_loss: 0.2331 - val_op_main_accuracy: 0.8952 - val_op_conv_accuracy: 0.9037 - val_avg_accuracy: 0.9037\n",
      "Epoch 181/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7439 - op_main_loss: 0.1818 - op_conv_loss: 0.1046 - avg_loss: 0.1357 - op_main_accuracy: 0.9376 - op_conv_accuracy: 0.9582 - avg_accuracy: 0.9586\n",
      "Epoch 00181: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7439 - op_main_loss: 0.1818 - op_conv_loss: 0.1046 - avg_loss: 0.1357 - op_main_accuracy: 0.9376 - op_conv_accuracy: 0.9582 - avg_accuracy: 0.9586 - val_loss: 1.2142 - val_op_main_loss: 0.2514 - val_op_conv_loss: 0.3747 - val_avg_loss: 0.2662 - val_op_main_accuracy: 0.8905 - val_op_conv_accuracy: 0.8810 - val_avg_accuracy: 0.8886\n",
      "Epoch 182/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.7617 - op_main_loss: 0.1903 - op_conv_loss: 0.1093 - avg_loss: 0.1404 - op_main_accuracy: 0.9270 - op_conv_accuracy: 0.9542 - avg_accuracy: 0.9542\n",
      "Epoch 00182: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 0.7603 - op_main_loss: 0.1898 - op_conv_loss: 0.1088 - avg_loss: 0.1400 - op_main_accuracy: 0.9272 - op_conv_accuracy: 0.9544 - avg_accuracy: 0.9544 - val_loss: 1.2761 - val_op_main_loss: 0.2774 - val_op_conv_loss: 0.3886 - val_avg_loss: 0.2883 - val_op_main_accuracy: 0.8848 - val_op_conv_accuracy: 0.8857 - val_avg_accuracy: 0.8876\n",
      "Epoch 183/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.7168 - op_main_loss: 0.1745 - op_conv_loss: 0.0943 - avg_loss: 0.1266 - op_main_accuracy: 0.9394 - op_conv_accuracy: 0.9637 - avg_accuracy: 0.9625\n",
      "Epoch 00183: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 0.7174 - op_main_loss: 0.1751 - op_conv_loss: 0.0942 - avg_loss: 0.1268 - op_main_accuracy: 0.9390 - op_conv_accuracy: 0.9636 - avg_accuracy: 0.9624 - val_loss: 1.0917 - val_op_main_loss: 0.2410 - val_op_conv_loss: 0.2928 - val_avg_loss: 0.2368 - val_op_main_accuracy: 0.8905 - val_op_conv_accuracy: 0.9008 - val_avg_accuracy: 0.9027\n",
      "Epoch 184/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.7307 - op_main_loss: 0.1756 - op_conv_loss: 0.1026 - avg_loss: 0.1316 - op_main_accuracy: 0.9392 - op_conv_accuracy: 0.9592 - avg_accuracy: 0.9578\n",
      "Epoch 00184: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.7293 - op_main_loss: 0.1752 - op_conv_loss: 0.1020 - avg_loss: 0.1312 - op_main_accuracy: 0.9395 - op_conv_accuracy: 0.9596 - avg_accuracy: 0.9582 - val_loss: 1.1837 - val_op_main_loss: 0.2424 - val_op_conv_loss: 0.3768 - val_avg_loss: 0.2437 - val_op_main_accuracy: 0.8999 - val_op_conv_accuracy: 0.8848 - val_avg_accuracy: 0.9046\n",
      "Epoch 185/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7479 - op_main_loss: 0.1820 - op_conv_loss: 0.1092 - avg_loss: 0.1362 - op_main_accuracy: 0.9324 - op_conv_accuracy: 0.9563 - avg_accuracy: 0.9560\n",
      "Epoch 00185: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.7479 - op_main_loss: 0.1820 - op_conv_loss: 0.1092 - avg_loss: 0.1362 - op_main_accuracy: 0.9324 - op_conv_accuracy: 0.9563 - avg_accuracy: 0.9560 - val_loss: 1.0997 - val_op_main_loss: 0.2431 - val_op_conv_loss: 0.2974 - val_avg_loss: 0.2389 - val_op_main_accuracy: 0.8971 - val_op_conv_accuracy: 0.8961 - val_avg_accuracy: 0.8971\n",
      "Epoch 186/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/133 [============================>.] - ETA: 0s - loss: 0.7250 - op_main_loss: 0.1766 - op_conv_loss: 0.0982 - avg_loss: 0.1299 - op_main_accuracy: 0.9396 - op_conv_accuracy: 0.9616 - avg_accuracy: 0.9616\n",
      "Epoch 00186: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.7246 - op_main_loss: 0.1765 - op_conv_loss: 0.0980 - avg_loss: 0.1298 - op_main_accuracy: 0.9397 - op_conv_accuracy: 0.9617 - avg_accuracy: 0.9617 - val_loss: 1.1843 - val_op_main_loss: 0.2662 - val_op_conv_loss: 0.3333 - val_avg_loss: 0.2647 - val_op_main_accuracy: 0.8924 - val_op_conv_accuracy: 0.8980 - val_avg_accuracy: 0.8990\n",
      "Epoch 187/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.7078 - op_main_loss: 0.1702 - op_conv_loss: 0.0933 - avg_loss: 0.1243 - op_main_accuracy: 0.9425 - op_conv_accuracy: 0.9661 - avg_accuracy: 0.9628\n",
      "Epoch 00187: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.7087 - op_main_loss: 0.1704 - op_conv_loss: 0.0937 - avg_loss: 0.1245 - op_main_accuracy: 0.9423 - op_conv_accuracy: 0.9657 - avg_accuracy: 0.9624 - val_loss: 1.4640 - val_op_main_loss: 0.2899 - val_op_conv_loss: 0.5248 - val_avg_loss: 0.3294 - val_op_main_accuracy: 0.8791 - val_op_conv_accuracy: 0.8574 - val_avg_accuracy: 0.8650\n",
      "Epoch 188/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.7496 - op_main_loss: 0.1804 - op_conv_loss: 0.1126 - avg_loss: 0.1375 - op_main_accuracy: 0.9373 - op_conv_accuracy: 0.9572 - avg_accuracy: 0.9570\n",
      "Epoch 00188: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.7462 - op_main_loss: 0.1795 - op_conv_loss: 0.1112 - avg_loss: 0.1364 - op_main_accuracy: 0.9381 - op_conv_accuracy: 0.9579 - avg_accuracy: 0.9577 - val_loss: 1.0677 - val_op_main_loss: 0.2409 - val_op_conv_loss: 0.2778 - val_avg_loss: 0.2302 - val_op_main_accuracy: 0.8961 - val_op_conv_accuracy: 0.9122 - val_avg_accuracy: 0.9084\n",
      "Epoch 189/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.7367 - op_main_loss: 0.1816 - op_conv_loss: 0.1029 - avg_loss: 0.1335 - op_main_accuracy: 0.9318 - op_conv_accuracy: 0.9567 - avg_accuracy: 0.9543\n",
      "Epoch 00189: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.7373 - op_main_loss: 0.1819 - op_conv_loss: 0.1031 - avg_loss: 0.1336 - op_main_accuracy: 0.9315 - op_conv_accuracy: 0.9565 - avg_accuracy: 0.9542 - val_loss: 1.1380 - val_op_main_loss: 0.2519 - val_op_conv_loss: 0.3156 - val_avg_loss: 0.2518 - val_op_main_accuracy: 0.8933 - val_op_conv_accuracy: 0.8971 - val_avg_accuracy: 0.8980\n",
      "Epoch 190/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.7234 - op_main_loss: 0.1753 - op_conv_loss: 0.0997 - avg_loss: 0.1294 - op_main_accuracy: 0.9423 - op_conv_accuracy: 0.9602 - avg_accuracy: 0.9611\n",
      "Epoch 00190: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.7262 - op_main_loss: 0.1763 - op_conv_loss: 0.1006 - avg_loss: 0.1304 - op_main_accuracy: 0.9414 - op_conv_accuracy: 0.9594 - avg_accuracy: 0.9603 - val_loss: 1.1294 - val_op_main_loss: 0.2462 - val_op_conv_loss: 0.3293 - val_avg_loss: 0.2349 - val_op_main_accuracy: 0.8886 - val_op_conv_accuracy: 0.8980 - val_avg_accuracy: 0.9075\n",
      "Epoch 191/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.7125 - op_main_loss: 0.1723 - op_conv_loss: 0.0950 - avg_loss: 0.1260 - op_main_accuracy: 0.9420 - op_conv_accuracy: 0.9643 - avg_accuracy: 0.9600\n",
      "Epoch 00191: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.7127 - op_main_loss: 0.1724 - op_conv_loss: 0.0950 - avg_loss: 0.1260 - op_main_accuracy: 0.9419 - op_conv_accuracy: 0.9643 - avg_accuracy: 0.9601 - val_loss: 1.1669 - val_op_main_loss: 0.2618 - val_op_conv_loss: 0.3271 - val_avg_loss: 0.2588 - val_op_main_accuracy: 0.8914 - val_op_conv_accuracy: 0.9018 - val_avg_accuracy: 0.8999\n",
      "Epoch 192/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.7270 - op_main_loss: 0.1764 - op_conv_loss: 0.1011 - avg_loss: 0.1307 - op_main_accuracy: 0.9354 - op_conv_accuracy: 0.9628 - avg_accuracy: 0.9583\n",
      "Epoch 00192: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.7294 - op_main_loss: 0.1771 - op_conv_loss: 0.1020 - avg_loss: 0.1315 - op_main_accuracy: 0.9348 - op_conv_accuracy: 0.9624 - avg_accuracy: 0.9579 - val_loss: 1.1325 - val_op_main_loss: 0.2481 - val_op_conv_loss: 0.3237 - val_avg_loss: 0.2427 - val_op_main_accuracy: 0.8952 - val_op_conv_accuracy: 0.9056 - val_avg_accuracy: 0.8999\n",
      "Epoch 193/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7298 - op_main_loss: 0.1767 - op_conv_loss: 0.1032 - avg_loss: 0.1317 - op_main_accuracy: 0.9360 - op_conv_accuracy: 0.9570 - avg_accuracy: 0.9549\n",
      "Epoch 00193: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.7298 - op_main_loss: 0.1767 - op_conv_loss: 0.1032 - avg_loss: 0.1317 - op_main_accuracy: 0.9360 - op_conv_accuracy: 0.9570 - avg_accuracy: 0.9549 - val_loss: 1.2191 - val_op_main_loss: 0.2750 - val_op_conv_loss: 0.3507 - val_avg_loss: 0.2752 - val_op_main_accuracy: 0.8914 - val_op_conv_accuracy: 0.8999 - val_avg_accuracy: 0.8999\n",
      "Epoch 194/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.7584 - op_main_loss: 0.1884 - op_conv_loss: 0.1120 - avg_loss: 0.1398 - op_main_accuracy: 0.9247 - op_conv_accuracy: 0.9538 - avg_accuracy: 0.9527\n",
      "Epoch 00194: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.7579 - op_main_loss: 0.1882 - op_conv_loss: 0.1120 - avg_loss: 0.1397 - op_main_accuracy: 0.9249 - op_conv_accuracy: 0.9539 - avg_accuracy: 0.9527 - val_loss: 1.1230 - val_op_main_loss: 0.2621 - val_op_conv_loss: 0.2949 - val_avg_loss: 0.2482 - val_op_main_accuracy: 0.8895 - val_op_conv_accuracy: 0.9027 - val_avg_accuracy: 0.9056\n",
      "Epoch 195/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.7425 - op_main_loss: 0.1779 - op_conv_loss: 0.1108 - avg_loss: 0.1361 - op_main_accuracy: 0.9339 - op_conv_accuracy: 0.9562 - avg_accuracy: 0.9555\n",
      "Epoch 00195: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.7424 - op_main_loss: 0.1780 - op_conv_loss: 0.1107 - avg_loss: 0.1361 - op_main_accuracy: 0.9338 - op_conv_accuracy: 0.9563 - avg_accuracy: 0.9553 - val_loss: 1.1177 - val_op_main_loss: 0.2623 - val_op_conv_loss: 0.2913 - val_avg_loss: 0.2467 - val_op_main_accuracy: 0.8886 - val_op_conv_accuracy: 0.9056 - val_avg_accuracy: 0.9008\n",
      "Epoch 196/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.7289 - op_main_loss: 0.1781 - op_conv_loss: 0.1018 - avg_loss: 0.1317 - op_main_accuracy: 0.9349 - op_conv_accuracy: 0.9606 - avg_accuracy: 0.9575\n",
      "Epoch 00196: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.7288 - op_main_loss: 0.1782 - op_conv_loss: 0.1017 - avg_loss: 0.1317 - op_main_accuracy: 0.9345 - op_conv_accuracy: 0.9608 - avg_accuracy: 0.9572 - val_loss: 1.1401 - val_op_main_loss: 0.2525 - val_op_conv_loss: 0.3231 - val_avg_loss: 0.2474 - val_op_main_accuracy: 0.8886 - val_op_conv_accuracy: 0.9037 - val_avg_accuracy: 0.9046\n",
      "Epoch 197/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.7417 - op_main_loss: 0.1809 - op_conv_loss: 0.1081 - avg_loss: 0.1358 - op_main_accuracy: 0.9353 - op_conv_accuracy: 0.9565 - avg_accuracy: 0.9572\n",
      "Epoch 00197: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.7439 - op_main_loss: 0.1815 - op_conv_loss: 0.1090 - avg_loss: 0.1366 - op_main_accuracy: 0.9350 - op_conv_accuracy: 0.9560 - avg_accuracy: 0.9570 - val_loss: 1.2140 - val_op_main_loss: 0.2451 - val_op_conv_loss: 0.3895 - val_avg_loss: 0.2626 - val_op_main_accuracy: 0.8876 - val_op_conv_accuracy: 0.8763 - val_avg_accuracy: 0.8867\n",
      "Epoch 198/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/133 [============================>.] - ETA: 0s - loss: 0.7180 - op_main_loss: 0.1710 - op_conv_loss: 0.1017 - avg_loss: 0.1287 - op_main_accuracy: 0.9448 - op_conv_accuracy: 0.9574 - avg_accuracy: 0.9583\n",
      "Epoch 00198: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.7186 - op_main_loss: 0.1712 - op_conv_loss: 0.1019 - avg_loss: 0.1289 - op_main_accuracy: 0.9447 - op_conv_accuracy: 0.9572 - avg_accuracy: 0.9582 - val_loss: 1.0834 - val_op_main_loss: 0.2423 - val_op_conv_loss: 0.2896 - val_avg_loss: 0.2349 - val_op_main_accuracy: 0.8952 - val_op_conv_accuracy: 0.9084 - val_avg_accuracy: 0.9075\n",
      "Epoch 199/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7557 - op_main_loss: 0.1856 - op_conv_loss: 0.1136 - avg_loss: 0.1405 - op_main_accuracy: 0.9329 - op_conv_accuracy: 0.9558 - avg_accuracy: 0.9542\n",
      "Epoch 00199: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.7557 - op_main_loss: 0.1856 - op_conv_loss: 0.1136 - avg_loss: 0.1405 - op_main_accuracy: 0.9329 - op_conv_accuracy: 0.9558 - avg_accuracy: 0.9542 - val_loss: 1.5539 - val_op_main_loss: 0.3319 - val_op_conv_loss: 0.5362 - val_avg_loss: 0.3706 - val_op_main_accuracy: 0.8697 - val_op_conv_accuracy: 0.8451 - val_avg_accuracy: 0.8555\n",
      "Epoch 200/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.7093 - op_main_loss: 0.1712 - op_conv_loss: 0.0963 - avg_loss: 0.1270 - op_main_accuracy: 0.9411 - op_conv_accuracy: 0.9594 - avg_accuracy: 0.9571\n",
      "Epoch 00200: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.7083 - op_main_loss: 0.1708 - op_conv_loss: 0.0960 - avg_loss: 0.1267 - op_main_accuracy: 0.9414 - op_conv_accuracy: 0.9596 - avg_accuracy: 0.9572 - val_loss: 1.1451 - val_op_main_loss: 0.2731 - val_op_conv_loss: 0.2979 - val_avg_loss: 0.2591 - val_op_main_accuracy: 0.8848 - val_op_conv_accuracy: 0.9027 - val_avg_accuracy: 0.9037\n",
      "Epoch 201/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.7309 - op_main_loss: 0.1758 - op_conv_loss: 0.1074 - avg_loss: 0.1324 - op_main_accuracy: 0.9416 - op_conv_accuracy: 0.9598 - avg_accuracy: 0.9574\n",
      "Epoch 00201: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.7314 - op_main_loss: 0.1762 - op_conv_loss: 0.1073 - avg_loss: 0.1326 - op_main_accuracy: 0.9412 - op_conv_accuracy: 0.9591 - avg_accuracy: 0.9568 - val_loss: 1.1421 - val_op_main_loss: 0.2566 - val_op_conv_loss: 0.3222 - val_avg_loss: 0.2474 - val_op_main_accuracy: 0.8942 - val_op_conv_accuracy: 0.9112 - val_avg_accuracy: 0.9065\n",
      "Epoch 202/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.7114 - op_main_loss: 0.1723 - op_conv_loss: 0.0968 - avg_loss: 0.1268 - op_main_accuracy: 0.9389 - op_conv_accuracy: 0.9637 - avg_accuracy: 0.9608\n",
      "Epoch 00202: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.7117 - op_main_loss: 0.1724 - op_conv_loss: 0.0968 - avg_loss: 0.1269 - op_main_accuracy: 0.9393 - op_conv_accuracy: 0.9638 - avg_accuracy: 0.9610 - val_loss: 1.3999 - val_op_main_loss: 0.2665 - val_op_conv_loss: 0.5092 - val_avg_loss: 0.3087 - val_op_main_accuracy: 0.8839 - val_op_conv_accuracy: 0.8555 - val_avg_accuracy: 0.8669\n",
      "Epoch 203/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.7182 - op_main_loss: 0.1717 - op_conv_loss: 0.1018 - avg_loss: 0.1293 - op_main_accuracy: 0.9435 - op_conv_accuracy: 0.9627 - avg_accuracy: 0.9591\n",
      "Epoch 00203: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.7166 - op_main_loss: 0.1710 - op_conv_loss: 0.1014 - avg_loss: 0.1288 - op_main_accuracy: 0.9438 - op_conv_accuracy: 0.9629 - avg_accuracy: 0.9594 - val_loss: 1.1766 - val_op_main_loss: 0.2578 - val_op_conv_loss: 0.3422 - val_avg_loss: 0.2619 - val_op_main_accuracy: 0.8867 - val_op_conv_accuracy: 0.8905 - val_avg_accuracy: 0.8924\n",
      "Epoch 204/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.7099 - op_main_loss: 0.1697 - op_conv_loss: 0.0988 - avg_loss: 0.1270 - op_main_accuracy: 0.9411 - op_conv_accuracy: 0.9580 - avg_accuracy: 0.9590\n",
      "Epoch 00204: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.7155 - op_main_loss: 0.1712 - op_conv_loss: 0.1012 - avg_loss: 0.1287 - op_main_accuracy: 0.9393 - op_conv_accuracy: 0.9570 - avg_accuracy: 0.9577 - val_loss: 1.0796 - val_op_main_loss: 0.2442 - val_op_conv_loss: 0.2873 - val_avg_loss: 0.2339 - val_op_main_accuracy: 0.8980 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9103\n",
      "Epoch 205/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.7284 - op_main_loss: 0.1770 - op_conv_loss: 0.1046 - avg_loss: 0.1330 - op_main_accuracy: 0.9353 - op_conv_accuracy: 0.9574 - avg_accuracy: 0.9554\n",
      "Epoch 00205: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.7271 - op_main_loss: 0.1764 - op_conv_loss: 0.1042 - avg_loss: 0.1326 - op_main_accuracy: 0.9362 - op_conv_accuracy: 0.9575 - avg_accuracy: 0.9558 - val_loss: 1.0899 - val_op_main_loss: 0.2497 - val_op_conv_loss: 0.2878 - val_avg_loss: 0.2389 - val_op_main_accuracy: 0.8876 - val_op_conv_accuracy: 0.9075 - val_avg_accuracy: 0.9065\n",
      "Epoch 206/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7081 - op_main_loss: 0.1737 - op_conv_loss: 0.0947 - avg_loss: 0.1265 - op_main_accuracy: 0.9414 - op_conv_accuracy: 0.9610 - avg_accuracy: 0.9620\n",
      "Epoch 00206: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.7081 - op_main_loss: 0.1737 - op_conv_loss: 0.0947 - avg_loss: 0.1265 - op_main_accuracy: 0.9414 - op_conv_accuracy: 0.9610 - avg_accuracy: 0.9620 - val_loss: 1.1516 - val_op_main_loss: 0.2462 - val_op_conv_loss: 0.3461 - val_avg_loss: 0.2454 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.8990 - val_avg_accuracy: 0.9027\n",
      "Epoch 207/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.7102 - op_main_loss: 0.1711 - op_conv_loss: 0.0983 - avg_loss: 0.1268 - op_main_accuracy: 0.9420 - op_conv_accuracy: 0.9626 - avg_accuracy: 0.9614\n",
      "Epoch 00207: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.7099 - op_main_loss: 0.1710 - op_conv_loss: 0.0982 - avg_loss: 0.1267 - op_main_accuracy: 0.9419 - op_conv_accuracy: 0.9627 - avg_accuracy: 0.9615 - val_loss: 1.2065 - val_op_main_loss: 0.2478 - val_op_conv_loss: 0.3890 - val_avg_loss: 0.2563 - val_op_main_accuracy: 0.8971 - val_op_conv_accuracy: 0.8801 - val_avg_accuracy: 0.8961\n",
      "Epoch 208/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7058 - op_main_loss: 0.1687 - op_conv_loss: 0.0980 - avg_loss: 0.1258 - op_main_accuracy: 0.9428 - op_conv_accuracy: 0.9622 - avg_accuracy: 0.9596\n",
      "Epoch 00208: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.7058 - op_main_loss: 0.1687 - op_conv_loss: 0.0980 - avg_loss: 0.1258 - op_main_accuracy: 0.9428 - op_conv_accuracy: 0.9622 - avg_accuracy: 0.9596 - val_loss: 1.0922 - val_op_main_loss: 0.2594 - val_op_conv_loss: 0.2821 - val_avg_loss: 0.2376 - val_op_main_accuracy: 0.8848 - val_op_conv_accuracy: 0.9075 - val_avg_accuracy: 0.9037\n",
      "Epoch 209/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.7263 - op_main_loss: 0.1764 - op_conv_loss: 0.1052 - avg_loss: 0.1318 - op_main_accuracy: 0.9394 - op_conv_accuracy: 0.9586 - avg_accuracy: 0.9557\n",
      "Epoch 00209: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.7276 - op_main_loss: 0.1770 - op_conv_loss: 0.1054 - avg_loss: 0.1321 - op_main_accuracy: 0.9390 - op_conv_accuracy: 0.9584 - avg_accuracy: 0.9553 - val_loss: 1.2575 - val_op_main_loss: 0.2816 - val_op_conv_loss: 0.3813 - val_avg_loss: 0.2823 - val_op_main_accuracy: 0.8952 - val_op_conv_accuracy: 0.8961 - val_avg_accuracy: 0.8980\n",
      "Epoch 210/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/133 [============================>.] - ETA: 0s - loss: 0.7125 - op_main_loss: 0.1721 - op_conv_loss: 0.0993 - avg_loss: 0.1284 - op_main_accuracy: 0.9387 - op_conv_accuracy: 0.9587 - avg_accuracy: 0.9571\n",
      "Epoch 00210: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.7157 - op_main_loss: 0.1728 - op_conv_loss: 0.1007 - avg_loss: 0.1294 - op_main_accuracy: 0.9383 - op_conv_accuracy: 0.9582 - avg_accuracy: 0.9565 - val_loss: 1.1229 - val_op_main_loss: 0.2627 - val_op_conv_loss: 0.2971 - val_avg_loss: 0.2503 - val_op_main_accuracy: 0.8857 - val_op_conv_accuracy: 0.9027 - val_avg_accuracy: 0.8990\n",
      "Epoch 211/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.7050 - op_main_loss: 0.1711 - op_conv_loss: 0.0955 - avg_loss: 0.1258 - op_main_accuracy: 0.9399 - op_conv_accuracy: 0.9627 - avg_accuracy: 0.9576\n",
      "Epoch 00211: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.7046 - op_main_loss: 0.1710 - op_conv_loss: 0.0953 - avg_loss: 0.1257 - op_main_accuracy: 0.9405 - op_conv_accuracy: 0.9627 - avg_accuracy: 0.9579 - val_loss: 1.1745 - val_op_main_loss: 0.2618 - val_op_conv_loss: 0.3443 - val_avg_loss: 0.2556 - val_op_main_accuracy: 0.8952 - val_op_conv_accuracy: 0.9008 - val_avg_accuracy: 0.9046\n",
      "Epoch 212/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7073 - op_main_loss: 0.1714 - op_conv_loss: 0.0964 - avg_loss: 0.1258 - op_main_accuracy: 0.9393 - op_conv_accuracy: 0.9620 - avg_accuracy: 0.9610\n",
      "Epoch 00212: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7073 - op_main_loss: 0.1714 - op_conv_loss: 0.0964 - avg_loss: 0.1258 - op_main_accuracy: 0.9393 - op_conv_accuracy: 0.9620 - avg_accuracy: 0.9610 - val_loss: 1.1101 - val_op_main_loss: 0.2472 - val_op_conv_loss: 0.3107 - val_avg_loss: 0.2385 - val_op_main_accuracy: 0.8980 - val_op_conv_accuracy: 0.9018 - val_avg_accuracy: 0.8990\n",
      "Epoch 213/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6959 - op_main_loss: 0.1662 - op_conv_loss: 0.0945 - avg_loss: 0.1224 - op_main_accuracy: 0.9438 - op_conv_accuracy: 0.9627 - avg_accuracy: 0.9630\n",
      "Epoch 00213: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.6990 - op_main_loss: 0.1670 - op_conv_loss: 0.0957 - avg_loss: 0.1234 - op_main_accuracy: 0.9438 - op_conv_accuracy: 0.9624 - avg_accuracy: 0.9624 - val_loss: 1.2514 - val_op_main_loss: 0.2570 - val_op_conv_loss: 0.4069 - val_avg_loss: 0.2748 - val_op_main_accuracy: 0.8942 - val_op_conv_accuracy: 0.8791 - val_avg_accuracy: 0.8810\n",
      "Epoch 214/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6822 - op_main_loss: 0.1644 - op_conv_loss: 0.0873 - avg_loss: 0.1181 - op_main_accuracy: 0.9461 - op_conv_accuracy: 0.9667 - avg_accuracy: 0.9664\n",
      "Epoch 00214: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.6822 - op_main_loss: 0.1644 - op_conv_loss: 0.0873 - avg_loss: 0.1181 - op_main_accuracy: 0.9461 - op_conv_accuracy: 0.9667 - avg_accuracy: 0.9664 - val_loss: 1.2652 - val_op_main_loss: 0.2711 - val_op_conv_loss: 0.3948 - val_avg_loss: 0.2875 - val_op_main_accuracy: 0.8848 - val_op_conv_accuracy: 0.8763 - val_avg_accuracy: 0.8857\n",
      "Epoch 215/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.7706 - op_main_loss: 0.1967 - op_conv_loss: 0.1157 - avg_loss: 0.1466 - op_main_accuracy: 0.9284 - op_conv_accuracy: 0.9567 - avg_accuracy: 0.9534\n",
      "Epoch 00215: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.7676 - op_main_loss: 0.1957 - op_conv_loss: 0.1146 - avg_loss: 0.1456 - op_main_accuracy: 0.9286 - op_conv_accuracy: 0.9572 - avg_accuracy: 0.9537 - val_loss: 1.1056 - val_op_main_loss: 0.2465 - val_op_conv_loss: 0.3099 - val_avg_loss: 0.2374 - val_op_main_accuracy: 0.8924 - val_op_conv_accuracy: 0.8971 - val_avg_accuracy: 0.9027\n",
      "Epoch 216/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7004 - op_main_loss: 0.1676 - op_conv_loss: 0.0965 - avg_loss: 0.1241 - op_main_accuracy: 0.9438 - op_conv_accuracy: 0.9631 - avg_accuracy: 0.9596\n",
      "Epoch 00216: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.7004 - op_main_loss: 0.1676 - op_conv_loss: 0.0965 - avg_loss: 0.1241 - op_main_accuracy: 0.9438 - op_conv_accuracy: 0.9631 - avg_accuracy: 0.9596 - val_loss: 1.1675 - val_op_main_loss: 0.2603 - val_op_conv_loss: 0.3413 - val_avg_loss: 0.2541 - val_op_main_accuracy: 0.8952 - val_op_conv_accuracy: 0.9027 - val_avg_accuracy: 0.9027\n",
      "Epoch 217/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6945 - op_main_loss: 0.1680 - op_conv_loss: 0.0927 - avg_loss: 0.1220 - op_main_accuracy: 0.9423 - op_conv_accuracy: 0.9646 - avg_accuracy: 0.9612\n",
      "Epoch 00217: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.6945 - op_main_loss: 0.1680 - op_conv_loss: 0.0927 - avg_loss: 0.1220 - op_main_accuracy: 0.9423 - op_conv_accuracy: 0.9646 - avg_accuracy: 0.9612 - val_loss: 1.1008 - val_op_main_loss: 0.2430 - val_op_conv_loss: 0.3067 - val_avg_loss: 0.2392 - val_op_main_accuracy: 0.9027 - val_op_conv_accuracy: 0.9065 - val_avg_accuracy: 0.9027\n",
      "Epoch 218/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6805 - op_main_loss: 0.1640 - op_conv_loss: 0.0870 - avg_loss: 0.1177 - op_main_accuracy: 0.9422 - op_conv_accuracy: 0.9643 - avg_accuracy: 0.9614\n",
      "Epoch 00218: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 0.6800 - op_main_loss: 0.1639 - op_conv_loss: 0.0868 - avg_loss: 0.1176 - op_main_accuracy: 0.9423 - op_conv_accuracy: 0.9643 - avg_accuracy: 0.9615 - val_loss: 1.1681 - val_op_main_loss: 0.2555 - val_op_conv_loss: 0.3460 - val_avg_loss: 0.2551 - val_op_main_accuracy: 0.8971 - val_op_conv_accuracy: 0.9018 - val_avg_accuracy: 0.9027\n",
      "Epoch 219/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7067 - op_main_loss: 0.1710 - op_conv_loss: 0.0981 - avg_loss: 0.1259 - op_main_accuracy: 0.9423 - op_conv_accuracy: 0.9624 - avg_accuracy: 0.9617\n",
      "Epoch 00219: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.7067 - op_main_loss: 0.1710 - op_conv_loss: 0.0981 - avg_loss: 0.1259 - op_main_accuracy: 0.9423 - op_conv_accuracy: 0.9624 - avg_accuracy: 0.9617 - val_loss: 1.1004 - val_op_main_loss: 0.2443 - val_op_conv_loss: 0.3063 - val_avg_loss: 0.2381 - val_op_main_accuracy: 0.8952 - val_op_conv_accuracy: 0.9093 - val_avg_accuracy: 0.9065\n",
      "Epoch 220/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6760 - op_main_loss: 0.1605 - op_conv_loss: 0.0872 - avg_loss: 0.1167 - op_main_accuracy: 0.9449 - op_conv_accuracy: 0.9662 - avg_accuracy: 0.9643\n",
      "Epoch 00220: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.6760 - op_main_loss: 0.1605 - op_conv_loss: 0.0872 - avg_loss: 0.1167 - op_main_accuracy: 0.9449 - op_conv_accuracy: 0.9662 - avg_accuracy: 0.9643 - val_loss: 1.3632 - val_op_main_loss: 0.2662 - val_op_conv_loss: 0.4844 - val_avg_loss: 0.3009 - val_op_main_accuracy: 0.8867 - val_op_conv_accuracy: 0.8687 - val_avg_accuracy: 0.8782\n",
      "Epoch 221/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.7269 - op_main_loss: 0.1778 - op_conv_loss: 0.1059 - avg_loss: 0.1325 - op_main_accuracy: 0.9384 - op_conv_accuracy: 0.9626 - avg_accuracy: 0.9598\n",
      "Epoch 00221: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.7265 - op_main_loss: 0.1777 - op_conv_loss: 0.1057 - avg_loss: 0.1323 - op_main_accuracy: 0.9386 - op_conv_accuracy: 0.9627 - avg_accuracy: 0.9598 - val_loss: 1.1064 - val_op_main_loss: 0.2574 - val_op_conv_loss: 0.2936 - val_avg_loss: 0.2451 - val_op_main_accuracy: 0.8961 - val_op_conv_accuracy: 0.9037 - val_avg_accuracy: 0.9037\n",
      "Epoch 222/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/133 [============================>.] - ETA: 0s - loss: 0.6834 - op_main_loss: 0.1629 - op_conv_loss: 0.0902 - avg_loss: 0.1201 - op_main_accuracy: 0.9437 - op_conv_accuracy: 0.9649 - avg_accuracy: 0.9618\n",
      "Epoch 00222: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6867 - op_main_loss: 0.1642 - op_conv_loss: 0.0911 - avg_loss: 0.1211 - op_main_accuracy: 0.9421 - op_conv_accuracy: 0.9646 - avg_accuracy: 0.9612 - val_loss: 1.1211 - val_op_main_loss: 0.2511 - val_op_conv_loss: 0.3116 - val_avg_loss: 0.2481 - val_op_main_accuracy: 0.8952 - val_op_conv_accuracy: 0.8971 - val_avg_accuracy: 0.9075\n",
      "Epoch 223/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6864 - op_main_loss: 0.1646 - op_conv_loss: 0.0910 - avg_loss: 0.1207 - op_main_accuracy: 0.9430 - op_conv_accuracy: 0.9635 - avg_accuracy: 0.9627\n",
      "Epoch 00223: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6860 - op_main_loss: 0.1643 - op_conv_loss: 0.0910 - avg_loss: 0.1206 - op_main_accuracy: 0.9435 - op_conv_accuracy: 0.9631 - avg_accuracy: 0.9629 - val_loss: 1.0858 - val_op_main_loss: 0.2412 - val_op_conv_loss: 0.2979 - val_avg_loss: 0.2366 - val_op_main_accuracy: 0.8961 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9027\n",
      "Epoch 224/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6956 - op_main_loss: 0.1651 - op_conv_loss: 0.0980 - avg_loss: 0.1234 - op_main_accuracy: 0.9471 - op_conv_accuracy: 0.9618 - avg_accuracy: 0.9635\n",
      "Epoch 00224: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6947 - op_main_loss: 0.1647 - op_conv_loss: 0.0979 - avg_loss: 0.1231 - op_main_accuracy: 0.9468 - op_conv_accuracy: 0.9622 - avg_accuracy: 0.9636 - val_loss: 1.0960 - val_op_main_loss: 0.2393 - val_op_conv_loss: 0.3126 - val_avg_loss: 0.2350 - val_op_main_accuracy: 0.8933 - val_op_conv_accuracy: 0.8952 - val_avg_accuracy: 0.9008\n",
      "Epoch 225/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.7054 - op_main_loss: 0.1713 - op_conv_loss: 0.0989 - avg_loss: 0.1261 - op_main_accuracy: 0.9380 - op_conv_accuracy: 0.9625 - avg_accuracy: 0.9620\n",
      "Epoch 00225: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.7048 - op_main_loss: 0.1712 - op_conv_loss: 0.0986 - avg_loss: 0.1260 - op_main_accuracy: 0.9376 - op_conv_accuracy: 0.9627 - avg_accuracy: 0.9620 - val_loss: 1.1672 - val_op_main_loss: 0.2400 - val_op_conv_loss: 0.3675 - val_avg_loss: 0.2511 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.8876 - val_avg_accuracy: 0.8990\n",
      "Epoch 226/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6717 - op_main_loss: 0.1581 - op_conv_loss: 0.0885 - avg_loss: 0.1164 - op_main_accuracy: 0.9462 - op_conv_accuracy: 0.9630 - avg_accuracy: 0.9637\n",
      "Epoch 00226: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6738 - op_main_loss: 0.1586 - op_conv_loss: 0.0894 - avg_loss: 0.1171 - op_main_accuracy: 0.9459 - op_conv_accuracy: 0.9624 - avg_accuracy: 0.9634 - val_loss: 1.1564 - val_op_main_loss: 0.2587 - val_op_conv_loss: 0.3292 - val_avg_loss: 0.2596 - val_op_main_accuracy: 0.8886 - val_op_conv_accuracy: 0.8886 - val_avg_accuracy: 0.8971\n",
      "Epoch 227/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6897 - op_main_loss: 0.1668 - op_conv_loss: 0.0928 - avg_loss: 0.1215 - op_main_accuracy: 0.9426 - op_conv_accuracy: 0.9660 - avg_accuracy: 0.9636\n",
      "Epoch 00227: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6897 - op_main_loss: 0.1668 - op_conv_loss: 0.0928 - avg_loss: 0.1215 - op_main_accuracy: 0.9426 - op_conv_accuracy: 0.9660 - avg_accuracy: 0.9636 - val_loss: 1.3059 - val_op_main_loss: 0.2714 - val_op_conv_loss: 0.4314 - val_avg_loss: 0.2944 - val_op_main_accuracy: 0.8857 - val_op_conv_accuracy: 0.8772 - val_avg_accuracy: 0.8886\n",
      "Epoch 228/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6837 - op_main_loss: 0.1647 - op_conv_loss: 0.0904 - avg_loss: 0.1198 - op_main_accuracy: 0.9441 - op_conv_accuracy: 0.9645 - avg_accuracy: 0.9605\n",
      "Epoch 00228: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6833 - op_main_loss: 0.1645 - op_conv_loss: 0.0903 - avg_loss: 0.1197 - op_main_accuracy: 0.9442 - op_conv_accuracy: 0.9646 - avg_accuracy: 0.9605 - val_loss: 1.1145 - val_op_main_loss: 0.2469 - val_op_conv_loss: 0.3167 - val_avg_loss: 0.2421 - val_op_main_accuracy: 0.8914 - val_op_conv_accuracy: 0.9018 - val_avg_accuracy: 0.9056\n",
      "Epoch 229/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.6764 - op_main_loss: 0.1598 - op_conv_loss: 0.0901 - avg_loss: 0.1178 - op_main_accuracy: 0.9462 - op_conv_accuracy: 0.9629 - avg_accuracy: 0.9615\n",
      "Epoch 00229: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6765 - op_main_loss: 0.1598 - op_conv_loss: 0.0902 - avg_loss: 0.1178 - op_main_accuracy: 0.9461 - op_conv_accuracy: 0.9627 - avg_accuracy: 0.9615 - val_loss: 1.1212 - val_op_main_loss: 0.2562 - val_op_conv_loss: 0.3085 - val_avg_loss: 0.2477 - val_op_main_accuracy: 0.8895 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9065\n",
      "Epoch 230/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.7032 - op_main_loss: 0.1725 - op_conv_loss: 0.0966 - avg_loss: 0.1260 - op_main_accuracy: 0.9425 - op_conv_accuracy: 0.9635 - avg_accuracy: 0.9611\n",
      "Epoch 00230: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.7037 - op_main_loss: 0.1725 - op_conv_loss: 0.0970 - avg_loss: 0.1261 - op_main_accuracy: 0.9423 - op_conv_accuracy: 0.9636 - avg_accuracy: 0.9610 - val_loss: 1.1065 - val_op_main_loss: 0.2441 - val_op_conv_loss: 0.3146 - val_avg_loss: 0.2398 - val_op_main_accuracy: 0.8971 - val_op_conv_accuracy: 0.8999 - val_avg_accuracy: 0.9065\n",
      "Epoch 231/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6955 - op_main_loss: 0.1644 - op_conv_loss: 0.0992 - avg_loss: 0.1239 - op_main_accuracy: 0.9438 - op_conv_accuracy: 0.9620 - avg_accuracy: 0.9613\n",
      "Epoch 00231: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6951 - op_main_loss: 0.1648 - op_conv_loss: 0.0985 - avg_loss: 0.1237 - op_main_accuracy: 0.9433 - op_conv_accuracy: 0.9622 - avg_accuracy: 0.9620 - val_loss: 1.1072 - val_op_main_loss: 0.2414 - val_op_conv_loss: 0.3197 - val_avg_loss: 0.2381 - val_op_main_accuracy: 0.8952 - val_op_conv_accuracy: 0.9027 - val_avg_accuracy: 0.9037\n",
      "Epoch 232/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6645 - op_main_loss: 0.1570 - op_conv_loss: 0.0854 - avg_loss: 0.1140 - op_main_accuracy: 0.9479 - op_conv_accuracy: 0.9666 - avg_accuracy: 0.9671\n",
      "Epoch 00232: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6639 - op_main_loss: 0.1568 - op_conv_loss: 0.0852 - avg_loss: 0.1139 - op_main_accuracy: 0.9480 - op_conv_accuracy: 0.9667 - avg_accuracy: 0.9672 - val_loss: 1.1216 - val_op_main_loss: 0.2566 - val_op_conv_loss: 0.3074 - val_avg_loss: 0.2500 - val_op_main_accuracy: 0.8848 - val_op_conv_accuracy: 0.9018 - val_avg_accuracy: 0.9008\n",
      "Epoch 233/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.6929 - op_main_loss: 0.1693 - op_conv_loss: 0.0927 - avg_loss: 0.1235 - op_main_accuracy: 0.9409 - op_conv_accuracy: 0.9629 - avg_accuracy: 0.9603\n",
      "Epoch 00233: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6921 - op_main_loss: 0.1689 - op_conv_loss: 0.0926 - avg_loss: 0.1232 - op_main_accuracy: 0.9409 - op_conv_accuracy: 0.9629 - avg_accuracy: 0.9603 - val_loss: 1.0970 - val_op_main_loss: 0.2426 - val_op_conv_loss: 0.3082 - val_avg_loss: 0.2390 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.8990 - val_avg_accuracy: 0.9046\n",
      "Epoch 234/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/133 [============================>.] - ETA: 0s - loss: 0.6961 - op_main_loss: 0.1666 - op_conv_loss: 0.0981 - avg_loss: 0.1243 - op_main_accuracy: 0.9448 - op_conv_accuracy: 0.9622 - avg_accuracy: 0.9605\n",
      "Epoch 00234: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6941 - op_main_loss: 0.1659 - op_conv_loss: 0.0974 - avg_loss: 0.1237 - op_main_accuracy: 0.9454 - op_conv_accuracy: 0.9624 - avg_accuracy: 0.9608 - val_loss: 1.1516 - val_op_main_loss: 0.2503 - val_op_conv_loss: 0.3396 - val_avg_loss: 0.2543 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.8990 - val_avg_accuracy: 0.8999\n",
      "Epoch 235/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6572 - op_main_loss: 0.1549 - op_conv_loss: 0.0825 - avg_loss: 0.1122 - op_main_accuracy: 0.9505 - op_conv_accuracy: 0.9664 - avg_accuracy: 0.9664\n",
      "Epoch 00235: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6576 - op_main_loss: 0.1550 - op_conv_loss: 0.0826 - avg_loss: 0.1124 - op_main_accuracy: 0.9504 - op_conv_accuracy: 0.9662 - avg_accuracy: 0.9662 - val_loss: 1.1036 - val_op_main_loss: 0.2483 - val_op_conv_loss: 0.3084 - val_avg_loss: 0.2392 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.9112 - val_avg_accuracy: 0.9103\n",
      "Epoch 236/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.6819 - op_main_loss: 0.1580 - op_conv_loss: 0.0965 - avg_loss: 0.1199 - op_main_accuracy: 0.9482 - op_conv_accuracy: 0.9618 - avg_accuracy: 0.9611\n",
      "Epoch 00236: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6816 - op_main_loss: 0.1579 - op_conv_loss: 0.0963 - avg_loss: 0.1198 - op_main_accuracy: 0.9483 - op_conv_accuracy: 0.9620 - avg_accuracy: 0.9610 - val_loss: 1.3984 - val_op_main_loss: 0.2618 - val_op_conv_loss: 0.5246 - val_avg_loss: 0.3048 - val_op_main_accuracy: 0.8886 - val_op_conv_accuracy: 0.8555 - val_avg_accuracy: 0.8725\n",
      "Epoch 237/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.6805 - op_main_loss: 0.1608 - op_conv_loss: 0.0924 - avg_loss: 0.1200 - op_main_accuracy: 0.9423 - op_conv_accuracy: 0.9625 - avg_accuracy: 0.9583\n",
      "Epoch 00237: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6788 - op_main_loss: 0.1603 - op_conv_loss: 0.0917 - avg_loss: 0.1195 - op_main_accuracy: 0.9428 - op_conv_accuracy: 0.9629 - avg_accuracy: 0.9586 - val_loss: 1.1392 - val_op_main_loss: 0.2403 - val_op_conv_loss: 0.3487 - val_avg_loss: 0.2429 - val_op_main_accuracy: 0.8999 - val_op_conv_accuracy: 0.8933 - val_avg_accuracy: 0.8971\n",
      "Epoch 238/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.6645 - op_main_loss: 0.1549 - op_conv_loss: 0.0886 - avg_loss: 0.1141 - op_main_accuracy: 0.9475 - op_conv_accuracy: 0.9676 - avg_accuracy: 0.9671\n",
      "Epoch 00238: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6663 - op_main_loss: 0.1555 - op_conv_loss: 0.0892 - avg_loss: 0.1147 - op_main_accuracy: 0.9473 - op_conv_accuracy: 0.9672 - avg_accuracy: 0.9667 - val_loss: 1.0899 - val_op_main_loss: 0.2476 - val_op_conv_loss: 0.2998 - val_avg_loss: 0.2363 - val_op_main_accuracy: 0.8999 - val_op_conv_accuracy: 0.9141 - val_avg_accuracy: 0.9084\n",
      "Epoch 239/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6785 - op_main_loss: 0.1617 - op_conv_loss: 0.0919 - avg_loss: 0.1193 - op_main_accuracy: 0.9423 - op_conv_accuracy: 0.9667 - avg_accuracy: 0.9627\n",
      "Epoch 00239: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.6785 - op_main_loss: 0.1617 - op_conv_loss: 0.0919 - avg_loss: 0.1193 - op_main_accuracy: 0.9423 - op_conv_accuracy: 0.9667 - avg_accuracy: 0.9627 - val_loss: 1.1629 - val_op_main_loss: 0.2486 - val_op_conv_loss: 0.3581 - val_avg_loss: 0.2511 - val_op_main_accuracy: 0.8961 - val_op_conv_accuracy: 0.9037 - val_avg_accuracy: 0.9027\n",
      "Epoch 240/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6806 - op_main_loss: 0.1620 - op_conv_loss: 0.0934 - avg_loss: 0.1202 - op_main_accuracy: 0.9453 - op_conv_accuracy: 0.9647 - avg_accuracy: 0.9619\n",
      "Epoch 00240: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6810 - op_main_loss: 0.1622 - op_conv_loss: 0.0935 - avg_loss: 0.1204 - op_main_accuracy: 0.9452 - op_conv_accuracy: 0.9646 - avg_accuracy: 0.9617 - val_loss: 1.0871 - val_op_main_loss: 0.2419 - val_op_conv_loss: 0.3043 - val_avg_loss: 0.2360 - val_op_main_accuracy: 0.8999 - val_op_conv_accuracy: 0.9065 - val_avg_accuracy: 0.9056\n",
      "Epoch 241/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6686 - op_main_loss: 0.1587 - op_conv_loss: 0.0888 - avg_loss: 0.1164 - op_main_accuracy: 0.9462 - op_conv_accuracy: 0.9625 - avg_accuracy: 0.9642\n",
      "Epoch 00241: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6689 - op_main_loss: 0.1587 - op_conv_loss: 0.0890 - avg_loss: 0.1166 - op_main_accuracy: 0.9461 - op_conv_accuracy: 0.9622 - avg_accuracy: 0.9638 - val_loss: 1.1667 - val_op_main_loss: 0.2456 - val_op_conv_loss: 0.3586 - val_avg_loss: 0.2578 - val_op_main_accuracy: 0.8924 - val_op_conv_accuracy: 0.8905 - val_avg_accuracy: 0.8971\n",
      "Epoch 242/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6905 - op_main_loss: 0.1638 - op_conv_loss: 0.0984 - avg_loss: 0.1231 - op_main_accuracy: 0.9451 - op_conv_accuracy: 0.9612 - avg_accuracy: 0.9602\n",
      "Epoch 00242: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6900 - op_main_loss: 0.1636 - op_conv_loss: 0.0982 - avg_loss: 0.1230 - op_main_accuracy: 0.9452 - op_conv_accuracy: 0.9612 - avg_accuracy: 0.9603 - val_loss: 1.1297 - val_op_main_loss: 0.2410 - val_op_conv_loss: 0.3367 - val_avg_loss: 0.2461 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.8999 - val_avg_accuracy: 0.9018\n",
      "Epoch 243/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.6796 - op_main_loss: 0.1641 - op_conv_loss: 0.0907 - avg_loss: 0.1193 - op_main_accuracy: 0.9394 - op_conv_accuracy: 0.9637 - avg_accuracy: 0.9633\n",
      "Epoch 00243: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6799 - op_main_loss: 0.1644 - op_conv_loss: 0.0907 - avg_loss: 0.1194 - op_main_accuracy: 0.9388 - op_conv_accuracy: 0.9636 - avg_accuracy: 0.9631 - val_loss: 1.1210 - val_op_main_loss: 0.2561 - val_op_conv_loss: 0.3124 - val_avg_loss: 0.2470 - val_op_main_accuracy: 0.8952 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9018\n",
      "Epoch 244/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.6797 - op_main_loss: 0.1632 - op_conv_loss: 0.0916 - avg_loss: 0.1192 - op_main_accuracy: 0.9430 - op_conv_accuracy: 0.9649 - avg_accuracy: 0.9642\n",
      "Epoch 00244: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6783 - op_main_loss: 0.1628 - op_conv_loss: 0.0911 - avg_loss: 0.1188 - op_main_accuracy: 0.9433 - op_conv_accuracy: 0.9653 - avg_accuracy: 0.9643 - val_loss: 1.0627 - val_op_main_loss: 0.2380 - val_op_conv_loss: 0.2903 - val_avg_loss: 0.2289 - val_op_main_accuracy: 0.8971 - val_op_conv_accuracy: 0.9084 - val_avg_accuracy: 0.9056\n",
      "Epoch 245/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6795 - op_main_loss: 0.1624 - op_conv_loss: 0.0925 - avg_loss: 0.1198 - op_main_accuracy: 0.9433 - op_conv_accuracy: 0.9615 - avg_accuracy: 0.9603\n",
      "Epoch 00245: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6795 - op_main_loss: 0.1624 - op_conv_loss: 0.0925 - avg_loss: 0.1198 - op_main_accuracy: 0.9433 - op_conv_accuracy: 0.9615 - avg_accuracy: 0.9603 - val_loss: 1.1099 - val_op_main_loss: 0.2375 - val_op_conv_loss: 0.3270 - val_avg_loss: 0.2407 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.8961 - val_avg_accuracy: 0.8999\n",
      "Epoch 246/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/133 [============================>.] - ETA: 0s - loss: 0.6599 - op_main_loss: 0.1545 - op_conv_loss: 0.0868 - avg_loss: 0.1137 - op_main_accuracy: 0.9482 - op_conv_accuracy: 0.9647 - avg_accuracy: 0.9626\n",
      "Epoch 00246: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6593 - op_main_loss: 0.1543 - op_conv_loss: 0.0866 - avg_loss: 0.1135 - op_main_accuracy: 0.9483 - op_conv_accuracy: 0.9648 - avg_accuracy: 0.9627 - val_loss: 1.2999 - val_op_main_loss: 0.2766 - val_op_conv_loss: 0.4212 - val_avg_loss: 0.2978 - val_op_main_accuracy: 0.8848 - val_op_conv_accuracy: 0.8754 - val_avg_accuracy: 0.8772\n",
      "Epoch 247/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6974 - op_main_loss: 0.1731 - op_conv_loss: 0.0952 - avg_loss: 0.1250 - op_main_accuracy: 0.9401 - op_conv_accuracy: 0.9675 - avg_accuracy: 0.9635\n",
      "Epoch 00247: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6954 - op_main_loss: 0.1721 - op_conv_loss: 0.0949 - avg_loss: 0.1244 - op_main_accuracy: 0.9405 - op_conv_accuracy: 0.9676 - avg_accuracy: 0.9636 - val_loss: 1.1551 - val_op_main_loss: 0.2421 - val_op_conv_loss: 0.3580 - val_avg_loss: 0.2516 - val_op_main_accuracy: 0.8961 - val_op_conv_accuracy: 0.8857 - val_avg_accuracy: 0.8886\n",
      "Epoch 248/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6664 - op_main_loss: 0.1557 - op_conv_loss: 0.0911 - avg_loss: 0.1158 - op_main_accuracy: 0.9505 - op_conv_accuracy: 0.9608 - avg_accuracy: 0.9637\n",
      "Epoch 00248: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6657 - op_main_loss: 0.1556 - op_conv_loss: 0.0908 - avg_loss: 0.1156 - op_main_accuracy: 0.9501 - op_conv_accuracy: 0.9610 - avg_accuracy: 0.9636 - val_loss: 1.0917 - val_op_main_loss: 0.2404 - val_op_conv_loss: 0.3085 - val_avg_loss: 0.2388 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9027\n",
      "Epoch 249/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6519 - op_main_loss: 0.1548 - op_conv_loss: 0.0817 - avg_loss: 0.1116 - op_main_accuracy: 0.9483 - op_conv_accuracy: 0.9655 - avg_accuracy: 0.9643\n",
      "Epoch 00249: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6519 - op_main_loss: 0.1548 - op_conv_loss: 0.0817 - avg_loss: 0.1116 - op_main_accuracy: 0.9483 - op_conv_accuracy: 0.9655 - avg_accuracy: 0.9643 - val_loss: 1.2504 - val_op_main_loss: 0.2912 - val_op_conv_loss: 0.3648 - val_avg_loss: 0.2908 - val_op_main_accuracy: 0.8829 - val_op_conv_accuracy: 0.8980 - val_avg_accuracy: 0.8933\n",
      "Epoch 250/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.6954 - op_main_loss: 0.1670 - op_conv_loss: 0.1005 - avg_loss: 0.1246 - op_main_accuracy: 0.9387 - op_conv_accuracy: 0.9632 - avg_accuracy: 0.9610\n",
      "Epoch 00250: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6905 - op_main_loss: 0.1653 - op_conv_loss: 0.0988 - avg_loss: 0.1231 - op_main_accuracy: 0.9402 - op_conv_accuracy: 0.9638 - avg_accuracy: 0.9617 - val_loss: 1.0748 - val_op_main_loss: 0.2350 - val_op_conv_loss: 0.3021 - val_avg_loss: 0.2340 - val_op_main_accuracy: 0.8952 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9065\n",
      "Epoch 251/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6851 - op_main_loss: 0.1653 - op_conv_loss: 0.0944 - avg_loss: 0.1212 - op_main_accuracy: 0.9415 - op_conv_accuracy: 0.9626 - avg_accuracy: 0.9607\n",
      "Epoch 00251: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6848 - op_main_loss: 0.1653 - op_conv_loss: 0.0943 - avg_loss: 0.1212 - op_main_accuracy: 0.9414 - op_conv_accuracy: 0.9627 - avg_accuracy: 0.9608 - val_loss: 1.1324 - val_op_main_loss: 0.2560 - val_op_conv_loss: 0.3219 - val_avg_loss: 0.2497 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.9056 - val_avg_accuracy: 0.9027\n",
      "Epoch 252/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6538 - op_main_loss: 0.1520 - op_conv_loss: 0.0856 - avg_loss: 0.1114 - op_main_accuracy: 0.9479 - op_conv_accuracy: 0.9666 - avg_accuracy: 0.9666\n",
      "Epoch 00252: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6532 - op_main_loss: 0.1518 - op_conv_loss: 0.0854 - avg_loss: 0.1112 - op_main_accuracy: 0.9480 - op_conv_accuracy: 0.9667 - avg_accuracy: 0.9667 - val_loss: 1.2267 - val_op_main_loss: 0.2608 - val_op_conv_loss: 0.3899 - val_avg_loss: 0.2716 - val_op_main_accuracy: 0.8933 - val_op_conv_accuracy: 0.8905 - val_avg_accuracy: 0.8933\n",
      "Epoch 253/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6616 - op_main_loss: 0.1579 - op_conv_loss: 0.0848 - avg_loss: 0.1148 - op_main_accuracy: 0.9465 - op_conv_accuracy: 0.9633 - avg_accuracy: 0.9624\n",
      "Epoch 00253: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6615 - op_main_loss: 0.1579 - op_conv_loss: 0.0848 - avg_loss: 0.1148 - op_main_accuracy: 0.9466 - op_conv_accuracy: 0.9634 - avg_accuracy: 0.9624 - val_loss: 1.1520 - val_op_main_loss: 0.2436 - val_op_conv_loss: 0.3506 - val_avg_loss: 0.2541 - val_op_main_accuracy: 0.8942 - val_op_conv_accuracy: 0.8914 - val_avg_accuracy: 0.8971\n",
      "Epoch 254/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6676 - op_main_loss: 0.1583 - op_conv_loss: 0.0899 - avg_loss: 0.1157 - op_main_accuracy: 0.9418 - op_conv_accuracy: 0.9661 - avg_accuracy: 0.9635\n",
      "Epoch 00254: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6673 - op_main_loss: 0.1582 - op_conv_loss: 0.0897 - avg_loss: 0.1156 - op_main_accuracy: 0.9419 - op_conv_accuracy: 0.9662 - avg_accuracy: 0.9636 - val_loss: 1.3248 - val_op_main_loss: 0.2874 - val_op_conv_loss: 0.4266 - val_avg_loss: 0.3070 - val_op_main_accuracy: 0.8857 - val_op_conv_accuracy: 0.8791 - val_avg_accuracy: 0.8839\n",
      "Epoch 255/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.7112 - op_main_loss: 0.1687 - op_conv_loss: 0.1094 - avg_loss: 0.1294 - op_main_accuracy: 0.9404 - op_conv_accuracy: 0.9571 - avg_accuracy: 0.9566\n",
      "Epoch 00255: val_avg_accuracy did not improve from 0.91124\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.7096 - op_main_loss: 0.1681 - op_conv_loss: 0.1089 - avg_loss: 0.1289 - op_main_accuracy: 0.9407 - op_conv_accuracy: 0.9572 - avg_accuracy: 0.9568 - val_loss: 1.0870 - val_op_main_loss: 0.2457 - val_op_conv_loss: 0.2988 - val_avg_loss: 0.2393 - val_op_main_accuracy: 0.8980 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9065\n",
      "Epoch 256/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6644 - op_main_loss: 0.1543 - op_conv_loss: 0.0907 - avg_loss: 0.1158 - op_main_accuracy: 0.9487 - op_conv_accuracy: 0.9622 - avg_accuracy: 0.9622\n",
      "Epoch 00256: val_avg_accuracy improved from 0.91124 to 0.91313, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.6644 - op_main_loss: 0.1543 - op_conv_loss: 0.0907 - avg_loss: 0.1158 - op_main_accuracy: 0.9487 - op_conv_accuracy: 0.9622 - avg_accuracy: 0.9622 - val_loss: 1.0817 - val_op_main_loss: 0.2401 - val_op_conv_loss: 0.2999 - val_avg_loss: 0.2383 - val_op_main_accuracy: 0.9037 - val_op_conv_accuracy: 0.9103 - val_avg_accuracy: 0.9131\n",
      "Epoch 257/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6634 - op_main_loss: 0.1561 - op_conv_loss: 0.0891 - avg_loss: 0.1151 - op_main_accuracy: 0.9493 - op_conv_accuracy: 0.9663 - avg_accuracy: 0.9656\n",
      "Epoch 00257: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6635 - op_main_loss: 0.1564 - op_conv_loss: 0.0888 - avg_loss: 0.1151 - op_main_accuracy: 0.9487 - op_conv_accuracy: 0.9662 - avg_accuracy: 0.9655 - val_loss: 1.1427 - val_op_main_loss: 0.2508 - val_op_conv_loss: 0.3337 - val_avg_loss: 0.2554 - val_op_main_accuracy: 0.8961 - val_op_conv_accuracy: 0.9008 - val_avg_accuracy: 0.9018\n",
      "Epoch 258/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/133 [============================>.] - ETA: 0s - loss: 0.6469 - op_main_loss: 0.1505 - op_conv_loss: 0.0832 - avg_loss: 0.1106 - op_main_accuracy: 0.9484 - op_conv_accuracy: 0.9669 - avg_accuracy: 0.9661\n",
      "Epoch 00258: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6469 - op_main_loss: 0.1504 - op_conv_loss: 0.0833 - avg_loss: 0.1106 - op_main_accuracy: 0.9485 - op_conv_accuracy: 0.9667 - avg_accuracy: 0.9662 - val_loss: 1.1009 - val_op_main_loss: 0.2462 - val_op_conv_loss: 0.3110 - val_avg_loss: 0.2411 - val_op_main_accuracy: 0.8971 - val_op_conv_accuracy: 0.9037 - val_avg_accuracy: 0.9018\n",
      "Epoch 259/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6486 - op_main_loss: 0.1503 - op_conv_loss: 0.0850 - avg_loss: 0.1110 - op_main_accuracy: 0.9512 - op_conv_accuracy: 0.9654 - avg_accuracy: 0.9659\n",
      "Epoch 00259: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6512 - op_main_loss: 0.1512 - op_conv_loss: 0.0858 - avg_loss: 0.1118 - op_main_accuracy: 0.9504 - op_conv_accuracy: 0.9655 - avg_accuracy: 0.9657 - val_loss: 1.2023 - val_op_main_loss: 0.2602 - val_op_conv_loss: 0.3722 - val_avg_loss: 0.2675 - val_op_main_accuracy: 0.8933 - val_op_conv_accuracy: 0.8961 - val_avg_accuracy: 0.9018\n",
      "Epoch 260/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6706 - op_main_loss: 0.1576 - op_conv_loss: 0.0930 - avg_loss: 0.1180 - op_main_accuracy: 0.9464 - op_conv_accuracy: 0.9622 - avg_accuracy: 0.9620\n",
      "Epoch 00260: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6706 - op_main_loss: 0.1576 - op_conv_loss: 0.0930 - avg_loss: 0.1180 - op_main_accuracy: 0.9464 - op_conv_accuracy: 0.9622 - avg_accuracy: 0.9620 - val_loss: 1.0907 - val_op_main_loss: 0.2384 - val_op_conv_loss: 0.3146 - val_avg_loss: 0.2361 - val_op_main_accuracy: 0.8980 - val_op_conv_accuracy: 0.9056 - val_avg_accuracy: 0.9056\n",
      "Epoch 261/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6426 - op_main_loss: 0.1501 - op_conv_loss: 0.0821 - avg_loss: 0.1092 - op_main_accuracy: 0.9490 - op_conv_accuracy: 0.9678 - avg_accuracy: 0.9656\n",
      "Epoch 00261: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6413 - op_main_loss: 0.1497 - op_conv_loss: 0.0816 - avg_loss: 0.1088 - op_main_accuracy: 0.9490 - op_conv_accuracy: 0.9679 - avg_accuracy: 0.9655 - val_loss: 1.0994 - val_op_main_loss: 0.2454 - val_op_conv_loss: 0.3118 - val_avg_loss: 0.2415 - val_op_main_accuracy: 0.8924 - val_op_conv_accuracy: 0.9018 - val_avg_accuracy: 0.9008\n",
      "Epoch 262/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.6358 - op_main_loss: 0.1459 - op_conv_loss: 0.0824 - avg_loss: 0.1071 - op_main_accuracy: 0.9525 - op_conv_accuracy: 0.9704 - avg_accuracy: 0.9685\n",
      "Epoch 00262: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6369 - op_main_loss: 0.1464 - op_conv_loss: 0.0827 - avg_loss: 0.1074 - op_main_accuracy: 0.9518 - op_conv_accuracy: 0.9702 - avg_accuracy: 0.9683 - val_loss: 1.1158 - val_op_main_loss: 0.2477 - val_op_conv_loss: 0.3260 - val_avg_loss: 0.2420 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.9141 - val_avg_accuracy: 0.9093\n",
      "Epoch 263/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.6506 - op_main_loss: 0.1555 - op_conv_loss: 0.0834 - avg_loss: 0.1118 - op_main_accuracy: 0.9473 - op_conv_accuracy: 0.9671 - avg_accuracy: 0.9647\n",
      "Epoch 00263: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6502 - op_main_loss: 0.1552 - op_conv_loss: 0.0835 - avg_loss: 0.1117 - op_main_accuracy: 0.9475 - op_conv_accuracy: 0.9669 - avg_accuracy: 0.9646 - val_loss: 1.0714 - val_op_main_loss: 0.2362 - val_op_conv_loss: 0.3029 - val_avg_loss: 0.2327 - val_op_main_accuracy: 0.9065 - val_op_conv_accuracy: 0.8999 - val_avg_accuracy: 0.9065\n",
      "Epoch 264/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.6685 - op_main_loss: 0.1557 - op_conv_loss: 0.0949 - avg_loss: 0.1178 - op_main_accuracy: 0.9489 - op_conv_accuracy: 0.9627 - avg_accuracy: 0.9637\n",
      "Epoch 00264: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6677 - op_main_loss: 0.1550 - op_conv_loss: 0.0951 - avg_loss: 0.1176 - op_main_accuracy: 0.9490 - op_conv_accuracy: 0.9629 - avg_accuracy: 0.9638 - val_loss: 1.1361 - val_op_main_loss: 0.2512 - val_op_conv_loss: 0.3392 - val_avg_loss: 0.2458 - val_op_main_accuracy: 0.8924 - val_op_conv_accuracy: 0.9084 - val_avg_accuracy: 0.9075\n",
      "Epoch 265/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6373 - op_main_loss: 0.1481 - op_conv_loss: 0.0809 - avg_loss: 0.1085 - op_main_accuracy: 0.9537 - op_conv_accuracy: 0.9681 - avg_accuracy: 0.9683\n",
      "Epoch 00265: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6373 - op_main_loss: 0.1481 - op_conv_loss: 0.0809 - avg_loss: 0.1085 - op_main_accuracy: 0.9537 - op_conv_accuracy: 0.9681 - avg_accuracy: 0.9683 - val_loss: 1.0623 - val_op_main_loss: 0.2434 - val_op_conv_loss: 0.2846 - val_avg_loss: 0.2348 - val_op_main_accuracy: 0.8914 - val_op_conv_accuracy: 0.9075 - val_avg_accuracy: 0.9065\n",
      "Epoch 266/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6426 - op_main_loss: 0.1524 - op_conv_loss: 0.0809 - avg_loss: 0.1100 - op_main_accuracy: 0.9496 - op_conv_accuracy: 0.9721 - avg_accuracy: 0.9692\n",
      "Epoch 00266: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6424 - op_main_loss: 0.1524 - op_conv_loss: 0.0807 - avg_loss: 0.1099 - op_main_accuracy: 0.9497 - op_conv_accuracy: 0.9721 - avg_accuracy: 0.9693 - val_loss: 1.1477 - val_op_main_loss: 0.2680 - val_op_conv_loss: 0.3231 - val_avg_loss: 0.2577 - val_op_main_accuracy: 0.8933 - val_op_conv_accuracy: 0.9093 - val_avg_accuracy: 0.9075\n",
      "Epoch 267/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6423 - op_main_loss: 0.1539 - op_conv_loss: 0.0795 - avg_loss: 0.1099 - op_main_accuracy: 0.9474 - op_conv_accuracy: 0.9697 - avg_accuracy: 0.9678\n",
      "Epoch 00267: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6418 - op_main_loss: 0.1537 - op_conv_loss: 0.0793 - avg_loss: 0.1097 - op_main_accuracy: 0.9475 - op_conv_accuracy: 0.9698 - avg_accuracy: 0.9679 - val_loss: 1.2851 - val_op_main_loss: 0.2914 - val_op_conv_loss: 0.3934 - val_avg_loss: 0.3014 - val_op_main_accuracy: 0.8810 - val_op_conv_accuracy: 0.8886 - val_avg_accuracy: 0.8895\n",
      "Epoch 268/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6588 - op_main_loss: 0.1555 - op_conv_loss: 0.0889 - avg_loss: 0.1153 - op_main_accuracy: 0.9435 - op_conv_accuracy: 0.9646 - avg_accuracy: 0.9612\n",
      "Epoch 00268: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6588 - op_main_loss: 0.1555 - op_conv_loss: 0.0889 - avg_loss: 0.1153 - op_main_accuracy: 0.9435 - op_conv_accuracy: 0.9646 - avg_accuracy: 0.9612 - val_loss: 1.2397 - val_op_main_loss: 0.2820 - val_op_conv_loss: 0.3702 - val_avg_loss: 0.2884 - val_op_main_accuracy: 0.8867 - val_op_conv_accuracy: 0.8867 - val_avg_accuracy: 0.8914\n",
      "Epoch 269/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6539 - op_main_loss: 0.1556 - op_conv_loss: 0.0866 - avg_loss: 0.1132 - op_main_accuracy: 0.9493 - op_conv_accuracy: 0.9685 - avg_accuracy: 0.9678\n",
      "Epoch 00269: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6571 - op_main_loss: 0.1564 - op_conv_loss: 0.0880 - avg_loss: 0.1142 - op_main_accuracy: 0.9490 - op_conv_accuracy: 0.9681 - avg_accuracy: 0.9676 - val_loss: 1.1177 - val_op_main_loss: 0.2398 - val_op_conv_loss: 0.3350 - val_avg_loss: 0.2444 - val_op_main_accuracy: 0.9084 - val_op_conv_accuracy: 0.8961 - val_avg_accuracy: 0.9037\n",
      "Epoch 270/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/133 [============================>.] - ETA: 0s - loss: 0.6441 - op_main_loss: 0.1481 - op_conv_loss: 0.0878 - avg_loss: 0.1102 - op_main_accuracy: 0.9522 - op_conv_accuracy: 0.9639 - avg_accuracy: 0.9639\n",
      "Epoch 00270: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6444 - op_main_loss: 0.1486 - op_conv_loss: 0.0875 - avg_loss: 0.1103 - op_main_accuracy: 0.9523 - op_conv_accuracy: 0.9643 - avg_accuracy: 0.9641 - val_loss: 1.0772 - val_op_main_loss: 0.2395 - val_op_conv_loss: 0.3051 - val_avg_loss: 0.2352 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.8961 - val_avg_accuracy: 0.9018\n",
      "Epoch 271/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.6335 - op_main_loss: 0.1465 - op_conv_loss: 0.0822 - avg_loss: 0.1071 - op_main_accuracy: 0.9542 - op_conv_accuracy: 0.9654 - avg_accuracy: 0.9673\n",
      "Epoch 00271: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6328 - op_main_loss: 0.1463 - op_conv_loss: 0.0819 - avg_loss: 0.1069 - op_main_accuracy: 0.9539 - op_conv_accuracy: 0.9655 - avg_accuracy: 0.9672 - val_loss: 1.3416 - val_op_main_loss: 0.2755 - val_op_conv_loss: 0.4634 - val_avg_loss: 0.3049 - val_op_main_accuracy: 0.8905 - val_op_conv_accuracy: 0.8725 - val_avg_accuracy: 0.8839\n",
      "Epoch 272/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6300 - op_main_loss: 0.1459 - op_conv_loss: 0.0798 - avg_loss: 0.1064 - op_main_accuracy: 0.9542 - op_conv_accuracy: 0.9681 - avg_accuracy: 0.9653\n",
      "Epoch 00272: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6300 - op_main_loss: 0.1459 - op_conv_loss: 0.0798 - avg_loss: 0.1064 - op_main_accuracy: 0.9542 - op_conv_accuracy: 0.9681 - avg_accuracy: 0.9653 - val_loss: 1.1106 - val_op_main_loss: 0.2471 - val_op_conv_loss: 0.3184 - val_avg_loss: 0.2472 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.9008 - val_avg_accuracy: 0.8999\n",
      "Epoch 273/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6378 - op_main_loss: 0.1490 - op_conv_loss: 0.0823 - avg_loss: 0.1089 - op_main_accuracy: 0.9509 - op_conv_accuracy: 0.9705 - avg_accuracy: 0.9686\n",
      "Epoch 00273: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6378 - op_main_loss: 0.1490 - op_conv_loss: 0.0823 - avg_loss: 0.1089 - op_main_accuracy: 0.9509 - op_conv_accuracy: 0.9705 - avg_accuracy: 0.9686 - val_loss: 1.1585 - val_op_main_loss: 0.2646 - val_op_conv_loss: 0.3333 - val_avg_loss: 0.2635 - val_op_main_accuracy: 0.8914 - val_op_conv_accuracy: 0.8961 - val_avg_accuracy: 0.8999\n",
      "Epoch 274/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6672 - op_main_loss: 0.1574 - op_conv_loss: 0.0951 - avg_loss: 0.1179 - op_main_accuracy: 0.9432 - op_conv_accuracy: 0.9624 - avg_accuracy: 0.9581\n",
      "Epoch 00274: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6677 - op_main_loss: 0.1576 - op_conv_loss: 0.0953 - avg_loss: 0.1181 - op_main_accuracy: 0.9431 - op_conv_accuracy: 0.9622 - avg_accuracy: 0.9579 - val_loss: 1.3296 - val_op_main_loss: 0.2860 - val_op_conv_loss: 0.4367 - val_avg_loss: 0.3105 - val_op_main_accuracy: 0.8839 - val_op_conv_accuracy: 0.8735 - val_avg_accuracy: 0.8791\n",
      "Epoch 275/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6593 - op_main_loss: 0.1546 - op_conv_loss: 0.0920 - avg_loss: 0.1155 - op_main_accuracy: 0.9476 - op_conv_accuracy: 0.9627 - avg_accuracy: 0.9623\n",
      "Epoch 00275: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6606 - op_main_loss: 0.1551 - op_conv_loss: 0.0924 - avg_loss: 0.1160 - op_main_accuracy: 0.9475 - op_conv_accuracy: 0.9624 - avg_accuracy: 0.9622 - val_loss: 1.2735 - val_op_main_loss: 0.2806 - val_op_conv_loss: 0.3995 - val_avg_loss: 0.2961 - val_op_main_accuracy: 0.8867 - val_op_conv_accuracy: 0.8829 - val_avg_accuracy: 0.8924\n",
      "Epoch 276/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.6386 - op_main_loss: 0.1475 - op_conv_loss: 0.0853 - avg_loss: 0.1085 - op_main_accuracy: 0.9499 - op_conv_accuracy: 0.9663 - avg_accuracy: 0.9637\n",
      "Epoch 00276: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6401 - op_main_loss: 0.1479 - op_conv_loss: 0.0859 - avg_loss: 0.1091 - op_main_accuracy: 0.9497 - op_conv_accuracy: 0.9655 - avg_accuracy: 0.9631 - val_loss: 1.2016 - val_op_main_loss: 0.2543 - val_op_conv_loss: 0.3812 - val_avg_loss: 0.2689 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.8905 - val_avg_accuracy: 0.8942\n",
      "Epoch 277/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6441 - op_main_loss: 0.1513 - op_conv_loss: 0.0849 - avg_loss: 0.1109 - op_main_accuracy: 0.9490 - op_conv_accuracy: 0.9649 - avg_accuracy: 0.9651\n",
      "Epoch 00277: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6441 - op_main_loss: 0.1511 - op_conv_loss: 0.0851 - avg_loss: 0.1110 - op_main_accuracy: 0.9490 - op_conv_accuracy: 0.9646 - avg_accuracy: 0.9653 - val_loss: 1.1798 - val_op_main_loss: 0.2656 - val_op_conv_loss: 0.3450 - val_avg_loss: 0.2722 - val_op_main_accuracy: 0.8933 - val_op_conv_accuracy: 0.8905 - val_avg_accuracy: 0.8952\n",
      "Epoch 278/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.6254 - op_main_loss: 0.1410 - op_conv_loss: 0.0819 - avg_loss: 0.1055 - op_main_accuracy: 0.9516 - op_conv_accuracy: 0.9680 - avg_accuracy: 0.9680\n",
      "Epoch 00278: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6252 - op_main_loss: 0.1406 - op_conv_loss: 0.0822 - avg_loss: 0.1054 - op_main_accuracy: 0.9523 - op_conv_accuracy: 0.9679 - avg_accuracy: 0.9681 - val_loss: 1.0832 - val_op_main_loss: 0.2405 - val_op_conv_loss: 0.3062 - val_avg_loss: 0.2404 - val_op_main_accuracy: 0.9018 - val_op_conv_accuracy: 0.9027 - val_avg_accuracy: 0.9065\n",
      "Epoch 279/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.6525 - op_main_loss: 0.1520 - op_conv_loss: 0.0908 - avg_loss: 0.1140 - op_main_accuracy: 0.9513 - op_conv_accuracy: 0.9663 - avg_accuracy: 0.9651\n",
      "Epoch 00279: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6544 - op_main_loss: 0.1525 - op_conv_loss: 0.0916 - avg_loss: 0.1146 - op_main_accuracy: 0.9504 - op_conv_accuracy: 0.9662 - avg_accuracy: 0.9650 - val_loss: 1.4664 - val_op_main_loss: 0.2896 - val_op_conv_loss: 0.5469 - val_avg_loss: 0.3342 - val_op_main_accuracy: 0.8763 - val_op_conv_accuracy: 0.8565 - val_avg_accuracy: 0.8669\n",
      "Epoch 280/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6524 - op_main_loss: 0.1556 - op_conv_loss: 0.0876 - avg_loss: 0.1135 - op_main_accuracy: 0.9471 - op_conv_accuracy: 0.9647 - avg_accuracy: 0.9639\n",
      "Epoch 00280: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.6559 - op_main_loss: 0.1562 - op_conv_loss: 0.0895 - avg_loss: 0.1145 - op_main_accuracy: 0.9471 - op_conv_accuracy: 0.9643 - avg_accuracy: 0.9636 - val_loss: 1.0895 - val_op_main_loss: 0.2426 - val_op_conv_loss: 0.3105 - val_avg_loss: 0.2413 - val_op_main_accuracy: 0.8933 - val_op_conv_accuracy: 0.9018 - val_avg_accuracy: 0.9037\n",
      "Epoch 281/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.6419 - op_main_loss: 0.1513 - op_conv_loss: 0.0841 - avg_loss: 0.1106 - op_main_accuracy: 0.9490 - op_conv_accuracy: 0.9673 - avg_accuracy: 0.9661\n",
      "Epoch 00281: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6401 - op_main_loss: 0.1508 - op_conv_loss: 0.0834 - avg_loss: 0.1100 - op_main_accuracy: 0.9494 - op_conv_accuracy: 0.9676 - avg_accuracy: 0.9664 - val_loss: 1.1133 - val_op_main_loss: 0.2477 - val_op_conv_loss: 0.3254 - val_avg_loss: 0.2440 - val_op_main_accuracy: 0.8933 - val_op_conv_accuracy: 0.9065 - val_avg_accuracy: 0.9084\n",
      "Epoch 282/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/133 [============================>.] - ETA: 0s - loss: 0.6336 - op_main_loss: 0.1481 - op_conv_loss: 0.0818 - avg_loss: 0.1079 - op_main_accuracy: 0.9514 - op_conv_accuracy: 0.9700 - avg_accuracy: 0.9675\n",
      "Epoch 00282: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6328 - op_main_loss: 0.1478 - op_conv_loss: 0.0815 - avg_loss: 0.1077 - op_main_accuracy: 0.9516 - op_conv_accuracy: 0.9698 - avg_accuracy: 0.9676 - val_loss: 1.1184 - val_op_main_loss: 0.2403 - val_op_conv_loss: 0.3406 - val_avg_loss: 0.2417 - val_op_main_accuracy: 0.9018 - val_op_conv_accuracy: 0.9056 - val_avg_accuracy: 0.9065\n",
      "Epoch 283/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6380 - op_main_loss: 0.1496 - op_conv_loss: 0.0832 - avg_loss: 0.1098 - op_main_accuracy: 0.9512 - op_conv_accuracy: 0.9683 - avg_accuracy: 0.9661\n",
      "Epoch 00283: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6383 - op_main_loss: 0.1496 - op_conv_loss: 0.0834 - avg_loss: 0.1099 - op_main_accuracy: 0.9518 - op_conv_accuracy: 0.9681 - avg_accuracy: 0.9662 - val_loss: 1.1026 - val_op_main_loss: 0.2452 - val_op_conv_loss: 0.3197 - val_avg_loss: 0.2422 - val_op_main_accuracy: 0.8971 - val_op_conv_accuracy: 0.9008 - val_avg_accuracy: 0.9037\n",
      "Epoch 284/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6268 - op_main_loss: 0.1449 - op_conv_loss: 0.0804 - avg_loss: 0.1059 - op_main_accuracy: 0.9531 - op_conv_accuracy: 0.9680 - avg_accuracy: 0.9683\n",
      "Epoch 00284: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6269 - op_main_loss: 0.1450 - op_conv_loss: 0.0804 - avg_loss: 0.1060 - op_main_accuracy: 0.9532 - op_conv_accuracy: 0.9681 - avg_accuracy: 0.9683 - val_loss: 1.1495 - val_op_main_loss: 0.2493 - val_op_conv_loss: 0.3506 - val_avg_loss: 0.2544 - val_op_main_accuracy: 0.8952 - val_op_conv_accuracy: 0.9027 - val_avg_accuracy: 0.9008\n",
      "Epoch 285/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6183 - op_main_loss: 0.1401 - op_conv_loss: 0.0800 - avg_loss: 0.1032 - op_main_accuracy: 0.9565 - op_conv_accuracy: 0.9702 - avg_accuracy: 0.9683\n",
      "Epoch 00285: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.6183 - op_main_loss: 0.1398 - op_conv_loss: 0.0802 - avg_loss: 0.1032 - op_main_accuracy: 0.9570 - op_conv_accuracy: 0.9698 - avg_accuracy: 0.9683 - val_loss: 1.1035 - val_op_main_loss: 0.2538 - val_op_conv_loss: 0.3127 - val_avg_loss: 0.2426 - val_op_main_accuracy: 0.8914 - val_op_conv_accuracy: 0.8980 - val_avg_accuracy: 0.9065\n",
      "Epoch 286/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.6123 - op_main_loss: 0.1424 - op_conv_loss: 0.0740 - avg_loss: 0.1017 - op_main_accuracy: 0.9554 - op_conv_accuracy: 0.9740 - avg_accuracy: 0.9707\n",
      "Epoch 00286: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6112 - op_main_loss: 0.1419 - op_conv_loss: 0.0737 - avg_loss: 0.1014 - op_main_accuracy: 0.9551 - op_conv_accuracy: 0.9740 - avg_accuracy: 0.9707 - val_loss: 1.2011 - val_op_main_loss: 0.2602 - val_op_conv_loss: 0.3795 - val_avg_loss: 0.2676 - val_op_main_accuracy: 0.8952 - val_op_conv_accuracy: 0.8942 - val_avg_accuracy: 0.9008\n",
      "Epoch 287/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6444 - op_main_loss: 0.1484 - op_conv_loss: 0.0904 - avg_loss: 0.1117 - op_main_accuracy: 0.9496 - op_conv_accuracy: 0.9652 - avg_accuracy: 0.9643\n",
      "Epoch 00287: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.6443 - op_main_loss: 0.1485 - op_conv_loss: 0.0902 - avg_loss: 0.1116 - op_main_accuracy: 0.9494 - op_conv_accuracy: 0.9653 - avg_accuracy: 0.9643 - val_loss: 1.6289 - val_op_main_loss: 0.3042 - val_op_conv_loss: 0.6634 - val_avg_loss: 0.3672 - val_op_main_accuracy: 0.8782 - val_op_conv_accuracy: 0.8404 - val_avg_accuracy: 0.8508\n",
      "Epoch 288/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6829 - op_main_loss: 0.1659 - op_conv_loss: 0.1005 - avg_loss: 0.1229 - op_main_accuracy: 0.9425 - op_conv_accuracy: 0.9599 - avg_accuracy: 0.9615\n",
      "Epoch 00288: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 0.6838 - op_main_loss: 0.1658 - op_conv_loss: 0.1013 - avg_loss: 0.1231 - op_main_accuracy: 0.9423 - op_conv_accuracy: 0.9596 - avg_accuracy: 0.9612 - val_loss: 1.0919 - val_op_main_loss: 0.2497 - val_op_conv_loss: 0.3082 - val_avg_loss: 0.2404 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.9093 - val_avg_accuracy: 0.9093\n",
      "Epoch 289/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7718 - op_main_loss: 0.1978 - op_conv_loss: 0.1301 - avg_loss: 0.1488 - op_main_accuracy: 0.9265 - op_conv_accuracy: 0.9490 - avg_accuracy: 0.9509\n",
      "Epoch 00289: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.7718 - op_main_loss: 0.1978 - op_conv_loss: 0.1301 - avg_loss: 0.1488 - op_main_accuracy: 0.9265 - op_conv_accuracy: 0.9490 - avg_accuracy: 0.9509 - val_loss: 1.0613 - val_op_main_loss: 0.2296 - val_op_conv_loss: 0.3077 - val_avg_loss: 0.2286 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.9027 - val_avg_accuracy: 0.9027\n",
      "Epoch 290/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6297 - op_main_loss: 0.1467 - op_conv_loss: 0.0802 - avg_loss: 0.1072 - op_main_accuracy: 0.9511 - op_conv_accuracy: 0.9683 - avg_accuracy: 0.9674\n",
      "Epoch 00290: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6297 - op_main_loss: 0.1467 - op_conv_loss: 0.0802 - avg_loss: 0.1072 - op_main_accuracy: 0.9511 - op_conv_accuracy: 0.9683 - avg_accuracy: 0.9674 - val_loss: 1.0921 - val_op_main_loss: 0.2363 - val_op_conv_loss: 0.3220 - val_avg_loss: 0.2383 - val_op_main_accuracy: 0.8971 - val_op_conv_accuracy: 0.8961 - val_avg_accuracy: 0.9008\n",
      "Epoch 291/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6076 - op_main_loss: 0.1405 - op_conv_loss: 0.0718 - avg_loss: 0.0999 - op_main_accuracy: 0.9550 - op_conv_accuracy: 0.9719 - avg_accuracy: 0.9702\n",
      "Epoch 00291: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6067 - op_main_loss: 0.1402 - op_conv_loss: 0.0715 - avg_loss: 0.0996 - op_main_accuracy: 0.9551 - op_conv_accuracy: 0.9721 - avg_accuracy: 0.9702 - val_loss: 1.0978 - val_op_main_loss: 0.2383 - val_op_conv_loss: 0.3249 - val_avg_loss: 0.2394 - val_op_main_accuracy: 0.9046 - val_op_conv_accuracy: 0.9037 - val_avg_accuracy: 0.9056\n",
      "Epoch 292/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6152 - op_main_loss: 0.1429 - op_conv_loss: 0.0752 - avg_loss: 0.1024 - op_main_accuracy: 0.9538 - op_conv_accuracy: 0.9724 - avg_accuracy: 0.9680\n",
      "Epoch 00292: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6162 - op_main_loss: 0.1435 - op_conv_loss: 0.0754 - avg_loss: 0.1026 - op_main_accuracy: 0.9537 - op_conv_accuracy: 0.9724 - avg_accuracy: 0.9674 - val_loss: 1.4106 - val_op_main_loss: 0.2971 - val_op_conv_loss: 0.4890 - val_avg_loss: 0.3302 - val_op_main_accuracy: 0.8820 - val_op_conv_accuracy: 0.8678 - val_avg_accuracy: 0.8791\n",
      "Epoch 293/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6366 - op_main_loss: 0.1480 - op_conv_loss: 0.0856 - avg_loss: 0.1090 - op_main_accuracy: 0.9512 - op_conv_accuracy: 0.9678 - avg_accuracy: 0.9680\n",
      "Epoch 00293: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6365 - op_main_loss: 0.1475 - op_conv_loss: 0.0860 - avg_loss: 0.1089 - op_main_accuracy: 0.9516 - op_conv_accuracy: 0.9676 - avg_accuracy: 0.9679 - val_loss: 1.0623 - val_op_main_loss: 0.2328 - val_op_conv_loss: 0.3029 - val_avg_loss: 0.2328 - val_op_main_accuracy: 0.9056 - val_op_conv_accuracy: 0.9093 - val_avg_accuracy: 0.9084\n",
      "Epoch 294/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/133 [============================>.] - ETA: 0s - loss: 0.6291 - op_main_loss: 0.1477 - op_conv_loss: 0.0807 - avg_loss: 0.1069 - op_main_accuracy: 0.9474 - op_conv_accuracy: 0.9675 - avg_accuracy: 0.9668\n",
      "Epoch 00294: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6306 - op_main_loss: 0.1489 - op_conv_loss: 0.0805 - avg_loss: 0.1073 - op_main_accuracy: 0.9466 - op_conv_accuracy: 0.9674 - avg_accuracy: 0.9667 - val_loss: 1.3777 - val_op_main_loss: 0.2976 - val_op_conv_loss: 0.4798 - val_avg_loss: 0.3058 - val_op_main_accuracy: 0.8895 - val_op_conv_accuracy: 0.8905 - val_avg_accuracy: 0.8990\n",
      "Epoch 295/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6685 - op_main_loss: 0.1595 - op_conv_loss: 0.0958 - avg_loss: 0.1191 - op_main_accuracy: 0.9441 - op_conv_accuracy: 0.9626 - avg_accuracy: 0.9633\n",
      "Epoch 00295: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6680 - op_main_loss: 0.1593 - op_conv_loss: 0.0956 - avg_loss: 0.1189 - op_main_accuracy: 0.9442 - op_conv_accuracy: 0.9627 - avg_accuracy: 0.9634 - val_loss: 1.1050 - val_op_main_loss: 0.2462 - val_op_conv_loss: 0.3173 - val_avg_loss: 0.2471 - val_op_main_accuracy: 0.8961 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9075\n",
      "Epoch 296/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6114 - op_main_loss: 0.1394 - op_conv_loss: 0.0760 - avg_loss: 0.1018 - op_main_accuracy: 0.9545 - op_conv_accuracy: 0.9699 - avg_accuracy: 0.9697\n",
      "Epoch 00296: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6115 - op_main_loss: 0.1396 - op_conv_loss: 0.0759 - avg_loss: 0.1019 - op_main_accuracy: 0.9544 - op_conv_accuracy: 0.9700 - avg_accuracy: 0.9698 - val_loss: 1.1267 - val_op_main_loss: 0.2377 - val_op_conv_loss: 0.3535 - val_avg_loss: 0.2413 - val_op_main_accuracy: 0.8999 - val_op_conv_accuracy: 0.8990 - val_avg_accuracy: 0.9084\n",
      "Epoch 297/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.6166 - op_main_loss: 0.1415 - op_conv_loss: 0.0778 - avg_loss: 0.1030 - op_main_accuracy: 0.9542 - op_conv_accuracy: 0.9721 - avg_accuracy: 0.9704\n",
      "Epoch 00297: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6163 - op_main_loss: 0.1413 - op_conv_loss: 0.0778 - avg_loss: 0.1030 - op_main_accuracy: 0.9544 - op_conv_accuracy: 0.9721 - avg_accuracy: 0.9705 - val_loss: 1.1269 - val_op_main_loss: 0.2506 - val_op_conv_loss: 0.3331 - val_avg_loss: 0.2493 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9046\n",
      "Epoch 298/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.6473 - op_main_loss: 0.1507 - op_conv_loss: 0.0895 - avg_loss: 0.1129 - op_main_accuracy: 0.9467 - op_conv_accuracy: 0.9620 - avg_accuracy: 0.9629\n",
      "Epoch 00298: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6474 - op_main_loss: 0.1515 - op_conv_loss: 0.0888 - avg_loss: 0.1129 - op_main_accuracy: 0.9466 - op_conv_accuracy: 0.9622 - avg_accuracy: 0.9631 - val_loss: 1.0469 - val_op_main_loss: 0.2327 - val_op_conv_loss: 0.2910 - val_avg_loss: 0.2289 - val_op_main_accuracy: 0.9065 - val_op_conv_accuracy: 0.9056 - val_avg_accuracy: 0.9093\n",
      "Epoch 299/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.6234 - op_main_loss: 0.1453 - op_conv_loss: 0.0783 - avg_loss: 0.1058 - op_main_accuracy: 0.9523 - op_conv_accuracy: 0.9688 - avg_accuracy: 0.9673\n",
      "Epoch 00299: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6231 - op_main_loss: 0.1452 - op_conv_loss: 0.0780 - avg_loss: 0.1057 - op_main_accuracy: 0.9525 - op_conv_accuracy: 0.9690 - avg_accuracy: 0.9674 - val_loss: 1.1141 - val_op_main_loss: 0.2465 - val_op_conv_loss: 0.3301 - val_avg_loss: 0.2434 - val_op_main_accuracy: 0.8980 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9056\n",
      "Epoch 300/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6548 - op_main_loss: 0.1523 - op_conv_loss: 0.0944 - avg_loss: 0.1145 - op_main_accuracy: 0.9468 - op_conv_accuracy: 0.9641 - avg_accuracy: 0.9627\n",
      "Epoch 00300: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.6548 - op_main_loss: 0.1523 - op_conv_loss: 0.0944 - avg_loss: 0.1145 - op_main_accuracy: 0.9468 - op_conv_accuracy: 0.9641 - avg_accuracy: 0.9627 - val_loss: 1.0905 - val_op_main_loss: 0.2403 - val_op_conv_loss: 0.3139 - val_avg_loss: 0.2429 - val_op_main_accuracy: 0.8971 - val_op_conv_accuracy: 0.8980 - val_avg_accuracy: 0.8999\n",
      "Epoch 301/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.6232 - op_main_loss: 0.1444 - op_conv_loss: 0.0798 - avg_loss: 0.1055 - op_main_accuracy: 0.9535 - op_conv_accuracy: 0.9711 - avg_accuracy: 0.9680\n",
      "Epoch 00301: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6219 - op_main_loss: 0.1439 - op_conv_loss: 0.0794 - avg_loss: 0.1051 - op_main_accuracy: 0.9537 - op_conv_accuracy: 0.9714 - avg_accuracy: 0.9683 - val_loss: 1.1652 - val_op_main_loss: 0.2459 - val_op_conv_loss: 0.3681 - val_avg_loss: 0.2578 - val_op_main_accuracy: 0.8933 - val_op_conv_accuracy: 0.8952 - val_avg_accuracy: 0.8999\n",
      "Epoch 302/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6273 - op_main_loss: 0.1444 - op_conv_loss: 0.0824 - avg_loss: 0.1073 - op_main_accuracy: 0.9534 - op_conv_accuracy: 0.9651 - avg_accuracy: 0.9613\n",
      "Epoch 00302: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6249 - op_main_loss: 0.1435 - op_conv_loss: 0.0816 - avg_loss: 0.1065 - op_main_accuracy: 0.9534 - op_conv_accuracy: 0.9657 - avg_accuracy: 0.9620 - val_loss: 1.1789 - val_op_main_loss: 0.2592 - val_op_conv_loss: 0.3604 - val_avg_loss: 0.2661 - val_op_main_accuracy: 0.8867 - val_op_conv_accuracy: 0.8952 - val_avg_accuracy: 0.8961\n",
      "Epoch 303/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.6103 - op_main_loss: 0.1370 - op_conv_loss: 0.0788 - avg_loss: 0.1015 - op_main_accuracy: 0.9549 - op_conv_accuracy: 0.9680 - avg_accuracy: 0.9683\n",
      "Epoch 00303: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6124 - op_main_loss: 0.1378 - op_conv_loss: 0.0794 - avg_loss: 0.1023 - op_main_accuracy: 0.9546 - op_conv_accuracy: 0.9676 - avg_accuracy: 0.9679 - val_loss: 1.1134 - val_op_main_loss: 0.2524 - val_op_conv_loss: 0.3215 - val_avg_loss: 0.2464 - val_op_main_accuracy: 0.8980 - val_op_conv_accuracy: 0.9122 - val_avg_accuracy: 0.9084\n",
      "Epoch 304/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6126 - op_main_loss: 0.1404 - op_conv_loss: 0.0774 - avg_loss: 0.1024 - op_main_accuracy: 0.9562 - op_conv_accuracy: 0.9695 - avg_accuracy: 0.9699\n",
      "Epoch 00304: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6126 - op_main_loss: 0.1405 - op_conv_loss: 0.0773 - avg_loss: 0.1023 - op_main_accuracy: 0.9560 - op_conv_accuracy: 0.9695 - avg_accuracy: 0.9700 - val_loss: 1.2190 - val_op_main_loss: 0.2461 - val_op_conv_loss: 0.4124 - val_avg_loss: 0.2683 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.8839 - val_avg_accuracy: 0.8933\n",
      "Epoch 305/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.6328 - op_main_loss: 0.1465 - op_conv_loss: 0.0861 - avg_loss: 0.1085 - op_main_accuracy: 0.9504 - op_conv_accuracy: 0.9676 - avg_accuracy: 0.9659\n",
      "Epoch 00305: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6316 - op_main_loss: 0.1462 - op_conv_loss: 0.0856 - avg_loss: 0.1081 - op_main_accuracy: 0.9506 - op_conv_accuracy: 0.9679 - avg_accuracy: 0.9660 - val_loss: 1.1585 - val_op_main_loss: 0.2656 - val_op_conv_loss: 0.3362 - val_avg_loss: 0.2655 - val_op_main_accuracy: 0.8905 - val_op_conv_accuracy: 0.8971 - val_avg_accuracy: 0.8961\n",
      "Epoch 306/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/133 [============================>.] - ETA: 0s - loss: 0.6090 - op_main_loss: 0.1421 - op_conv_loss: 0.0738 - avg_loss: 0.1018 - op_main_accuracy: 0.9520 - op_conv_accuracy: 0.9712 - avg_accuracy: 0.9685\n",
      "Epoch 00306: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6077 - op_main_loss: 0.1415 - op_conv_loss: 0.0735 - avg_loss: 0.1014 - op_main_accuracy: 0.9525 - op_conv_accuracy: 0.9714 - avg_accuracy: 0.9688 - val_loss: 1.0683 - val_op_main_loss: 0.2353 - val_op_conv_loss: 0.3081 - val_avg_loss: 0.2334 - val_op_main_accuracy: 0.9075 - val_op_conv_accuracy: 0.9150 - val_avg_accuracy: 0.9112\n",
      "Epoch 307/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6357 - op_main_loss: 0.1483 - op_conv_loss: 0.0863 - avg_loss: 0.1098 - op_main_accuracy: 0.9500 - op_conv_accuracy: 0.9683 - avg_accuracy: 0.9650\n",
      "Epoch 00307: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6356 - op_main_loss: 0.1483 - op_conv_loss: 0.0863 - avg_loss: 0.1097 - op_main_accuracy: 0.9501 - op_conv_accuracy: 0.9683 - avg_accuracy: 0.9650 - val_loss: 1.1687 - val_op_main_loss: 0.2504 - val_op_conv_loss: 0.3666 - val_avg_loss: 0.2609 - val_op_main_accuracy: 0.8942 - val_op_conv_accuracy: 0.9008 - val_avg_accuracy: 0.8980\n",
      "Epoch 308/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6193 - op_main_loss: 0.1449 - op_conv_loss: 0.0789 - avg_loss: 0.1049 - op_main_accuracy: 0.9500 - op_conv_accuracy: 0.9692 - avg_accuracy: 0.9671\n",
      "Epoch 00308: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6192 - op_main_loss: 0.1449 - op_conv_loss: 0.0788 - avg_loss: 0.1048 - op_main_accuracy: 0.9501 - op_conv_accuracy: 0.9693 - avg_accuracy: 0.9672 - val_loss: 1.1036 - val_op_main_loss: 0.2393 - val_op_conv_loss: 0.3342 - val_avg_loss: 0.2391 - val_op_main_accuracy: 0.8999 - val_op_conv_accuracy: 0.8999 - val_avg_accuracy: 0.9056\n",
      "Epoch 309/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.6139 - op_main_loss: 0.1422 - op_conv_loss: 0.0779 - avg_loss: 0.1030 - op_main_accuracy: 0.9542 - op_conv_accuracy: 0.9717 - avg_accuracy: 0.9692\n",
      "Epoch 00309: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6136 - op_main_loss: 0.1423 - op_conv_loss: 0.0778 - avg_loss: 0.1028 - op_main_accuracy: 0.9546 - op_conv_accuracy: 0.9719 - avg_accuracy: 0.9693 - val_loss: 1.0919 - val_op_main_loss: 0.2387 - val_op_conv_loss: 0.3253 - val_avg_loss: 0.2380 - val_op_main_accuracy: 0.8971 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9112\n",
      "Epoch 310/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6210 - op_main_loss: 0.1448 - op_conv_loss: 0.0803 - avg_loss: 0.1058 - op_main_accuracy: 0.9519 - op_conv_accuracy: 0.9678 - avg_accuracy: 0.9654\n",
      "Epoch 00310: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6237 - op_main_loss: 0.1459 - op_conv_loss: 0.0810 - avg_loss: 0.1067 - op_main_accuracy: 0.9511 - op_conv_accuracy: 0.9672 - avg_accuracy: 0.9648 - val_loss: 1.1170 - val_op_main_loss: 0.2453 - val_op_conv_loss: 0.3344 - val_avg_loss: 0.2470 - val_op_main_accuracy: 0.8961 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.8999\n",
      "Epoch 311/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6285 - op_main_loss: 0.1447 - op_conv_loss: 0.0860 - avg_loss: 0.1075 - op_main_accuracy: 0.9498 - op_conv_accuracy: 0.9661 - avg_accuracy: 0.9661\n",
      "Epoch 00311: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.6282 - op_main_loss: 0.1447 - op_conv_loss: 0.0858 - avg_loss: 0.1074 - op_main_accuracy: 0.9499 - op_conv_accuracy: 0.9662 - avg_accuracy: 0.9662 - val_loss: 1.2306 - val_op_main_loss: 0.2676 - val_op_conv_loss: 0.4012 - val_avg_loss: 0.2712 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.9027 - val_avg_accuracy: 0.9027\n",
      "Epoch 312/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6200 - op_main_loss: 0.1433 - op_conv_loss: 0.0817 - avg_loss: 0.1047 - op_main_accuracy: 0.9506 - op_conv_accuracy: 0.9714 - avg_accuracy: 0.9693\n",
      "Epoch 00312: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.6200 - op_main_loss: 0.1433 - op_conv_loss: 0.0817 - avg_loss: 0.1047 - op_main_accuracy: 0.9506 - op_conv_accuracy: 0.9714 - avg_accuracy: 0.9693 - val_loss: 1.0680 - val_op_main_loss: 0.2355 - val_op_conv_loss: 0.3091 - val_avg_loss: 0.2332 - val_op_main_accuracy: 0.8980 - val_op_conv_accuracy: 0.9093 - val_avg_accuracy: 0.9046\n",
      "Epoch 313/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6436 - op_main_loss: 0.1476 - op_conv_loss: 0.0942 - avg_loss: 0.1123 - op_main_accuracy: 0.9509 - op_conv_accuracy: 0.9627 - avg_accuracy: 0.9643\n",
      "Epoch 00313: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.6436 - op_main_loss: 0.1476 - op_conv_loss: 0.0942 - avg_loss: 0.1123 - op_main_accuracy: 0.9509 - op_conv_accuracy: 0.9627 - avg_accuracy: 0.9643 - val_loss: 1.0817 - val_op_main_loss: 0.2358 - val_op_conv_loss: 0.3195 - val_avg_loss: 0.2370 - val_op_main_accuracy: 0.9018 - val_op_conv_accuracy: 0.9075 - val_avg_accuracy: 0.9056\n",
      "Epoch 314/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.6200 - op_main_loss: 0.1464 - op_conv_loss: 0.0791 - avg_loss: 0.1054 - op_main_accuracy: 0.9473 - op_conv_accuracy: 0.9709 - avg_accuracy: 0.9697\n",
      "Epoch 00314: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.6196 - op_main_loss: 0.1463 - op_conv_loss: 0.0789 - avg_loss: 0.1052 - op_main_accuracy: 0.9473 - op_conv_accuracy: 0.9709 - avg_accuracy: 0.9698 - val_loss: 1.1130 - val_op_main_loss: 0.2561 - val_op_conv_loss: 0.3195 - val_avg_loss: 0.2479 - val_op_main_accuracy: 0.8914 - val_op_conv_accuracy: 0.9027 - val_avg_accuracy: 0.9037\n",
      "Epoch 315/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6443 - op_main_loss: 0.1494 - op_conv_loss: 0.0928 - avg_loss: 0.1128 - op_main_accuracy: 0.9482 - op_conv_accuracy: 0.9645 - avg_accuracy: 0.9650\n",
      "Epoch 00315: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.6451 - op_main_loss: 0.1499 - op_conv_loss: 0.0929 - avg_loss: 0.1130 - op_main_accuracy: 0.9475 - op_conv_accuracy: 0.9646 - avg_accuracy: 0.9648 - val_loss: 1.1417 - val_op_main_loss: 0.2409 - val_op_conv_loss: 0.3628 - val_avg_loss: 0.2488 - val_op_main_accuracy: 0.9037 - val_op_conv_accuracy: 0.8980 - val_avg_accuracy: 0.9037\n",
      "Epoch 316/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6005 - op_main_loss: 0.1386 - op_conv_loss: 0.0727 - avg_loss: 0.0998 - op_main_accuracy: 0.9534 - op_conv_accuracy: 0.9742 - avg_accuracy: 0.9716\n",
      "Epoch 00316: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6006 - op_main_loss: 0.1387 - op_conv_loss: 0.0726 - avg_loss: 0.0999 - op_main_accuracy: 0.9532 - op_conv_accuracy: 0.9742 - avg_accuracy: 0.9716 - val_loss: 1.1828 - val_op_main_loss: 0.2475 - val_op_conv_loss: 0.3816 - val_avg_loss: 0.2644 - val_op_main_accuracy: 0.8933 - val_op_conv_accuracy: 0.8914 - val_avg_accuracy: 0.8942\n",
      "Epoch 317/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.6433 - op_main_loss: 0.1529 - op_conv_loss: 0.0884 - avg_loss: 0.1132 - op_main_accuracy: 0.9463 - op_conv_accuracy: 0.9656 - avg_accuracy: 0.9635\n",
      "Epoch 00317: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.6438 - op_main_loss: 0.1529 - op_conv_loss: 0.0888 - avg_loss: 0.1134 - op_main_accuracy: 0.9464 - op_conv_accuracy: 0.9655 - avg_accuracy: 0.9631 - val_loss: 1.1057 - val_op_main_loss: 0.2356 - val_op_conv_loss: 0.3402 - val_avg_loss: 0.2412 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.8990 - val_avg_accuracy: 0.9065\n",
      "Epoch 318/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - ETA: 0s - loss: 0.6119 - op_main_loss: 0.1391 - op_conv_loss: 0.0809 - avg_loss: 0.1029 - op_main_accuracy: 0.9527 - op_conv_accuracy: 0.9672 - avg_accuracy: 0.9662\n",
      "Epoch 00318: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.6119 - op_main_loss: 0.1391 - op_conv_loss: 0.0809 - avg_loss: 0.1029 - op_main_accuracy: 0.9527 - op_conv_accuracy: 0.9672 - avg_accuracy: 0.9662 - val_loss: 1.0526 - val_op_main_loss: 0.2313 - val_op_conv_loss: 0.3018 - val_avg_loss: 0.2304 - val_op_main_accuracy: 0.9075 - val_op_conv_accuracy: 0.9075 - val_avg_accuracy: 0.9075\n",
      "Epoch 319/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5893 - op_main_loss: 0.1320 - op_conv_loss: 0.0717 - avg_loss: 0.0965 - op_main_accuracy: 0.9565 - op_conv_accuracy: 0.9702 - avg_accuracy: 0.9702\n",
      "Epoch 00319: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.5921 - op_main_loss: 0.1330 - op_conv_loss: 0.0727 - avg_loss: 0.0974 - op_main_accuracy: 0.9556 - op_conv_accuracy: 0.9695 - avg_accuracy: 0.9695 - val_loss: 1.0645 - val_op_main_loss: 0.2353 - val_op_conv_loss: 0.3040 - val_avg_loss: 0.2362 - val_op_main_accuracy: 0.9018 - val_op_conv_accuracy: 0.9065 - val_avg_accuracy: 0.9103\n",
      "Epoch 320/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6423 - op_main_loss: 0.1522 - op_conv_loss: 0.0887 - avg_loss: 0.1124 - op_main_accuracy: 0.9459 - op_conv_accuracy: 0.9653 - avg_accuracy: 0.9636\n",
      "Epoch 00320: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6423 - op_main_loss: 0.1522 - op_conv_loss: 0.0887 - avg_loss: 0.1124 - op_main_accuracy: 0.9459 - op_conv_accuracy: 0.9653 - avg_accuracy: 0.9636 - val_loss: 1.0805 - val_op_main_loss: 0.2339 - val_op_conv_loss: 0.3189 - val_avg_loss: 0.2389 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.9027 - val_avg_accuracy: 0.8980\n",
      "Epoch 321/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.6150 - op_main_loss: 0.1411 - op_conv_loss: 0.0812 - avg_loss: 0.1039 - op_main_accuracy: 0.9506 - op_conv_accuracy: 0.9654 - avg_accuracy: 0.9654\n",
      "Epoch 00321: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6201 - op_main_loss: 0.1420 - op_conv_loss: 0.0839 - avg_loss: 0.1054 - op_main_accuracy: 0.9499 - op_conv_accuracy: 0.9648 - avg_accuracy: 0.9648 - val_loss: 1.1804 - val_op_main_loss: 0.2599 - val_op_conv_loss: 0.3589 - val_avg_loss: 0.2727 - val_op_main_accuracy: 0.8942 - val_op_conv_accuracy: 0.8905 - val_avg_accuracy: 0.8961\n",
      "Epoch 322/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6352 - op_main_loss: 0.1477 - op_conv_loss: 0.0889 - avg_loss: 0.1101 - op_main_accuracy: 0.9480 - op_conv_accuracy: 0.9624 - avg_accuracy: 0.9636\n",
      "Epoch 00322: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6352 - op_main_loss: 0.1477 - op_conv_loss: 0.0889 - avg_loss: 0.1101 - op_main_accuracy: 0.9480 - op_conv_accuracy: 0.9624 - avg_accuracy: 0.9636 - val_loss: 1.2159 - val_op_main_loss: 0.2860 - val_op_conv_loss: 0.3563 - val_avg_loss: 0.2854 - val_op_main_accuracy: 0.8848 - val_op_conv_accuracy: 0.8980 - val_avg_accuracy: 0.8952\n",
      "Epoch 323/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6438 - op_main_loss: 0.1544 - op_conv_loss: 0.0874 - avg_loss: 0.1135 - op_main_accuracy: 0.9480 - op_conv_accuracy: 0.9683 - avg_accuracy: 0.9664\n",
      "Epoch 00323: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6438 - op_main_loss: 0.1544 - op_conv_loss: 0.0874 - avg_loss: 0.1135 - op_main_accuracy: 0.9480 - op_conv_accuracy: 0.9683 - avg_accuracy: 0.9664 - val_loss: 1.7637 - val_op_main_loss: 0.4025 - val_op_conv_loss: 0.6309 - val_avg_loss: 0.4415 - val_op_main_accuracy: 0.8461 - val_op_conv_accuracy: 0.8414 - val_avg_accuracy: 0.8423\n",
      "Epoch 324/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.6323 - op_main_loss: 0.1441 - op_conv_loss: 0.0891 - avg_loss: 0.1090 - op_main_accuracy: 0.9501 - op_conv_accuracy: 0.9637 - avg_accuracy: 0.9644\n",
      "Epoch 00324: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6309 - op_main_loss: 0.1437 - op_conv_loss: 0.0886 - avg_loss: 0.1086 - op_main_accuracy: 0.9501 - op_conv_accuracy: 0.9636 - avg_accuracy: 0.9643 - val_loss: 1.1029 - val_op_main_loss: 0.2421 - val_op_conv_loss: 0.3249 - val_avg_loss: 0.2454 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.9037 - val_avg_accuracy: 0.9084\n",
      "Epoch 325/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.6028 - op_main_loss: 0.1385 - op_conv_loss: 0.0741 - avg_loss: 0.1001 - op_main_accuracy: 0.9557 - op_conv_accuracy: 0.9702 - avg_accuracy: 0.9678\n",
      "Epoch 00325: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6029 - op_main_loss: 0.1389 - op_conv_loss: 0.0739 - avg_loss: 0.1002 - op_main_accuracy: 0.9549 - op_conv_accuracy: 0.9702 - avg_accuracy: 0.9679 - val_loss: 1.0850 - val_op_main_loss: 0.2349 - val_op_conv_loss: 0.3247 - val_avg_loss: 0.2361 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.9056 - val_avg_accuracy: 0.9056\n",
      "Epoch 326/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.6291 - op_main_loss: 0.1469 - op_conv_loss: 0.0841 - avg_loss: 0.1079 - op_main_accuracy: 0.9496 - op_conv_accuracy: 0.9658 - avg_accuracy: 0.9654\n",
      "Epoch 00326: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6279 - op_main_loss: 0.1467 - op_conv_loss: 0.0835 - avg_loss: 0.1075 - op_main_accuracy: 0.9499 - op_conv_accuracy: 0.9660 - avg_accuracy: 0.9653 - val_loss: 1.0921 - val_op_main_loss: 0.2349 - val_op_conv_loss: 0.3265 - val_avg_loss: 0.2402 - val_op_main_accuracy: 0.9027 - val_op_conv_accuracy: 0.9093 - val_avg_accuracy: 0.9093\n",
      "Epoch 327/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.6030 - op_main_loss: 0.1360 - op_conv_loss: 0.0770 - avg_loss: 0.1000 - op_main_accuracy: 0.9554 - op_conv_accuracy: 0.9697 - avg_accuracy: 0.9683\n",
      "Epoch 00327: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6021 - op_main_loss: 0.1356 - op_conv_loss: 0.0768 - avg_loss: 0.0998 - op_main_accuracy: 0.9551 - op_conv_accuracy: 0.9695 - avg_accuracy: 0.9679 - val_loss: 1.0738 - val_op_main_loss: 0.2315 - val_op_conv_loss: 0.3197 - val_avg_loss: 0.2329 - val_op_main_accuracy: 0.9027 - val_op_conv_accuracy: 0.9103 - val_avg_accuracy: 0.9122\n",
      "Epoch 328/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6076 - op_main_loss: 0.1382 - op_conv_loss: 0.0786 - avg_loss: 0.1013 - op_main_accuracy: 0.9543 - op_conv_accuracy: 0.9712 - avg_accuracy: 0.9695\n",
      "Epoch 00328: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6058 - op_main_loss: 0.1376 - op_conv_loss: 0.0780 - avg_loss: 0.1007 - op_main_accuracy: 0.9549 - op_conv_accuracy: 0.9712 - avg_accuracy: 0.9700 - val_loss: 1.6060 - val_op_main_loss: 0.3582 - val_op_conv_loss: 0.5652 - val_avg_loss: 0.3936 - val_op_main_accuracy: 0.8631 - val_op_conv_accuracy: 0.8574 - val_avg_accuracy: 0.8593\n",
      "Epoch 329/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5953 - op_main_loss: 0.1374 - op_conv_loss: 0.0714 - avg_loss: 0.0975 - op_main_accuracy: 0.9543 - op_conv_accuracy: 0.9711 - avg_accuracy: 0.9711\n",
      "Epoch 00329: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5950 - op_main_loss: 0.1373 - op_conv_loss: 0.0713 - avg_loss: 0.0974 - op_main_accuracy: 0.9544 - op_conv_accuracy: 0.9712 - avg_accuracy: 0.9712 - val_loss: 1.0675 - val_op_main_loss: 0.2308 - val_op_conv_loss: 0.3168 - val_avg_loss: 0.2312 - val_op_main_accuracy: 0.9075 - val_op_conv_accuracy: 0.9122 - val_avg_accuracy: 0.9122\n",
      "Epoch 330/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/133 [============================>.] - ETA: 0s - loss: 0.6081 - op_main_loss: 0.1373 - op_conv_loss: 0.0804 - avg_loss: 0.1018 - op_main_accuracy: 0.9569 - op_conv_accuracy: 0.9690 - avg_accuracy: 0.9697\n",
      "Epoch 00330: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6096 - op_main_loss: 0.1378 - op_conv_loss: 0.0808 - avg_loss: 0.1023 - op_main_accuracy: 0.9570 - op_conv_accuracy: 0.9686 - avg_accuracy: 0.9693 - val_loss: 1.0711 - val_op_main_loss: 0.2339 - val_op_conv_loss: 0.3148 - val_avg_loss: 0.2342 - val_op_main_accuracy: 0.9046 - val_op_conv_accuracy: 0.9169 - val_avg_accuracy: 0.9131\n",
      "Epoch 331/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6011 - op_main_loss: 0.1351 - op_conv_loss: 0.0776 - avg_loss: 0.0998 - op_main_accuracy: 0.9534 - op_conv_accuracy: 0.9700 - avg_accuracy: 0.9672\n",
      "Epoch 00331: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6011 - op_main_loss: 0.1351 - op_conv_loss: 0.0776 - avg_loss: 0.0998 - op_main_accuracy: 0.9534 - op_conv_accuracy: 0.9700 - avg_accuracy: 0.9672 - val_loss: 1.1462 - val_op_main_loss: 0.2435 - val_op_conv_loss: 0.3587 - val_avg_loss: 0.2548 - val_op_main_accuracy: 0.9075 - val_op_conv_accuracy: 0.8895 - val_avg_accuracy: 0.9008\n",
      "Epoch 332/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6847 - op_main_loss: 0.1656 - op_conv_loss: 0.1042 - avg_loss: 0.1261 - op_main_accuracy: 0.9420 - op_conv_accuracy: 0.9569 - avg_accuracy: 0.9574\n",
      "Epoch 00332: val_avg_accuracy did not improve from 0.91313\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6849 - op_main_loss: 0.1656 - op_conv_loss: 0.1043 - avg_loss: 0.1261 - op_main_accuracy: 0.9419 - op_conv_accuracy: 0.9568 - avg_accuracy: 0.9572 - val_loss: 1.0758 - val_op_main_loss: 0.2322 - val_op_conv_loss: 0.3232 - val_avg_loss: 0.2307 - val_op_main_accuracy: 0.9037 - val_op_conv_accuracy: 0.9093 - val_avg_accuracy: 0.9112\n",
      "Epoch 333/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6418 - op_main_loss: 0.1493 - op_conv_loss: 0.0911 - avg_loss: 0.1120 - op_main_accuracy: 0.9494 - op_conv_accuracy: 0.9662 - avg_accuracy: 0.9636\n",
      "Epoch 00333: val_avg_accuracy improved from 0.91313 to 0.91407, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 0.6418 - op_main_loss: 0.1493 - op_conv_loss: 0.0911 - avg_loss: 0.1120 - op_main_accuracy: 0.9494 - op_conv_accuracy: 0.9662 - avg_accuracy: 0.9636 - val_loss: 1.0717 - val_op_main_loss: 0.2337 - val_op_conv_loss: 0.3153 - val_avg_loss: 0.2332 - val_op_main_accuracy: 0.9065 - val_op_conv_accuracy: 0.9141 - val_avg_accuracy: 0.9141\n",
      "Epoch 334/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6029 - op_main_loss: 0.1350 - op_conv_loss: 0.0786 - avg_loss: 0.1000 - op_main_accuracy: 0.9550 - op_conv_accuracy: 0.9697 - avg_accuracy: 0.9697\n",
      "Epoch 00334: val_avg_accuracy did not improve from 0.91407\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6018 - op_main_loss: 0.1347 - op_conv_loss: 0.0781 - avg_loss: 0.0997 - op_main_accuracy: 0.9551 - op_conv_accuracy: 0.9700 - avg_accuracy: 0.9698 - val_loss: 1.1766 - val_op_main_loss: 0.2466 - val_op_conv_loss: 0.3842 - val_avg_loss: 0.2566 - val_op_main_accuracy: 0.9018 - val_op_conv_accuracy: 0.8952 - val_avg_accuracy: 0.9018\n",
      "Epoch 335/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6087 - op_main_loss: 0.1373 - op_conv_loss: 0.0806 - avg_loss: 0.1019 - op_main_accuracy: 0.9511 - op_conv_accuracy: 0.9681 - avg_accuracy: 0.9660\n",
      "Epoch 00335: val_avg_accuracy did not improve from 0.91407\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6087 - op_main_loss: 0.1373 - op_conv_loss: 0.0806 - avg_loss: 0.1019 - op_main_accuracy: 0.9511 - op_conv_accuracy: 0.9681 - avg_accuracy: 0.9660 - val_loss: 1.1526 - val_op_main_loss: 0.2431 - val_op_conv_loss: 0.3731 - val_avg_loss: 0.2476 - val_op_main_accuracy: 0.9027 - val_op_conv_accuracy: 0.9056 - val_avg_accuracy: 0.9065\n",
      "Epoch 336/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5853 - op_main_loss: 0.1307 - op_conv_loss: 0.0708 - avg_loss: 0.0951 - op_main_accuracy: 0.9574 - op_conv_accuracy: 0.9718 - avg_accuracy: 0.9714\n",
      "Epoch 00336: val_avg_accuracy did not improve from 0.91407\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5850 - op_main_loss: 0.1306 - op_conv_loss: 0.0707 - avg_loss: 0.0950 - op_main_accuracy: 0.9575 - op_conv_accuracy: 0.9719 - avg_accuracy: 0.9714 - val_loss: 1.1606 - val_op_main_loss: 0.2409 - val_op_conv_loss: 0.3783 - val_avg_loss: 0.2529 - val_op_main_accuracy: 0.9018 - val_op_conv_accuracy: 0.8971 - val_avg_accuracy: 0.9018\n",
      "Epoch 337/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6146 - op_main_loss: 0.1425 - op_conv_loss: 0.0791 - avg_loss: 0.1047 - op_main_accuracy: 0.9460 - op_conv_accuracy: 0.9673 - avg_accuracy: 0.9661\n",
      "Epoch 00337: val_avg_accuracy did not improve from 0.91407\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.6145 - op_main_loss: 0.1426 - op_conv_loss: 0.0790 - avg_loss: 0.1047 - op_main_accuracy: 0.9461 - op_conv_accuracy: 0.9674 - avg_accuracy: 0.9662 - val_loss: 1.1139 - val_op_main_loss: 0.2576 - val_op_conv_loss: 0.3182 - val_avg_loss: 0.2502 - val_op_main_accuracy: 0.8905 - val_op_conv_accuracy: 0.9141 - val_avg_accuracy: 0.9008\n",
      "Epoch 338/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.6025 - op_main_loss: 0.1406 - op_conv_loss: 0.0733 - avg_loss: 0.1007 - op_main_accuracy: 0.9530 - op_conv_accuracy: 0.9719 - avg_accuracy: 0.9695\n",
      "Epoch 00338: val_avg_accuracy did not improve from 0.91407\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5997 - op_main_loss: 0.1392 - op_conv_loss: 0.0728 - avg_loss: 0.0998 - op_main_accuracy: 0.9537 - op_conv_accuracy: 0.9719 - avg_accuracy: 0.9695 - val_loss: 1.2011 - val_op_main_loss: 0.2774 - val_op_conv_loss: 0.3627 - val_avg_loss: 0.2732 - val_op_main_accuracy: 0.8905 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9018\n",
      "Epoch 339/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6264 - op_main_loss: 0.1415 - op_conv_loss: 0.0893 - avg_loss: 0.1082 - op_main_accuracy: 0.9488 - op_conv_accuracy: 0.9618 - avg_accuracy: 0.9613\n",
      "Epoch 00339: val_avg_accuracy did not improve from 0.91407\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6258 - op_main_loss: 0.1418 - op_conv_loss: 0.0887 - avg_loss: 0.1080 - op_main_accuracy: 0.9485 - op_conv_accuracy: 0.9622 - avg_accuracy: 0.9612 - val_loss: 1.4649 - val_op_main_loss: 0.2934 - val_op_conv_loss: 0.5471 - val_avg_loss: 0.3373 - val_op_main_accuracy: 0.8876 - val_op_conv_accuracy: 0.8650 - val_avg_accuracy: 0.8687\n",
      "Epoch 340/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5810 - op_main_loss: 0.1298 - op_conv_loss: 0.0697 - avg_loss: 0.0941 - op_main_accuracy: 0.9568 - op_conv_accuracy: 0.9724 - avg_accuracy: 0.9726\n",
      "Epoch 00340: val_avg_accuracy did not improve from 0.91407\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.5810 - op_main_loss: 0.1298 - op_conv_loss: 0.0697 - avg_loss: 0.0941 - op_main_accuracy: 0.9568 - op_conv_accuracy: 0.9724 - avg_accuracy: 0.9726 - val_loss: 1.1370 - val_op_main_loss: 0.2459 - val_op_conv_loss: 0.3501 - val_avg_loss: 0.2536 - val_op_main_accuracy: 0.8961 - val_op_conv_accuracy: 0.9056 - val_avg_accuracy: 0.8999\n",
      "Epoch 341/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.6313 - op_main_loss: 0.1484 - op_conv_loss: 0.0859 - avg_loss: 0.1100 - op_main_accuracy: 0.9448 - op_conv_accuracy: 0.9649 - avg_accuracy: 0.9625\n",
      "Epoch 00341: val_avg_accuracy did not improve from 0.91407\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6305 - op_main_loss: 0.1480 - op_conv_loss: 0.0858 - avg_loss: 0.1097 - op_main_accuracy: 0.9449 - op_conv_accuracy: 0.9653 - avg_accuracy: 0.9629 - val_loss: 1.1160 - val_op_main_loss: 0.2486 - val_op_conv_loss: 0.3278 - val_avg_loss: 0.2530 - val_op_main_accuracy: 0.8952 - val_op_conv_accuracy: 0.9027 - val_avg_accuracy: 0.8990\n",
      "Epoch 342/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/133 [============================>.] - ETA: 0s - loss: 0.5961 - op_main_loss: 0.1324 - op_conv_loss: 0.0790 - avg_loss: 0.0982 - op_main_accuracy: 0.9567 - op_conv_accuracy: 0.9704 - avg_accuracy: 0.9697\n",
      "Epoch 00342: val_avg_accuracy did not improve from 0.91407\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.5972 - op_main_loss: 0.1329 - op_conv_loss: 0.0793 - avg_loss: 0.0986 - op_main_accuracy: 0.9563 - op_conv_accuracy: 0.9702 - avg_accuracy: 0.9693 - val_loss: 1.3384 - val_op_main_loss: 0.2490 - val_op_conv_loss: 0.5162 - val_avg_loss: 0.2872 - val_op_main_accuracy: 0.8942 - val_op_conv_accuracy: 0.8735 - val_avg_accuracy: 0.8829\n",
      "Epoch 343/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6101 - op_main_loss: 0.1380 - op_conv_loss: 0.0828 - avg_loss: 0.1027 - op_main_accuracy: 0.9551 - op_conv_accuracy: 0.9683 - avg_accuracy: 0.9709\n",
      "Epoch 00343: val_avg_accuracy did not improve from 0.91407\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.6101 - op_main_loss: 0.1380 - op_conv_loss: 0.0828 - avg_loss: 0.1027 - op_main_accuracy: 0.9551 - op_conv_accuracy: 0.9683 - avg_accuracy: 0.9709 - val_loss: 1.1074 - val_op_main_loss: 0.2414 - val_op_conv_loss: 0.3347 - val_avg_loss: 0.2453 - val_op_main_accuracy: 0.9037 - val_op_conv_accuracy: 0.9056 - val_avg_accuracy: 0.9065\n",
      "Epoch 344/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5788 - op_main_loss: 0.1348 - op_conv_loss: 0.0642 - avg_loss: 0.0937 - op_main_accuracy: 0.9512 - op_conv_accuracy: 0.9738 - avg_accuracy: 0.9707\n",
      "Epoch 00344: val_avg_accuracy did not improve from 0.91407\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5797 - op_main_loss: 0.1347 - op_conv_loss: 0.0649 - avg_loss: 0.0940 - op_main_accuracy: 0.9513 - op_conv_accuracy: 0.9735 - avg_accuracy: 0.9705 - val_loss: 1.1961 - val_op_main_loss: 0.2421 - val_op_conv_loss: 0.4082 - val_avg_loss: 0.2597 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.8867 - val_avg_accuracy: 0.8952\n",
      "Epoch 345/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5832 - op_main_loss: 0.1346 - op_conv_loss: 0.0672 - avg_loss: 0.0954 - op_main_accuracy: 0.9529 - op_conv_accuracy: 0.9704 - avg_accuracy: 0.9699\n",
      "Epoch 00345: val_avg_accuracy did not improve from 0.91407\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5841 - op_main_loss: 0.1347 - op_conv_loss: 0.0676 - avg_loss: 0.0956 - op_main_accuracy: 0.9527 - op_conv_accuracy: 0.9702 - avg_accuracy: 0.9698 - val_loss: 1.0827 - val_op_main_loss: 0.2475 - val_op_conv_loss: 0.3061 - val_avg_loss: 0.2432 - val_op_main_accuracy: 0.8971 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9008\n",
      "Epoch 346/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5915 - op_main_loss: 0.1336 - op_conv_loss: 0.0752 - avg_loss: 0.0967 - op_main_accuracy: 0.9543 - op_conv_accuracy: 0.9716 - avg_accuracy: 0.9685\n",
      "Epoch 00346: val_avg_accuracy did not improve from 0.91407\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.5916 - op_main_loss: 0.1338 - op_conv_loss: 0.0751 - avg_loss: 0.0967 - op_main_accuracy: 0.9539 - op_conv_accuracy: 0.9716 - avg_accuracy: 0.9686 - val_loss: 1.1070 - val_op_main_loss: 0.2383 - val_op_conv_loss: 0.3394 - val_avg_loss: 0.2435 - val_op_main_accuracy: 0.9018 - val_op_conv_accuracy: 0.9027 - val_avg_accuracy: 0.9065\n",
      "Epoch 347/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5840 - op_main_loss: 0.1342 - op_conv_loss: 0.0686 - avg_loss: 0.0956 - op_main_accuracy: 0.9537 - op_conv_accuracy: 0.9742 - avg_accuracy: 0.9690\n",
      "Epoch 00347: val_avg_accuracy did not improve from 0.91407\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.5839 - op_main_loss: 0.1338 - op_conv_loss: 0.0690 - avg_loss: 0.0954 - op_main_accuracy: 0.9542 - op_conv_accuracy: 0.9742 - avg_accuracy: 0.9690 - val_loss: 1.1969 - val_op_main_loss: 0.2457 - val_op_conv_loss: 0.4023 - val_avg_loss: 0.2633 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.8952 - val_avg_accuracy: 0.9008\n",
      "Epoch 348/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5967 - op_main_loss: 0.1356 - op_conv_loss: 0.0762 - avg_loss: 0.0994 - op_main_accuracy: 0.9538 - op_conv_accuracy: 0.9690 - avg_accuracy: 0.9659\n",
      "Epoch 00348: val_avg_accuracy did not improve from 0.91407\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.6010 - op_main_loss: 0.1370 - op_conv_loss: 0.0776 - avg_loss: 0.1008 - op_main_accuracy: 0.9523 - op_conv_accuracy: 0.9683 - avg_accuracy: 0.9650 - val_loss: 1.2205 - val_op_main_loss: 0.2924 - val_op_conv_loss: 0.3561 - val_avg_loss: 0.2866 - val_op_main_accuracy: 0.8848 - val_op_conv_accuracy: 0.9018 - val_avg_accuracy: 0.8999\n",
      "Epoch 349/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5892 - op_main_loss: 0.1316 - op_conv_loss: 0.0749 - avg_loss: 0.0972 - op_main_accuracy: 0.9575 - op_conv_accuracy: 0.9690 - avg_accuracy: 0.9695\n",
      "Epoch 00349: val_avg_accuracy did not improve from 0.91407\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5892 - op_main_loss: 0.1316 - op_conv_loss: 0.0749 - avg_loss: 0.0972 - op_main_accuracy: 0.9575 - op_conv_accuracy: 0.9690 - avg_accuracy: 0.9695 - val_loss: 1.1373 - val_op_main_loss: 0.2507 - val_op_conv_loss: 0.3504 - val_avg_loss: 0.2509 - val_op_main_accuracy: 0.8961 - val_op_conv_accuracy: 0.9056 - val_avg_accuracy: 0.9065\n",
      "Epoch 350/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5800 - op_main_loss: 0.1314 - op_conv_loss: 0.0690 - avg_loss: 0.0945 - op_main_accuracy: 0.9585 - op_conv_accuracy: 0.9752 - avg_accuracy: 0.9742\n",
      "Epoch 00350: val_avg_accuracy did not improve from 0.91407\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5794 - op_main_loss: 0.1311 - op_conv_loss: 0.0688 - avg_loss: 0.0943 - op_main_accuracy: 0.9584 - op_conv_accuracy: 0.9752 - avg_accuracy: 0.9742 - val_loss: 1.1782 - val_op_main_loss: 0.2432 - val_op_conv_loss: 0.3897 - val_avg_loss: 0.2604 - val_op_main_accuracy: 0.9056 - val_op_conv_accuracy: 0.8961 - val_avg_accuracy: 0.8961\n",
      "Epoch 351/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5969 - op_main_loss: 0.1335 - op_conv_loss: 0.0792 - avg_loss: 0.0995 - op_main_accuracy: 0.9555 - op_conv_accuracy: 0.9690 - avg_accuracy: 0.9695\n",
      "Epoch 00351: val_avg_accuracy did not improve from 0.91407\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5969 - op_main_loss: 0.1335 - op_conv_loss: 0.0793 - avg_loss: 0.0995 - op_main_accuracy: 0.9556 - op_conv_accuracy: 0.9690 - avg_accuracy: 0.9695 - val_loss: 1.3498 - val_op_main_loss: 0.3040 - val_op_conv_loss: 0.4412 - val_avg_loss: 0.3201 - val_op_main_accuracy: 0.8848 - val_op_conv_accuracy: 0.8924 - val_avg_accuracy: 0.8857\n",
      "Epoch 352/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5901 - op_main_loss: 0.1347 - op_conv_loss: 0.0735 - avg_loss: 0.0976 - op_main_accuracy: 0.9539 - op_conv_accuracy: 0.9742 - avg_accuracy: 0.9698\n",
      "Epoch 00352: val_avg_accuracy did not improve from 0.91407\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.5901 - op_main_loss: 0.1347 - op_conv_loss: 0.0735 - avg_loss: 0.0976 - op_main_accuracy: 0.9539 - op_conv_accuracy: 0.9742 - avg_accuracy: 0.9698 - val_loss: 1.0811 - val_op_main_loss: 0.2375 - val_op_conv_loss: 0.3217 - val_avg_loss: 0.2384 - val_op_main_accuracy: 0.9027 - val_op_conv_accuracy: 0.9084 - val_avg_accuracy: 0.9075\n",
      "Epoch 353/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5909 - op_main_loss: 0.1348 - op_conv_loss: 0.0741 - avg_loss: 0.0983 - op_main_accuracy: 0.9548 - op_conv_accuracy: 0.9716 - avg_accuracy: 0.9704\n",
      "Epoch 00353: val_avg_accuracy improved from 0.91407 to 0.91501, saving model to ./weight_cp\\weight_lstm2.hdf5\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.5905 - op_main_loss: 0.1346 - op_conv_loss: 0.0740 - avg_loss: 0.0982 - op_main_accuracy: 0.9549 - op_conv_accuracy: 0.9716 - avg_accuracy: 0.9705 - val_loss: 1.1263 - val_op_main_loss: 0.2598 - val_op_conv_loss: 0.3313 - val_avg_loss: 0.2512 - val_op_main_accuracy: 0.9056 - val_op_conv_accuracy: 0.9122 - val_avg_accuracy: 0.9150\n",
      "Epoch 354/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/133 [============================>.] - ETA: 0s - loss: 0.5830 - op_main_loss: 0.1299 - op_conv_loss: 0.0735 - avg_loss: 0.0951 - op_main_accuracy: 0.9565 - op_conv_accuracy: 0.9714 - avg_accuracy: 0.9712\n",
      "Epoch 00354: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5822 - op_main_loss: 0.1298 - op_conv_loss: 0.0730 - avg_loss: 0.0949 - op_main_accuracy: 0.9568 - op_conv_accuracy: 0.9716 - avg_accuracy: 0.9712 - val_loss: 1.0856 - val_op_main_loss: 0.2468 - val_op_conv_loss: 0.3121 - val_avg_loss: 0.2422 - val_op_main_accuracy: 0.8961 - val_op_conv_accuracy: 0.9084 - val_avg_accuracy: 0.9046\n",
      "Epoch 355/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6289 - op_main_loss: 0.1477 - op_conv_loss: 0.0870 - avg_loss: 0.1103 - op_main_accuracy: 0.9478 - op_conv_accuracy: 0.9675 - avg_accuracy: 0.9627\n",
      "Epoch 00355: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6281 - op_main_loss: 0.1469 - op_conv_loss: 0.0873 - avg_loss: 0.1100 - op_main_accuracy: 0.9483 - op_conv_accuracy: 0.9674 - avg_accuracy: 0.9627 - val_loss: 1.1076 - val_op_main_loss: 0.2400 - val_op_conv_loss: 0.3367 - val_avg_loss: 0.2472 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.9008 - val_avg_accuracy: 0.9027\n",
      "Epoch 356/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5874 - op_main_loss: 0.1323 - op_conv_loss: 0.0736 - avg_loss: 0.0975 - op_main_accuracy: 0.9569 - op_conv_accuracy: 0.9714 - avg_accuracy: 0.9725\n",
      "Epoch 00356: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5873 - op_main_loss: 0.1323 - op_conv_loss: 0.0736 - avg_loss: 0.0974 - op_main_accuracy: 0.9570 - op_conv_accuracy: 0.9714 - avg_accuracy: 0.9726 - val_loss: 1.1340 - val_op_main_loss: 0.2440 - val_op_conv_loss: 0.3568 - val_avg_loss: 0.2492 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.9141 - val_avg_accuracy: 0.9084\n",
      "Epoch 357/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6030 - op_main_loss: 0.1351 - op_conv_loss: 0.0830 - avg_loss: 0.1011 - op_main_accuracy: 0.9543 - op_conv_accuracy: 0.9675 - avg_accuracy: 0.9654\n",
      "Epoch 00357: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6023 - op_main_loss: 0.1349 - op_conv_loss: 0.0826 - avg_loss: 0.1009 - op_main_accuracy: 0.9542 - op_conv_accuracy: 0.9676 - avg_accuracy: 0.9653 - val_loss: 1.1755 - val_op_main_loss: 0.2507 - val_op_conv_loss: 0.3758 - val_avg_loss: 0.2652 - val_op_main_accuracy: 0.8933 - val_op_conv_accuracy: 0.8895 - val_avg_accuracy: 0.8895\n",
      "Epoch 358/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.6064 - op_main_loss: 0.1379 - op_conv_loss: 0.0818 - avg_loss: 0.1029 - op_main_accuracy: 0.9542 - op_conv_accuracy: 0.9700 - avg_accuracy: 0.9690\n",
      "Epoch 00358: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6047 - op_main_loss: 0.1375 - op_conv_loss: 0.0810 - avg_loss: 0.1024 - op_main_accuracy: 0.9544 - op_conv_accuracy: 0.9705 - avg_accuracy: 0.9695 - val_loss: 1.0634 - val_op_main_loss: 0.2430 - val_op_conv_loss: 0.3019 - val_avg_loss: 0.2350 - val_op_main_accuracy: 0.8980 - val_op_conv_accuracy: 0.9093 - val_avg_accuracy: 0.9112\n",
      "Epoch 359/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5817 - op_main_loss: 0.1307 - op_conv_loss: 0.0728 - avg_loss: 0.0948 - op_main_accuracy: 0.9575 - op_conv_accuracy: 0.9709 - avg_accuracy: 0.9724\n",
      "Epoch 00359: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5817 - op_main_loss: 0.1307 - op_conv_loss: 0.0728 - avg_loss: 0.0948 - op_main_accuracy: 0.9575 - op_conv_accuracy: 0.9709 - avg_accuracy: 0.9724 - val_loss: 1.2498 - val_op_main_loss: 0.2718 - val_op_conv_loss: 0.4061 - val_avg_loss: 0.2888 - val_op_main_accuracy: 0.8914 - val_op_conv_accuracy: 0.8886 - val_avg_accuracy: 0.8895\n",
      "Epoch 360/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5856 - op_main_loss: 0.1330 - op_conv_loss: 0.0721 - avg_loss: 0.0972 - op_main_accuracy: 0.9567 - op_conv_accuracy: 0.9735 - avg_accuracy: 0.9676\n",
      "Epoch 00360: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5859 - op_main_loss: 0.1332 - op_conv_loss: 0.0721 - avg_loss: 0.0972 - op_main_accuracy: 0.9565 - op_conv_accuracy: 0.9735 - avg_accuracy: 0.9674 - val_loss: 1.0895 - val_op_main_loss: 0.2386 - val_op_conv_loss: 0.3249 - val_avg_loss: 0.2426 - val_op_main_accuracy: 0.9027 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9046\n",
      "Epoch 361/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5847 - op_main_loss: 0.1327 - op_conv_loss: 0.0727 - avg_loss: 0.0960 - op_main_accuracy: 0.9546 - op_conv_accuracy: 0.9724 - avg_accuracy: 0.9704\n",
      "Epoch 00361: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5833 - op_main_loss: 0.1321 - op_conv_loss: 0.0723 - avg_loss: 0.0956 - op_main_accuracy: 0.9549 - op_conv_accuracy: 0.9724 - avg_accuracy: 0.9705 - val_loss: 1.1023 - val_op_main_loss: 0.2477 - val_op_conv_loss: 0.3306 - val_avg_loss: 0.2410 - val_op_main_accuracy: 0.8980 - val_op_conv_accuracy: 0.9112 - val_avg_accuracy: 0.9065\n",
      "Epoch 362/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5674 - op_main_loss: 0.1285 - op_conv_loss: 0.0650 - avg_loss: 0.0910 - op_main_accuracy: 0.9564 - op_conv_accuracy: 0.9737 - avg_accuracy: 0.9732\n",
      "Epoch 00362: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5676 - op_main_loss: 0.1286 - op_conv_loss: 0.0650 - avg_loss: 0.0911 - op_main_accuracy: 0.9563 - op_conv_accuracy: 0.9738 - avg_accuracy: 0.9731 - val_loss: 1.2667 - val_op_main_loss: 0.2852 - val_op_conv_loss: 0.4132 - val_avg_loss: 0.2857 - val_op_main_accuracy: 0.8980 - val_op_conv_accuracy: 0.8980 - val_avg_accuracy: 0.9018\n",
      "Epoch 363/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.6174 - op_main_loss: 0.1436 - op_conv_loss: 0.0853 - avg_loss: 0.1064 - op_main_accuracy: 0.9521 - op_conv_accuracy: 0.9680 - avg_accuracy: 0.9659\n",
      "Epoch 00363: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6169 - op_main_loss: 0.1435 - op_conv_loss: 0.0851 - avg_loss: 0.1063 - op_main_accuracy: 0.9520 - op_conv_accuracy: 0.9681 - avg_accuracy: 0.9657 - val_loss: 1.0680 - val_op_main_loss: 0.2366 - val_op_conv_loss: 0.3109 - val_avg_loss: 0.2391 - val_op_main_accuracy: 0.9018 - val_op_conv_accuracy: 0.8990 - val_avg_accuracy: 0.9018\n",
      "Epoch 364/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.6035 - op_main_loss: 0.1375 - op_conv_loss: 0.0817 - avg_loss: 0.1023 - op_main_accuracy: 0.9530 - op_conv_accuracy: 0.9680 - avg_accuracy: 0.9683\n",
      "Epoch 00364: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6036 - op_main_loss: 0.1376 - op_conv_loss: 0.0818 - avg_loss: 0.1024 - op_main_accuracy: 0.9530 - op_conv_accuracy: 0.9679 - avg_accuracy: 0.9683 - val_loss: 1.1859 - val_op_main_loss: 0.2679 - val_op_conv_loss: 0.3647 - val_avg_loss: 0.2711 - val_op_main_accuracy: 0.8942 - val_op_conv_accuracy: 0.9027 - val_avg_accuracy: 0.8980\n",
      "Epoch 365/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.6024 - op_main_loss: 0.1407 - op_conv_loss: 0.0776 - avg_loss: 0.1016 - op_main_accuracy: 0.9501 - op_conv_accuracy: 0.9680 - avg_accuracy: 0.9673\n",
      "Epoch 00365: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6017 - op_main_loss: 0.1403 - op_conv_loss: 0.0776 - avg_loss: 0.1014 - op_main_accuracy: 0.9504 - op_conv_accuracy: 0.9681 - avg_accuracy: 0.9674 - val_loss: 1.1102 - val_op_main_loss: 0.2413 - val_op_conv_loss: 0.3394 - val_avg_loss: 0.2470 - val_op_main_accuracy: 0.9018 - val_op_conv_accuracy: 0.8961 - val_avg_accuracy: 0.8999\n",
      "Epoch 366/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/133 [============================>.] - ETA: 0s - loss: 0.6055 - op_main_loss: 0.1380 - op_conv_loss: 0.0822 - avg_loss: 0.1032 - op_main_accuracy: 0.9522 - op_conv_accuracy: 0.9680 - avg_accuracy: 0.9678\n",
      "Epoch 00366: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6083 - op_main_loss: 0.1383 - op_conv_loss: 0.0840 - avg_loss: 0.1038 - op_main_accuracy: 0.9520 - op_conv_accuracy: 0.9679 - avg_accuracy: 0.9679 - val_loss: 1.1311 - val_op_main_loss: 0.2534 - val_op_conv_loss: 0.3443 - val_avg_loss: 0.2512 - val_op_main_accuracy: 0.8971 - val_op_conv_accuracy: 0.9037 - val_avg_accuracy: 0.9103\n",
      "Epoch 367/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5974 - op_main_loss: 0.1384 - op_conv_loss: 0.0767 - avg_loss: 0.0997 - op_main_accuracy: 0.9527 - op_conv_accuracy: 0.9685 - avg_accuracy: 0.9702\n",
      "Epoch 00367: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5975 - op_main_loss: 0.1385 - op_conv_loss: 0.0767 - avg_loss: 0.0997 - op_main_accuracy: 0.9525 - op_conv_accuracy: 0.9686 - avg_accuracy: 0.9700 - val_loss: 1.2218 - val_op_main_loss: 0.2377 - val_op_conv_loss: 0.4394 - val_avg_loss: 0.2627 - val_op_main_accuracy: 0.9027 - val_op_conv_accuracy: 0.8857 - val_avg_accuracy: 0.8933\n",
      "Epoch 368/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6064 - op_main_loss: 0.1398 - op_conv_loss: 0.0813 - avg_loss: 0.1033 - op_main_accuracy: 0.9507 - op_conv_accuracy: 0.9685 - avg_accuracy: 0.9666\n",
      "Epoch 00368: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6043 - op_main_loss: 0.1391 - op_conv_loss: 0.0806 - avg_loss: 0.1026 - op_main_accuracy: 0.9513 - op_conv_accuracy: 0.9688 - avg_accuracy: 0.9672 - val_loss: 1.8038 - val_op_main_loss: 0.2955 - val_op_conv_loss: 0.8419 - val_avg_loss: 0.3846 - val_op_main_accuracy: 0.8763 - val_op_conv_accuracy: 0.8168 - val_avg_accuracy: 0.8395\n",
      "Epoch 369/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5788 - op_main_loss: 0.1313 - op_conv_loss: 0.0703 - avg_loss: 0.0951 - op_main_accuracy: 0.9553 - op_conv_accuracy: 0.9716 - avg_accuracy: 0.9704\n",
      "Epoch 00369: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5774 - op_main_loss: 0.1309 - op_conv_loss: 0.0698 - avg_loss: 0.0947 - op_main_accuracy: 0.9553 - op_conv_accuracy: 0.9716 - avg_accuracy: 0.9707 - val_loss: 1.5980 - val_op_main_loss: 0.2907 - val_op_conv_loss: 0.6683 - val_avg_loss: 0.3570 - val_op_main_accuracy: 0.8810 - val_op_conv_accuracy: 0.8423 - val_avg_accuracy: 0.8574\n",
      "Epoch 370/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5825 - op_main_loss: 0.1348 - op_conv_loss: 0.0700 - avg_loss: 0.0959 - op_main_accuracy: 0.9543 - op_conv_accuracy: 0.9709 - avg_accuracy: 0.9700\n",
      "Epoch 00370: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5818 - op_main_loss: 0.1344 - op_conv_loss: 0.0698 - avg_loss: 0.0957 - op_main_accuracy: 0.9546 - op_conv_accuracy: 0.9709 - avg_accuracy: 0.9702 - val_loss: 1.0749 - val_op_main_loss: 0.2300 - val_op_conv_loss: 0.3301 - val_avg_loss: 0.2330 - val_op_main_accuracy: 0.9056 - val_op_conv_accuracy: 0.9131 - val_avg_accuracy: 0.9141\n",
      "Epoch 371/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5662 - op_main_loss: 0.1255 - op_conv_loss: 0.0684 - avg_loss: 0.0903 - op_main_accuracy: 0.9576 - op_conv_accuracy: 0.9736 - avg_accuracy: 0.9748\n",
      "Epoch 00371: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5666 - op_main_loss: 0.1256 - op_conv_loss: 0.0686 - avg_loss: 0.0905 - op_main_accuracy: 0.9570 - op_conv_accuracy: 0.9731 - avg_accuracy: 0.9745 - val_loss: 1.0923 - val_op_main_loss: 0.2343 - val_op_conv_loss: 0.3377 - val_avg_loss: 0.2385 - val_op_main_accuracy: 0.9056 - val_op_conv_accuracy: 0.9065 - val_avg_accuracy: 0.9103\n",
      "Epoch 372/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.6097 - op_main_loss: 0.1435 - op_conv_loss: 0.0808 - avg_loss: 0.1031 - op_main_accuracy: 0.9512 - op_conv_accuracy: 0.9690 - avg_accuracy: 0.9668\n",
      "Epoch 00372: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6077 - op_main_loss: 0.1424 - op_conv_loss: 0.0804 - avg_loss: 0.1025 - op_main_accuracy: 0.9518 - op_conv_accuracy: 0.9690 - avg_accuracy: 0.9669 - val_loss: 1.1774 - val_op_main_loss: 0.2836 - val_op_conv_loss: 0.3370 - val_avg_loss: 0.2740 - val_op_main_accuracy: 0.8895 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9027\n",
      "Epoch 373/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5687 - op_main_loss: 0.1275 - op_conv_loss: 0.0672 - avg_loss: 0.0916 - op_main_accuracy: 0.9612 - op_conv_accuracy: 0.9776 - avg_accuracy: 0.9747\n",
      "Epoch 00373: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5687 - op_main_loss: 0.1275 - op_conv_loss: 0.0672 - avg_loss: 0.0916 - op_main_accuracy: 0.9612 - op_conv_accuracy: 0.9776 - avg_accuracy: 0.9747 - val_loss: 1.2317 - val_op_main_loss: 0.2560 - val_op_conv_loss: 0.4259 - val_avg_loss: 0.2681 - val_op_main_accuracy: 0.9018 - val_op_conv_accuracy: 0.8961 - val_avg_accuracy: 0.9046\n",
      "Epoch 374/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5745 - op_main_loss: 0.1283 - op_conv_loss: 0.0708 - avg_loss: 0.0938 - op_main_accuracy: 0.9578 - op_conv_accuracy: 0.9728 - avg_accuracy: 0.9733\n",
      "Epoch 00374: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5753 - op_main_loss: 0.1284 - op_conv_loss: 0.0713 - avg_loss: 0.0940 - op_main_accuracy: 0.9575 - op_conv_accuracy: 0.9728 - avg_accuracy: 0.9731 - val_loss: 1.1407 - val_op_main_loss: 0.2612 - val_op_conv_loss: 0.3375 - val_avg_loss: 0.2607 - val_op_main_accuracy: 0.8942 - val_op_conv_accuracy: 0.8990 - val_avg_accuracy: 0.9008\n",
      "Epoch 375/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5851 - op_main_loss: 0.1329 - op_conv_loss: 0.0741 - avg_loss: 0.0967 - op_main_accuracy: 0.9534 - op_conv_accuracy: 0.9702 - avg_accuracy: 0.9668\n",
      "Epoch 00375: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5843 - op_main_loss: 0.1324 - op_conv_loss: 0.0741 - avg_loss: 0.0965 - op_main_accuracy: 0.9537 - op_conv_accuracy: 0.9702 - avg_accuracy: 0.9669 - val_loss: 1.1386 - val_op_main_loss: 0.2417 - val_op_conv_loss: 0.3644 - val_avg_loss: 0.2510 - val_op_main_accuracy: 0.8980 - val_op_conv_accuracy: 0.8990 - val_avg_accuracy: 0.9056\n",
      "Epoch 376/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5733 - op_main_loss: 0.1285 - op_conv_loss: 0.0702 - avg_loss: 0.0937 - op_main_accuracy: 0.9626 - op_conv_accuracy: 0.9742 - avg_accuracy: 0.9735\n",
      "Epoch 00376: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5736 - op_main_loss: 0.1286 - op_conv_loss: 0.0703 - avg_loss: 0.0937 - op_main_accuracy: 0.9627 - op_conv_accuracy: 0.9742 - avg_accuracy: 0.9735 - val_loss: 1.1527 - val_op_main_loss: 0.2368 - val_op_conv_loss: 0.3825 - val_avg_loss: 0.2523 - val_op_main_accuracy: 0.9027 - val_op_conv_accuracy: 0.8905 - val_avg_accuracy: 0.9018\n",
      "Epoch 377/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5868 - op_main_loss: 0.1337 - op_conv_loss: 0.0744 - avg_loss: 0.0975 - op_main_accuracy: 0.9568 - op_conv_accuracy: 0.9728 - avg_accuracy: 0.9702\n",
      "Epoch 00377: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5871 - op_main_loss: 0.1339 - op_conv_loss: 0.0743 - avg_loss: 0.0976 - op_main_accuracy: 0.9563 - op_conv_accuracy: 0.9728 - avg_accuracy: 0.9702 - val_loss: 1.2011 - val_op_main_loss: 0.2877 - val_op_conv_loss: 0.3492 - val_avg_loss: 0.2832 - val_op_main_accuracy: 0.8876 - val_op_conv_accuracy: 0.8990 - val_avg_accuracy: 0.8952\n",
      "Epoch 378/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/133 [============================>.] - ETA: 0s - loss: 0.6064 - op_main_loss: 0.1385 - op_conv_loss: 0.0834 - avg_loss: 0.1033 - op_main_accuracy: 0.9528 - op_conv_accuracy: 0.9683 - avg_accuracy: 0.9656\n",
      "Epoch 00378: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6056 - op_main_loss: 0.1380 - op_conv_loss: 0.0834 - avg_loss: 0.1029 - op_main_accuracy: 0.9532 - op_conv_accuracy: 0.9683 - avg_accuracy: 0.9657 - val_loss: 1.1934 - val_op_main_loss: 0.2395 - val_op_conv_loss: 0.4107 - val_avg_loss: 0.2619 - val_op_main_accuracy: 0.9027 - val_op_conv_accuracy: 0.8895 - val_avg_accuracy: 0.8990\n",
      "Epoch 379/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5718 - op_main_loss: 0.1254 - op_conv_loss: 0.0725 - avg_loss: 0.0927 - op_main_accuracy: 0.9602 - op_conv_accuracy: 0.9738 - avg_accuracy: 0.9726\n",
      "Epoch 00379: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5712 - op_main_loss: 0.1253 - op_conv_loss: 0.0723 - avg_loss: 0.0925 - op_main_accuracy: 0.9605 - op_conv_accuracy: 0.9740 - avg_accuracy: 0.9728 - val_loss: 1.1111 - val_op_main_loss: 0.2384 - val_op_conv_loss: 0.3449 - val_avg_loss: 0.2468 - val_op_main_accuracy: 0.9075 - val_op_conv_accuracy: 0.9037 - val_avg_accuracy: 0.9037\n",
      "Epoch 380/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5585 - op_main_loss: 0.1243 - op_conv_loss: 0.0645 - avg_loss: 0.0889 - op_main_accuracy: 0.9613 - op_conv_accuracy: 0.9740 - avg_accuracy: 0.9731\n",
      "Epoch 00380: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5569 - op_main_loss: 0.1239 - op_conv_loss: 0.0639 - avg_loss: 0.0884 - op_main_accuracy: 0.9620 - op_conv_accuracy: 0.9745 - avg_accuracy: 0.9735 - val_loss: 1.0901 - val_op_main_loss: 0.2345 - val_op_conv_loss: 0.3310 - val_avg_loss: 0.2443 - val_op_main_accuracy: 0.9056 - val_op_conv_accuracy: 0.9037 - val_avg_accuracy: 0.9065\n",
      "Epoch 381/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5877 - op_main_loss: 0.1341 - op_conv_loss: 0.0757 - avg_loss: 0.0979 - op_main_accuracy: 0.9554 - op_conv_accuracy: 0.9697 - avg_accuracy: 0.9678\n",
      "Epoch 00381: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5859 - op_main_loss: 0.1335 - op_conv_loss: 0.0751 - avg_loss: 0.0974 - op_main_accuracy: 0.9558 - op_conv_accuracy: 0.9700 - avg_accuracy: 0.9681 - val_loss: 1.2177 - val_op_main_loss: 0.2925 - val_op_conv_loss: 0.3660 - val_avg_loss: 0.2795 - val_op_main_accuracy: 0.8952 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9122\n",
      "Epoch 382/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5785 - op_main_loss: 0.1311 - op_conv_loss: 0.0724 - avg_loss: 0.0951 - op_main_accuracy: 0.9542 - op_conv_accuracy: 0.9728 - avg_accuracy: 0.9698\n",
      "Epoch 00382: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5785 - op_main_loss: 0.1311 - op_conv_loss: 0.0724 - avg_loss: 0.0951 - op_main_accuracy: 0.9542 - op_conv_accuracy: 0.9728 - avg_accuracy: 0.9698 - val_loss: 1.1196 - val_op_main_loss: 0.2376 - val_op_conv_loss: 0.3508 - val_avg_loss: 0.2512 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.8971 - val_avg_accuracy: 0.8999\n",
      "Epoch 383/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5760 - op_main_loss: 0.1272 - op_conv_loss: 0.0748 - avg_loss: 0.0941 - op_main_accuracy: 0.9619 - op_conv_accuracy: 0.9721 - avg_accuracy: 0.9709\n",
      "Epoch 00383: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5759 - op_main_loss: 0.1272 - op_conv_loss: 0.0748 - avg_loss: 0.0941 - op_main_accuracy: 0.9620 - op_conv_accuracy: 0.9721 - avg_accuracy: 0.9709 - val_loss: 1.0643 - val_op_main_loss: 0.2358 - val_op_conv_loss: 0.3129 - val_avg_loss: 0.2359 - val_op_main_accuracy: 0.8999 - val_op_conv_accuracy: 0.9093 - val_avg_accuracy: 0.9075\n",
      "Epoch 384/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5583 - op_main_loss: 0.1218 - op_conv_loss: 0.0674 - avg_loss: 0.0888 - op_main_accuracy: 0.9599 - op_conv_accuracy: 0.9730 - avg_accuracy: 0.9735\n",
      "Epoch 00384: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5584 - op_main_loss: 0.1217 - op_conv_loss: 0.0676 - avg_loss: 0.0888 - op_main_accuracy: 0.9603 - op_conv_accuracy: 0.9731 - avg_accuracy: 0.9735 - val_loss: 1.1471 - val_op_main_loss: 0.2458 - val_op_conv_loss: 0.3660 - val_avg_loss: 0.2550 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9046\n",
      "Epoch 385/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.6062 - op_main_loss: 0.1420 - op_conv_loss: 0.0807 - avg_loss: 0.1039 - op_main_accuracy: 0.9528 - op_conv_accuracy: 0.9683 - avg_accuracy: 0.9680\n",
      "Epoch 00385: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6057 - op_main_loss: 0.1416 - op_conv_loss: 0.0808 - avg_loss: 0.1038 - op_main_accuracy: 0.9530 - op_conv_accuracy: 0.9681 - avg_accuracy: 0.9681 - val_loss: 1.1313 - val_op_main_loss: 0.2527 - val_op_conv_loss: 0.3386 - val_avg_loss: 0.2605 - val_op_main_accuracy: 0.8980 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9018\n",
      "Epoch 386/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6040 - op_main_loss: 0.1373 - op_conv_loss: 0.0843 - avg_loss: 0.1032 - op_main_accuracy: 0.9532 - op_conv_accuracy: 0.9688 - avg_accuracy: 0.9688\n",
      "Epoch 00386: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6040 - op_main_loss: 0.1373 - op_conv_loss: 0.0843 - avg_loss: 0.1032 - op_main_accuracy: 0.9532 - op_conv_accuracy: 0.9688 - avg_accuracy: 0.9688 - val_loss: 1.0891 - val_op_main_loss: 0.2365 - val_op_conv_loss: 0.3318 - val_avg_loss: 0.2417 - val_op_main_accuracy: 0.9018 - val_op_conv_accuracy: 0.9075 - val_avg_accuracy: 0.9103\n",
      "Epoch 387/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5734 - op_main_loss: 0.1287 - op_conv_loss: 0.0715 - avg_loss: 0.0941 - op_main_accuracy: 0.9583 - op_conv_accuracy: 0.9732 - avg_accuracy: 0.9711\n",
      "Epoch 00387: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5733 - op_main_loss: 0.1286 - op_conv_loss: 0.0715 - avg_loss: 0.0941 - op_main_accuracy: 0.9584 - op_conv_accuracy: 0.9733 - avg_accuracy: 0.9712 - val_loss: 1.1396 - val_op_main_loss: 0.2388 - val_op_conv_loss: 0.3746 - val_avg_loss: 0.2473 - val_op_main_accuracy: 0.9046 - val_op_conv_accuracy: 0.8961 - val_avg_accuracy: 0.9084\n",
      "Epoch 388/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6033 - op_main_loss: 0.1399 - op_conv_loss: 0.0809 - avg_loss: 0.1037 - op_main_accuracy: 0.9519 - op_conv_accuracy: 0.9685 - avg_accuracy: 0.9664\n",
      "Epoch 00388: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.6042 - op_main_loss: 0.1402 - op_conv_loss: 0.0812 - avg_loss: 0.1040 - op_main_accuracy: 0.9518 - op_conv_accuracy: 0.9683 - avg_accuracy: 0.9662 - val_loss: 1.1363 - val_op_main_loss: 0.2452 - val_op_conv_loss: 0.3613 - val_avg_loss: 0.2508 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9056\n",
      "Epoch 389/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5660 - op_main_loss: 0.1280 - op_conv_loss: 0.0666 - avg_loss: 0.0922 - op_main_accuracy: 0.9577 - op_conv_accuracy: 0.9731 - avg_accuracy: 0.9726\n",
      "Epoch 00389: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5673 - op_main_loss: 0.1281 - op_conv_loss: 0.0673 - avg_loss: 0.0926 - op_main_accuracy: 0.9577 - op_conv_accuracy: 0.9726 - avg_accuracy: 0.9726 - val_loss: 1.3224 - val_op_main_loss: 0.2739 - val_op_conv_loss: 0.4662 - val_avg_loss: 0.3029 - val_op_main_accuracy: 0.8933 - val_op_conv_accuracy: 0.8820 - val_avg_accuracy: 0.8876\n",
      "Epoch 390/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/133 [============================>.] - ETA: 0s - loss: 0.5859 - op_main_loss: 0.1321 - op_conv_loss: 0.0766 - avg_loss: 0.0980 - op_main_accuracy: 0.9534 - op_conv_accuracy: 0.9709 - avg_accuracy: 0.9688\n",
      "Epoch 00390: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5864 - op_main_loss: 0.1325 - op_conv_loss: 0.0766 - avg_loss: 0.0981 - op_main_accuracy: 0.9530 - op_conv_accuracy: 0.9709 - avg_accuracy: 0.9688 - val_loss: 1.2464 - val_op_main_loss: 0.2654 - val_op_conv_loss: 0.4165 - val_avg_loss: 0.2861 - val_op_main_accuracy: 0.8905 - val_op_conv_accuracy: 0.8886 - val_avg_accuracy: 0.8952\n",
      "Epoch 391/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5891 - op_main_loss: 0.1306 - op_conv_loss: 0.0813 - avg_loss: 0.0984 - op_main_accuracy: 0.9569 - op_conv_accuracy: 0.9668 - avg_accuracy: 0.9678\n",
      "Epoch 00391: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5879 - op_main_loss: 0.1304 - op_conv_loss: 0.0808 - avg_loss: 0.0980 - op_main_accuracy: 0.9565 - op_conv_accuracy: 0.9669 - avg_accuracy: 0.9679 - val_loss: 1.2639 - val_op_main_loss: 0.2559 - val_op_conv_loss: 0.4530 - val_avg_loss: 0.2759 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.8933 - val_avg_accuracy: 0.9018\n",
      "Epoch 392/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5918 - op_main_loss: 0.1346 - op_conv_loss: 0.0784 - avg_loss: 0.1002 - op_main_accuracy: 0.9562 - op_conv_accuracy: 0.9702 - avg_accuracy: 0.9692\n",
      "Epoch 00392: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5911 - op_main_loss: 0.1342 - op_conv_loss: 0.0784 - avg_loss: 0.0999 - op_main_accuracy: 0.9565 - op_conv_accuracy: 0.9702 - avg_accuracy: 0.9695 - val_loss: 1.1463 - val_op_main_loss: 0.2356 - val_op_conv_loss: 0.3782 - val_avg_loss: 0.2541 - val_op_main_accuracy: 0.8999 - val_op_conv_accuracy: 0.8952 - val_avg_accuracy: 0.9027\n",
      "Epoch 393/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5741 - op_main_loss: 0.1324 - op_conv_loss: 0.0690 - avg_loss: 0.0944 - op_main_accuracy: 0.9538 - op_conv_accuracy: 0.9716 - avg_accuracy: 0.9709\n",
      "Epoch 00393: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5759 - op_main_loss: 0.1331 - op_conv_loss: 0.0695 - avg_loss: 0.0951 - op_main_accuracy: 0.9539 - op_conv_accuracy: 0.9714 - avg_accuracy: 0.9707 - val_loss: 1.1692 - val_op_main_loss: 0.2463 - val_op_conv_loss: 0.3849 - val_avg_loss: 0.2592 - val_op_main_accuracy: 0.8952 - val_op_conv_accuracy: 0.8990 - val_avg_accuracy: 0.8990\n",
      "Epoch 394/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5856 - op_main_loss: 0.1346 - op_conv_loss: 0.0744 - avg_loss: 0.0974 - op_main_accuracy: 0.9530 - op_conv_accuracy: 0.9714 - avg_accuracy: 0.9692\n",
      "Epoch 00394: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5888 - op_main_loss: 0.1361 - op_conv_loss: 0.0750 - avg_loss: 0.0985 - op_main_accuracy: 0.9525 - op_conv_accuracy: 0.9709 - avg_accuracy: 0.9688 - val_loss: 1.0885 - val_op_main_loss: 0.2337 - val_op_conv_loss: 0.3388 - val_avg_loss: 0.2372 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.9103 - val_avg_accuracy: 0.9075\n",
      "Epoch 395/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5653 - op_main_loss: 0.1263 - op_conv_loss: 0.0689 - avg_loss: 0.0916 - op_main_accuracy: 0.9610 - op_conv_accuracy: 0.9726 - avg_accuracy: 0.9714\n",
      "Epoch 00395: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5653 - op_main_loss: 0.1263 - op_conv_loss: 0.0689 - avg_loss: 0.0916 - op_main_accuracy: 0.9610 - op_conv_accuracy: 0.9726 - avg_accuracy: 0.9714 - val_loss: 1.0902 - val_op_main_loss: 0.2348 - val_op_conv_loss: 0.3368 - val_avg_loss: 0.2405 - val_op_main_accuracy: 0.9018 - val_op_conv_accuracy: 0.9056 - val_avg_accuracy: 0.9065\n",
      "Epoch 396/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5888 - op_main_loss: 0.1323 - op_conv_loss: 0.0792 - avg_loss: 0.0991 - op_main_accuracy: 0.9557 - op_conv_accuracy: 0.9685 - avg_accuracy: 0.9683\n",
      "Epoch 00396: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5884 - op_main_loss: 0.1322 - op_conv_loss: 0.0791 - avg_loss: 0.0990 - op_main_accuracy: 0.9558 - op_conv_accuracy: 0.9686 - avg_accuracy: 0.9683 - val_loss: 1.1357 - val_op_main_loss: 0.2503 - val_op_conv_loss: 0.3500 - val_avg_loss: 0.2572 - val_op_main_accuracy: 0.8933 - val_op_conv_accuracy: 0.8999 - val_avg_accuracy: 0.9008\n",
      "Epoch 397/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5724 - op_main_loss: 0.1253 - op_conv_loss: 0.0746 - avg_loss: 0.0939 - op_main_accuracy: 0.9608 - op_conv_accuracy: 0.9712 - avg_accuracy: 0.9724\n",
      "Epoch 00397: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5717 - op_main_loss: 0.1252 - op_conv_loss: 0.0743 - avg_loss: 0.0937 - op_main_accuracy: 0.9610 - op_conv_accuracy: 0.9712 - avg_accuracy: 0.9726 - val_loss: 1.1354 - val_op_main_loss: 0.2401 - val_op_conv_loss: 0.3677 - val_avg_loss: 0.2488 - val_op_main_accuracy: 0.9018 - val_op_conv_accuracy: 0.9037 - val_avg_accuracy: 0.9056\n",
      "Epoch 398/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5662 - op_main_loss: 0.1260 - op_conv_loss: 0.0698 - avg_loss: 0.0917 - op_main_accuracy: 0.9563 - op_conv_accuracy: 0.9724 - avg_accuracy: 0.9740\n",
      "Epoch 00398: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5662 - op_main_loss: 0.1260 - op_conv_loss: 0.0698 - avg_loss: 0.0917 - op_main_accuracy: 0.9563 - op_conv_accuracy: 0.9724 - avg_accuracy: 0.9740 - val_loss: 1.0818 - val_op_main_loss: 0.2364 - val_op_conv_loss: 0.3271 - val_avg_loss: 0.2399 - val_op_main_accuracy: 0.9018 - val_op_conv_accuracy: 0.9084 - val_avg_accuracy: 0.9093\n",
      "Epoch 399/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5593 - op_main_loss: 0.1265 - op_conv_loss: 0.0645 - avg_loss: 0.0900 - op_main_accuracy: 0.9551 - op_conv_accuracy: 0.9747 - avg_accuracy: 0.9716\n",
      "Epoch 00399: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5593 - op_main_loss: 0.1265 - op_conv_loss: 0.0645 - avg_loss: 0.0900 - op_main_accuracy: 0.9551 - op_conv_accuracy: 0.9747 - avg_accuracy: 0.9716 - val_loss: 1.0960 - val_op_main_loss: 0.2383 - val_op_conv_loss: 0.3330 - val_avg_loss: 0.2467 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.9037 - val_avg_accuracy: 0.9037\n",
      "Epoch 400/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5697 - op_main_loss: 0.1265 - op_conv_loss: 0.0716 - avg_loss: 0.0930 - op_main_accuracy: 0.9593 - op_conv_accuracy: 0.9699 - avg_accuracy: 0.9716\n",
      "Epoch 00400: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5699 - op_main_loss: 0.1266 - op_conv_loss: 0.0716 - avg_loss: 0.0931 - op_main_accuracy: 0.9591 - op_conv_accuracy: 0.9700 - avg_accuracy: 0.9716 - val_loss: 1.2357 - val_op_main_loss: 0.2636 - val_op_conv_loss: 0.4189 - val_avg_loss: 0.2744 - val_op_main_accuracy: 0.9018 - val_op_conv_accuracy: 0.8961 - val_avg_accuracy: 0.9037\n",
      "Epoch 401/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5843 - op_main_loss: 0.1316 - op_conv_loss: 0.0769 - avg_loss: 0.0970 - op_main_accuracy: 0.9588 - op_conv_accuracy: 0.9690 - avg_accuracy: 0.9695\n",
      "Epoch 00401: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5859 - op_main_loss: 0.1322 - op_conv_loss: 0.0774 - avg_loss: 0.0976 - op_main_accuracy: 0.9586 - op_conv_accuracy: 0.9688 - avg_accuracy: 0.9690 - val_loss: 1.1282 - val_op_main_loss: 0.2390 - val_op_conv_loss: 0.3642 - val_avg_loss: 0.2460 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.9122 - val_avg_accuracy: 0.9084\n",
      "Epoch 402/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/133 [============================>.] - ETA: 0s - loss: 0.6166 - op_main_loss: 0.1424 - op_conv_loss: 0.0886 - avg_loss: 0.1071 - op_main_accuracy: 0.9505 - op_conv_accuracy: 0.9676 - avg_accuracy: 0.9645\n",
      "Epoch 00402: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.6164 - op_main_loss: 0.1423 - op_conv_loss: 0.0885 - avg_loss: 0.1070 - op_main_accuracy: 0.9506 - op_conv_accuracy: 0.9676 - avg_accuracy: 0.9646 - val_loss: 1.1647 - val_op_main_loss: 0.2422 - val_op_conv_loss: 0.3835 - val_avg_loss: 0.2610 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.8924 - val_avg_accuracy: 0.8942\n",
      "Epoch 403/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5682 - op_main_loss: 0.1279 - op_conv_loss: 0.0689 - avg_loss: 0.0932 - op_main_accuracy: 0.9580 - op_conv_accuracy: 0.9735 - avg_accuracy: 0.9721\n",
      "Epoch 00403: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5691 - op_main_loss: 0.1282 - op_conv_loss: 0.0691 - avg_loss: 0.0935 - op_main_accuracy: 0.9579 - op_conv_accuracy: 0.9733 - avg_accuracy: 0.9719 - val_loss: 1.1039 - val_op_main_loss: 0.2404 - val_op_conv_loss: 0.3347 - val_avg_loss: 0.2508 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.8999 - val_avg_accuracy: 0.8980\n",
      "Epoch 404/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5729 - op_main_loss: 0.1278 - op_conv_loss: 0.0729 - avg_loss: 0.0944 - op_main_accuracy: 0.9602 - op_conv_accuracy: 0.9716 - avg_accuracy: 0.9728\n",
      "Epoch 00404: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5719 - op_main_loss: 0.1276 - op_conv_loss: 0.0724 - avg_loss: 0.0941 - op_main_accuracy: 0.9605 - op_conv_accuracy: 0.9719 - avg_accuracy: 0.9731 - val_loss: 1.1237 - val_op_main_loss: 0.2342 - val_op_conv_loss: 0.3633 - val_avg_loss: 0.2484 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.9008 - val_avg_accuracy: 0.9008\n",
      "Epoch 405/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5714 - op_main_loss: 0.1288 - op_conv_loss: 0.0712 - avg_loss: 0.0935 - op_main_accuracy: 0.9552 - op_conv_accuracy: 0.9728 - avg_accuracy: 0.9709\n",
      "Epoch 00405: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5726 - op_main_loss: 0.1290 - op_conv_loss: 0.0717 - avg_loss: 0.0939 - op_main_accuracy: 0.9553 - op_conv_accuracy: 0.9726 - avg_accuracy: 0.9709 - val_loss: 1.1495 - val_op_main_loss: 0.2525 - val_op_conv_loss: 0.3627 - val_avg_loss: 0.2565 - val_op_main_accuracy: 0.8942 - val_op_conv_accuracy: 0.9027 - val_avg_accuracy: 0.8999\n",
      "Epoch 406/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5534 - op_main_loss: 0.1199 - op_conv_loss: 0.0677 - avg_loss: 0.0883 - op_main_accuracy: 0.9649 - op_conv_accuracy: 0.9731 - avg_accuracy: 0.9743\n",
      "Epoch 00406: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5553 - op_main_loss: 0.1203 - op_conv_loss: 0.0686 - avg_loss: 0.0889 - op_main_accuracy: 0.9648 - op_conv_accuracy: 0.9724 - avg_accuracy: 0.9735 - val_loss: 1.1931 - val_op_main_loss: 0.2537 - val_op_conv_loss: 0.3892 - val_avg_loss: 0.2730 - val_op_main_accuracy: 0.8933 - val_op_conv_accuracy: 0.8971 - val_avg_accuracy: 0.8990\n",
      "Epoch 407/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5494 - op_main_loss: 0.1225 - op_conv_loss: 0.0625 - avg_loss: 0.0875 - op_main_accuracy: 0.9613 - op_conv_accuracy: 0.9740 - avg_accuracy: 0.9712\n",
      "Epoch 00407: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5496 - op_main_loss: 0.1224 - op_conv_loss: 0.0627 - avg_loss: 0.0875 - op_main_accuracy: 0.9608 - op_conv_accuracy: 0.9738 - avg_accuracy: 0.9709 - val_loss: 1.0629 - val_op_main_loss: 0.2346 - val_op_conv_loss: 0.3139 - val_avg_loss: 0.2377 - val_op_main_accuracy: 0.9027 - val_op_conv_accuracy: 0.9065 - val_avg_accuracy: 0.9093\n",
      "Epoch 408/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5794 - op_main_loss: 0.1302 - op_conv_loss: 0.0757 - avg_loss: 0.0965 - op_main_accuracy: 0.9564 - op_conv_accuracy: 0.9707 - avg_accuracy: 0.9704\n",
      "Epoch 00408: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5795 - op_main_loss: 0.1303 - op_conv_loss: 0.0756 - avg_loss: 0.0965 - op_main_accuracy: 0.9560 - op_conv_accuracy: 0.9709 - avg_accuracy: 0.9700 - val_loss: 1.1180 - val_op_main_loss: 0.2403 - val_op_conv_loss: 0.3517 - val_avg_loss: 0.2489 - val_op_main_accuracy: 0.9046 - val_op_conv_accuracy: 0.9018 - val_avg_accuracy: 0.8980\n",
      "Epoch 409/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5540 - op_main_loss: 0.1236 - op_conv_loss: 0.0652 - avg_loss: 0.0881 - op_main_accuracy: 0.9642 - op_conv_accuracy: 0.9750 - avg_accuracy: 0.9733\n",
      "Epoch 00409: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5559 - op_main_loss: 0.1243 - op_conv_loss: 0.0658 - avg_loss: 0.0887 - op_main_accuracy: 0.9636 - op_conv_accuracy: 0.9747 - avg_accuracy: 0.9728 - val_loss: 1.0888 - val_op_main_loss: 0.2394 - val_op_conv_loss: 0.3287 - val_avg_loss: 0.2440 - val_op_main_accuracy: 0.9027 - val_op_conv_accuracy: 0.9075 - val_avg_accuracy: 0.9084\n",
      "Epoch 410/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5614 - op_main_loss: 0.1278 - op_conv_loss: 0.0655 - avg_loss: 0.0917 - op_main_accuracy: 0.9579 - op_conv_accuracy: 0.9732 - avg_accuracy: 0.9725\n",
      "Epoch 00410: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5612 - op_main_loss: 0.1277 - op_conv_loss: 0.0654 - avg_loss: 0.0916 - op_main_accuracy: 0.9579 - op_conv_accuracy: 0.9733 - avg_accuracy: 0.9726 - val_loss: 1.2228 - val_op_main_loss: 0.2499 - val_op_conv_loss: 0.4271 - val_avg_loss: 0.2690 - val_op_main_accuracy: 0.9075 - val_op_conv_accuracy: 0.8895 - val_avg_accuracy: 0.8952\n",
      "Epoch 411/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5542 - op_main_loss: 0.1238 - op_conv_loss: 0.0654 - avg_loss: 0.0883 - op_main_accuracy: 0.9600 - op_conv_accuracy: 0.9754 - avg_accuracy: 0.9732\n",
      "Epoch 00411: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5537 - op_main_loss: 0.1236 - op_conv_loss: 0.0652 - avg_loss: 0.0881 - op_main_accuracy: 0.9601 - op_conv_accuracy: 0.9754 - avg_accuracy: 0.9733 - val_loss: 1.1691 - val_op_main_loss: 0.2685 - val_op_conv_loss: 0.3523 - val_avg_loss: 0.2716 - val_op_main_accuracy: 0.8952 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.8971\n",
      "Epoch 412/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5554 - op_main_loss: 0.1257 - op_conv_loss: 0.0646 - avg_loss: 0.0889 - op_main_accuracy: 0.9591 - op_conv_accuracy: 0.9752 - avg_accuracy: 0.9728\n",
      "Epoch 00412: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5549 - op_main_loss: 0.1253 - op_conv_loss: 0.0646 - avg_loss: 0.0888 - op_main_accuracy: 0.9596 - op_conv_accuracy: 0.9752 - avg_accuracy: 0.9728 - val_loss: 1.1598 - val_op_main_loss: 0.2374 - val_op_conv_loss: 0.3877 - val_avg_loss: 0.2588 - val_op_main_accuracy: 0.8971 - val_op_conv_accuracy: 0.8961 - val_avg_accuracy: 0.9018\n",
      "Epoch 413/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5470 - op_main_loss: 0.1199 - op_conv_loss: 0.0650 - avg_loss: 0.0864 - op_main_accuracy: 0.9614 - op_conv_accuracy: 0.9769 - avg_accuracy: 0.9754\n",
      "Epoch 00413: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5474 - op_main_loss: 0.1201 - op_conv_loss: 0.0651 - avg_loss: 0.0866 - op_main_accuracy: 0.9610 - op_conv_accuracy: 0.9768 - avg_accuracy: 0.9754 - val_loss: 1.1049 - val_op_main_loss: 0.2357 - val_op_conv_loss: 0.3516 - val_avg_loss: 0.2418 - val_op_main_accuracy: 0.9065 - val_op_conv_accuracy: 0.9093 - val_avg_accuracy: 0.9084\n",
      "Epoch 414/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/133 [============================>.] - ETA: 0s - loss: 0.5846 - op_main_loss: 0.1332 - op_conv_loss: 0.0776 - avg_loss: 0.0978 - op_main_accuracy: 0.9550 - op_conv_accuracy: 0.9695 - avg_accuracy: 0.9692\n",
      "Epoch 00414: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5841 - op_main_loss: 0.1331 - op_conv_loss: 0.0775 - avg_loss: 0.0977 - op_main_accuracy: 0.9551 - op_conv_accuracy: 0.9695 - avg_accuracy: 0.9693 - val_loss: 1.1046 - val_op_main_loss: 0.2382 - val_op_conv_loss: 0.3480 - val_avg_loss: 0.2426 - val_op_main_accuracy: 0.8971 - val_op_conv_accuracy: 0.9018 - val_avg_accuracy: 0.9056\n",
      "Epoch 415/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5967 - op_main_loss: 0.1353 - op_conv_loss: 0.0838 - avg_loss: 0.1020 - op_main_accuracy: 0.9523 - op_conv_accuracy: 0.9662 - avg_accuracy: 0.9638\n",
      "Epoch 00415: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5967 - op_main_loss: 0.1353 - op_conv_loss: 0.0838 - avg_loss: 0.1020 - op_main_accuracy: 0.9523 - op_conv_accuracy: 0.9662 - avg_accuracy: 0.9638 - val_loss: 1.3619 - val_op_main_loss: 0.2938 - val_op_conv_loss: 0.4792 - val_avg_loss: 0.3134 - val_op_main_accuracy: 0.8886 - val_op_conv_accuracy: 0.8744 - val_avg_accuracy: 0.8829\n",
      "Epoch 416/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5382 - op_main_loss: 0.1184 - op_conv_loss: 0.0596 - avg_loss: 0.0844 - op_main_accuracy: 0.9629 - op_conv_accuracy: 0.9780 - avg_accuracy: 0.9783\n",
      "Epoch 00416: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5382 - op_main_loss: 0.1184 - op_conv_loss: 0.0596 - avg_loss: 0.0844 - op_main_accuracy: 0.9629 - op_conv_accuracy: 0.9780 - avg_accuracy: 0.9783 - val_loss: 1.1011 - val_op_main_loss: 0.2433 - val_op_conv_loss: 0.3360 - val_avg_loss: 0.2461 - val_op_main_accuracy: 0.8961 - val_op_conv_accuracy: 0.9075 - val_avg_accuracy: 0.9056\n",
      "Epoch 417/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5895 - op_main_loss: 0.1379 - op_conv_loss: 0.0789 - avg_loss: 0.0981 - op_main_accuracy: 0.9548 - op_conv_accuracy: 0.9755 - avg_accuracy: 0.9712\n",
      "Epoch 00417: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5882 - op_main_loss: 0.1378 - op_conv_loss: 0.0781 - avg_loss: 0.0978 - op_main_accuracy: 0.9546 - op_conv_accuracy: 0.9757 - avg_accuracy: 0.9714 - val_loss: 1.0821 - val_op_main_loss: 0.2265 - val_op_conv_loss: 0.3440 - val_avg_loss: 0.2376 - val_op_main_accuracy: 0.9018 - val_op_conv_accuracy: 0.9027 - val_avg_accuracy: 0.9027\n",
      "Epoch 418/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5557 - op_main_loss: 0.1244 - op_conv_loss: 0.0668 - avg_loss: 0.0901 - op_main_accuracy: 0.9583 - op_conv_accuracy: 0.9736 - avg_accuracy: 0.9750\n",
      "Epoch 00418: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5594 - op_main_loss: 0.1256 - op_conv_loss: 0.0680 - avg_loss: 0.0913 - op_main_accuracy: 0.9575 - op_conv_accuracy: 0.9726 - avg_accuracy: 0.9745 - val_loss: 1.0947 - val_op_main_loss: 0.2302 - val_op_conv_loss: 0.3500 - val_avg_loss: 0.2398 - val_op_main_accuracy: 0.9027 - val_op_conv_accuracy: 0.8999 - val_avg_accuracy: 0.9056\n",
      "Epoch 419/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5611 - op_main_loss: 0.1226 - op_conv_loss: 0.0721 - avg_loss: 0.0917 - op_main_accuracy: 0.9611 - op_conv_accuracy: 0.9733 - avg_accuracy: 0.9740\n",
      "Epoch 00419: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5601 - op_main_loss: 0.1224 - op_conv_loss: 0.0716 - avg_loss: 0.0914 - op_main_accuracy: 0.9612 - op_conv_accuracy: 0.9735 - avg_accuracy: 0.9742 - val_loss: 1.0681 - val_op_main_loss: 0.2322 - val_op_conv_loss: 0.3237 - val_avg_loss: 0.2376 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9075\n",
      "Epoch 420/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5561 - op_main_loss: 0.1255 - op_conv_loss: 0.0665 - avg_loss: 0.0894 - op_main_accuracy: 0.9560 - op_conv_accuracy: 0.9742 - avg_accuracy: 0.9718\n",
      "Epoch 00420: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.5556 - op_main_loss: 0.1253 - op_conv_loss: 0.0664 - avg_loss: 0.0893 - op_main_accuracy: 0.9560 - op_conv_accuracy: 0.9742 - avg_accuracy: 0.9719 - val_loss: 1.1244 - val_op_main_loss: 0.2455 - val_op_conv_loss: 0.3517 - val_avg_loss: 0.2527 - val_op_main_accuracy: 0.8952 - val_op_conv_accuracy: 0.8961 - val_avg_accuracy: 0.9084\n",
      "Epoch 421/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5548 - op_main_loss: 0.1241 - op_conv_loss: 0.0663 - avg_loss: 0.0900 - op_main_accuracy: 0.9586 - op_conv_accuracy: 0.9709 - avg_accuracy: 0.9706\n",
      "Epoch 00421: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.5548 - op_main_loss: 0.1242 - op_conv_loss: 0.0663 - avg_loss: 0.0900 - op_main_accuracy: 0.9586 - op_conv_accuracy: 0.9709 - avg_accuracy: 0.9707 - val_loss: 1.4375 - val_op_main_loss: 0.3087 - val_op_conv_loss: 0.5094 - val_avg_loss: 0.3447 - val_op_main_accuracy: 0.8754 - val_op_conv_accuracy: 0.8650 - val_avg_accuracy: 0.8678\n",
      "Epoch 422/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5474 - op_main_loss: 0.1226 - op_conv_loss: 0.0628 - avg_loss: 0.0870 - op_main_accuracy: 0.9590 - op_conv_accuracy: 0.9759 - avg_accuracy: 0.9747\n",
      "Epoch 00422: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.5456 - op_main_loss: 0.1218 - op_conv_loss: 0.0623 - avg_loss: 0.0865 - op_main_accuracy: 0.9594 - op_conv_accuracy: 0.9761 - avg_accuracy: 0.9750 - val_loss: 1.1873 - val_op_main_loss: 0.2559 - val_op_conv_loss: 0.3850 - val_avg_loss: 0.2715 - val_op_main_accuracy: 0.8942 - val_op_conv_accuracy: 0.8961 - val_avg_accuracy: 0.8971\n",
      "Epoch 423/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5566 - op_main_loss: 0.1228 - op_conv_loss: 0.0691 - avg_loss: 0.0899 - op_main_accuracy: 0.9582 - op_conv_accuracy: 0.9740 - avg_accuracy: 0.9719\n",
      "Epoch 00423: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.5566 - op_main_loss: 0.1228 - op_conv_loss: 0.0691 - avg_loss: 0.0899 - op_main_accuracy: 0.9582 - op_conv_accuracy: 0.9740 - avg_accuracy: 0.9719 - val_loss: 1.1502 - val_op_main_loss: 0.2389 - val_op_conv_loss: 0.3820 - val_avg_loss: 0.2545 - val_op_main_accuracy: 0.9027 - val_op_conv_accuracy: 0.8933 - val_avg_accuracy: 0.8980\n",
      "Epoch 424/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5878 - op_main_loss: 0.1325 - op_conv_loss: 0.0825 - avg_loss: 0.0986 - op_main_accuracy: 0.9554 - op_conv_accuracy: 0.9711 - avg_accuracy: 0.9707\n",
      "Epoch 00424: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5857 - op_main_loss: 0.1318 - op_conv_loss: 0.0818 - avg_loss: 0.0979 - op_main_accuracy: 0.9558 - op_conv_accuracy: 0.9714 - avg_accuracy: 0.9709 - val_loss: 1.0562 - val_op_main_loss: 0.2327 - val_op_conv_loss: 0.3156 - val_avg_loss: 0.2338 - val_op_main_accuracy: 0.9027 - val_op_conv_accuracy: 0.9075 - val_avg_accuracy: 0.9075\n",
      "Epoch 425/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5931 - op_main_loss: 0.1376 - op_conv_loss: 0.0793 - avg_loss: 0.1016 - op_main_accuracy: 0.9522 - op_conv_accuracy: 0.9688 - avg_accuracy: 0.9678\n",
      "Epoch 00425: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5928 - op_main_loss: 0.1375 - op_conv_loss: 0.0791 - avg_loss: 0.1015 - op_main_accuracy: 0.9523 - op_conv_accuracy: 0.9688 - avg_accuracy: 0.9679 - val_loss: 1.1671 - val_op_main_loss: 0.2436 - val_op_conv_loss: 0.3861 - val_avg_loss: 0.2624 - val_op_main_accuracy: 0.8980 - val_op_conv_accuracy: 0.8895 - val_avg_accuracy: 0.8961\n",
      "Epoch 426/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/133 [============================>.] - ETA: 0s - loss: 0.5363 - op_main_loss: 0.1162 - op_conv_loss: 0.0617 - avg_loss: 0.0836 - op_main_accuracy: 0.9627 - op_conv_accuracy: 0.9784 - avg_accuracy: 0.9740\n",
      "Epoch 00426: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5346 - op_main_loss: 0.1154 - op_conv_loss: 0.0613 - avg_loss: 0.0831 - op_main_accuracy: 0.9631 - op_conv_accuracy: 0.9783 - avg_accuracy: 0.9742 - val_loss: 1.1362 - val_op_main_loss: 0.2373 - val_op_conv_loss: 0.3769 - val_avg_loss: 0.2474 - val_op_main_accuracy: 0.9046 - val_op_conv_accuracy: 0.9027 - val_avg_accuracy: 0.9075\n",
      "Epoch 427/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5385 - op_main_loss: 0.1180 - op_conv_loss: 0.0618 - avg_loss: 0.0844 - op_main_accuracy: 0.9598 - op_conv_accuracy: 0.9765 - avg_accuracy: 0.9753\n",
      "Epoch 00427: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.5368 - op_main_loss: 0.1175 - op_conv_loss: 0.0611 - avg_loss: 0.0839 - op_main_accuracy: 0.9598 - op_conv_accuracy: 0.9768 - avg_accuracy: 0.9754 - val_loss: 1.1235 - val_op_main_loss: 0.2439 - val_op_conv_loss: 0.3541 - val_avg_loss: 0.2515 - val_op_main_accuracy: 0.9037 - val_op_conv_accuracy: 0.8990 - val_avg_accuracy: 0.9008\n",
      "Epoch 428/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5631 - op_main_loss: 0.1232 - op_conv_loss: 0.0735 - avg_loss: 0.0925 - op_main_accuracy: 0.9599 - op_conv_accuracy: 0.9704 - avg_accuracy: 0.9712\n",
      "Epoch 00428: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5683 - op_main_loss: 0.1243 - op_conv_loss: 0.0760 - avg_loss: 0.0941 - op_main_accuracy: 0.9591 - op_conv_accuracy: 0.9693 - avg_accuracy: 0.9700 - val_loss: 1.1519 - val_op_main_loss: 0.2518 - val_op_conv_loss: 0.3676 - val_avg_loss: 0.2586 - val_op_main_accuracy: 0.9018 - val_op_conv_accuracy: 0.9037 - val_avg_accuracy: 0.8999\n",
      "Epoch 429/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5752 - op_main_loss: 0.1232 - op_conv_loss: 0.0825 - avg_loss: 0.0963 - op_main_accuracy: 0.9603 - op_conv_accuracy: 0.9661 - avg_accuracy: 0.9692\n",
      "Epoch 00429: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5756 - op_main_loss: 0.1238 - op_conv_loss: 0.0823 - avg_loss: 0.0964 - op_main_accuracy: 0.9598 - op_conv_accuracy: 0.9662 - avg_accuracy: 0.9693 - val_loss: 1.1498 - val_op_main_loss: 0.2437 - val_op_conv_loss: 0.3758 - val_avg_loss: 0.2572 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.9018 - val_avg_accuracy: 0.9027\n",
      "Epoch 430/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5657 - op_main_loss: 0.1251 - op_conv_loss: 0.0743 - avg_loss: 0.0931 - op_main_accuracy: 0.9602 - op_conv_accuracy: 0.9718 - avg_accuracy: 0.9728\n",
      "Epoch 00430: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5659 - op_main_loss: 0.1252 - op_conv_loss: 0.0744 - avg_loss: 0.0932 - op_main_accuracy: 0.9601 - op_conv_accuracy: 0.9716 - avg_accuracy: 0.9726 - val_loss: 1.1115 - val_op_main_loss: 0.2399 - val_op_conv_loss: 0.3532 - val_avg_loss: 0.2449 - val_op_main_accuracy: 0.9027 - val_op_conv_accuracy: 0.9122 - val_avg_accuracy: 0.9112\n",
      "Epoch 431/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5749 - op_main_loss: 0.1281 - op_conv_loss: 0.0770 - avg_loss: 0.0963 - op_main_accuracy: 0.9590 - op_conv_accuracy: 0.9702 - avg_accuracy: 0.9697\n",
      "Epoch 00431: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5731 - op_main_loss: 0.1275 - op_conv_loss: 0.0764 - avg_loss: 0.0957 - op_main_accuracy: 0.9594 - op_conv_accuracy: 0.9705 - avg_accuracy: 0.9700 - val_loss: 1.0939 - val_op_main_loss: 0.2374 - val_op_conv_loss: 0.3417 - val_avg_loss: 0.2413 - val_op_main_accuracy: 0.8999 - val_op_conv_accuracy: 0.8980 - val_avg_accuracy: 0.9046\n",
      "Epoch 432/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5362 - op_main_loss: 0.1171 - op_conv_loss: 0.0611 - avg_loss: 0.0845 - op_main_accuracy: 0.9630 - op_conv_accuracy: 0.9747 - avg_accuracy: 0.9750\n",
      "Epoch 00432: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5361 - op_main_loss: 0.1170 - op_conv_loss: 0.0611 - avg_loss: 0.0845 - op_main_accuracy: 0.9631 - op_conv_accuracy: 0.9747 - avg_accuracy: 0.9752 - val_loss: 1.0718 - val_op_main_loss: 0.2366 - val_op_conv_loss: 0.3244 - val_avg_loss: 0.2376 - val_op_main_accuracy: 0.9037 - val_op_conv_accuracy: 0.9056 - val_avg_accuracy: 0.9093\n",
      "Epoch 433/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5468 - op_main_loss: 0.1218 - op_conv_loss: 0.0646 - avg_loss: 0.0874 - op_main_accuracy: 0.9612 - op_conv_accuracy: 0.9753 - avg_accuracy: 0.9743\n",
      "Epoch 00433: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5469 - op_main_loss: 0.1218 - op_conv_loss: 0.0646 - avg_loss: 0.0875 - op_main_accuracy: 0.9612 - op_conv_accuracy: 0.9750 - avg_accuracy: 0.9740 - val_loss: 1.0910 - val_op_main_loss: 0.2352 - val_op_conv_loss: 0.3420 - val_avg_loss: 0.2411 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.9075 - val_avg_accuracy: 0.9103\n",
      "Epoch 434/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5481 - op_main_loss: 0.1223 - op_conv_loss: 0.0652 - avg_loss: 0.0883 - op_main_accuracy: 0.9581 - op_conv_accuracy: 0.9737 - avg_accuracy: 0.9718\n",
      "Epoch 00434: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5479 - op_main_loss: 0.1223 - op_conv_loss: 0.0651 - avg_loss: 0.0883 - op_main_accuracy: 0.9582 - op_conv_accuracy: 0.9738 - avg_accuracy: 0.9719 - val_loss: 1.2139 - val_op_main_loss: 0.2604 - val_op_conv_loss: 0.4079 - val_avg_loss: 0.2735 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.9008 - val_avg_accuracy: 0.9037\n",
      "Epoch 435/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5780 - op_main_loss: 0.1318 - op_conv_loss: 0.0772 - avg_loss: 0.0965 - op_main_accuracy: 0.9542 - op_conv_accuracy: 0.9731 - avg_accuracy: 0.9700\n",
      "Epoch 00435: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5780 - op_main_loss: 0.1318 - op_conv_loss: 0.0772 - avg_loss: 0.0965 - op_main_accuracy: 0.9542 - op_conv_accuracy: 0.9731 - avg_accuracy: 0.9700 - val_loss: 1.0661 - val_op_main_loss: 0.2371 - val_op_conv_loss: 0.3150 - val_avg_loss: 0.2413 - val_op_main_accuracy: 0.8980 - val_op_conv_accuracy: 0.9065 - val_avg_accuracy: 0.9075\n",
      "Epoch 436/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5478 - op_main_loss: 0.1227 - op_conv_loss: 0.0642 - avg_loss: 0.0883 - op_main_accuracy: 0.9595 - op_conv_accuracy: 0.9760 - avg_accuracy: 0.9746\n",
      "Epoch 00436: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5470 - op_main_loss: 0.1228 - op_conv_loss: 0.0636 - avg_loss: 0.0881 - op_main_accuracy: 0.9591 - op_conv_accuracy: 0.9761 - avg_accuracy: 0.9747 - val_loss: 1.4533 - val_op_main_loss: 0.2583 - val_op_conv_loss: 0.6069 - val_avg_loss: 0.3152 - val_op_main_accuracy: 0.8961 - val_op_conv_accuracy: 0.8517 - val_avg_accuracy: 0.8697\n",
      "Epoch 437/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5481 - op_main_loss: 0.1198 - op_conv_loss: 0.0680 - avg_loss: 0.0877 - op_main_accuracy: 0.9624 - op_conv_accuracy: 0.9742 - avg_accuracy: 0.9723\n",
      "Epoch 00437: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5476 - op_main_loss: 0.1196 - op_conv_loss: 0.0679 - avg_loss: 0.0876 - op_main_accuracy: 0.9624 - op_conv_accuracy: 0.9742 - avg_accuracy: 0.9724 - val_loss: 1.2258 - val_op_main_loss: 0.2334 - val_op_conv_loss: 0.4546 - val_avg_loss: 0.2651 - val_op_main_accuracy: 0.8961 - val_op_conv_accuracy: 0.8763 - val_avg_accuracy: 0.8914\n",
      "Epoch 438/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/133 [============================>.] - ETA: 0s - loss: 0.5463 - op_main_loss: 0.1200 - op_conv_loss: 0.0664 - avg_loss: 0.0871 - op_main_accuracy: 0.9627 - op_conv_accuracy: 0.9748 - avg_accuracy: 0.9760\n",
      "Epoch 00438: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5451 - op_main_loss: 0.1196 - op_conv_loss: 0.0660 - avg_loss: 0.0868 - op_main_accuracy: 0.9629 - op_conv_accuracy: 0.9750 - avg_accuracy: 0.9761 - val_loss: 1.0897 - val_op_main_loss: 0.2371 - val_op_conv_loss: 0.3379 - val_avg_loss: 0.2422 - val_op_main_accuracy: 0.9027 - val_op_conv_accuracy: 0.9122 - val_avg_accuracy: 0.9122\n",
      "Epoch 439/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5422 - op_main_loss: 0.1222 - op_conv_loss: 0.0613 - avg_loss: 0.0858 - op_main_accuracy: 0.9624 - op_conv_accuracy: 0.9766 - avg_accuracy: 0.9759\n",
      "Epoch 00439: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5422 - op_main_loss: 0.1222 - op_conv_loss: 0.0613 - avg_loss: 0.0858 - op_main_accuracy: 0.9624 - op_conv_accuracy: 0.9766 - avg_accuracy: 0.9759 - val_loss: 1.2317 - val_op_main_loss: 0.2597 - val_op_conv_loss: 0.4181 - val_avg_loss: 0.2809 - val_op_main_accuracy: 0.8980 - val_op_conv_accuracy: 0.8971 - val_avg_accuracy: 0.8990\n",
      "Epoch 440/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5543 - op_main_loss: 0.1202 - op_conv_loss: 0.0713 - avg_loss: 0.0902 - op_main_accuracy: 0.9610 - op_conv_accuracy: 0.9700 - avg_accuracy: 0.9707\n",
      "Epoch 00440: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5529 - op_main_loss: 0.1197 - op_conv_loss: 0.0709 - avg_loss: 0.0898 - op_main_accuracy: 0.9620 - op_conv_accuracy: 0.9702 - avg_accuracy: 0.9709 - val_loss: 1.1406 - val_op_main_loss: 0.2401 - val_op_conv_loss: 0.3735 - val_avg_loss: 0.2552 - val_op_main_accuracy: 0.9027 - val_op_conv_accuracy: 0.9018 - val_avg_accuracy: 0.9018\n",
      "Epoch 441/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5786 - op_main_loss: 0.1300 - op_conv_loss: 0.0796 - avg_loss: 0.0970 - op_main_accuracy: 0.9550 - op_conv_accuracy: 0.9706 - avg_accuracy: 0.9702\n",
      "Epoch 00441: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 0.5783 - op_main_loss: 0.1299 - op_conv_loss: 0.0795 - avg_loss: 0.0969 - op_main_accuracy: 0.9551 - op_conv_accuracy: 0.9707 - avg_accuracy: 0.9702 - val_loss: 1.0570 - val_op_main_loss: 0.2296 - val_op_conv_loss: 0.3235 - val_avg_loss: 0.2321 - val_op_main_accuracy: 0.9065 - val_op_conv_accuracy: 0.9056 - val_avg_accuracy: 0.9103\n",
      "Epoch 442/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5594 - op_main_loss: 0.1238 - op_conv_loss: 0.0717 - avg_loss: 0.0917 - op_main_accuracy: 0.9599 - op_conv_accuracy: 0.9719 - avg_accuracy: 0.9721\n",
      "Epoch 00442: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5595 - op_main_loss: 0.1239 - op_conv_loss: 0.0717 - avg_loss: 0.0917 - op_main_accuracy: 0.9598 - op_conv_accuracy: 0.9719 - avg_accuracy: 0.9724 - val_loss: 1.5565 - val_op_main_loss: 0.2473 - val_op_conv_loss: 0.7235 - val_avg_loss: 0.3130 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.8470 - val_avg_accuracy: 0.8584\n",
      "Epoch 443/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5548 - op_main_loss: 0.1199 - op_conv_loss: 0.0719 - avg_loss: 0.0899 - op_main_accuracy: 0.9632 - op_conv_accuracy: 0.9728 - avg_accuracy: 0.9736\n",
      "Epoch 00443: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5545 - op_main_loss: 0.1199 - op_conv_loss: 0.0717 - avg_loss: 0.0899 - op_main_accuracy: 0.9631 - op_conv_accuracy: 0.9728 - avg_accuracy: 0.9735 - val_loss: 1.2085 - val_op_main_loss: 0.2355 - val_op_conv_loss: 0.4391 - val_avg_loss: 0.2612 - val_op_main_accuracy: 0.9046 - val_op_conv_accuracy: 0.8867 - val_avg_accuracy: 0.8952\n",
      "Epoch 444/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5585 - op_main_loss: 0.1247 - op_conv_loss: 0.0695 - avg_loss: 0.0913 - op_main_accuracy: 0.9570 - op_conv_accuracy: 0.9709 - avg_accuracy: 0.9712\n",
      "Epoch 00444: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5585 - op_main_loss: 0.1247 - op_conv_loss: 0.0695 - avg_loss: 0.0913 - op_main_accuracy: 0.9570 - op_conv_accuracy: 0.9709 - avg_accuracy: 0.9712 - val_loss: 1.1474 - val_op_main_loss: 0.2520 - val_op_conv_loss: 0.3586 - val_avg_loss: 0.2640 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.8980 - val_avg_accuracy: 0.8990\n",
      "Epoch 445/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5475 - op_main_loss: 0.1230 - op_conv_loss: 0.0639 - avg_loss: 0.0874 - op_main_accuracy: 0.9584 - op_conv_accuracy: 0.9773 - avg_accuracy: 0.9752\n",
      "Epoch 00445: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5475 - op_main_loss: 0.1230 - op_conv_loss: 0.0639 - avg_loss: 0.0874 - op_main_accuracy: 0.9584 - op_conv_accuracy: 0.9773 - avg_accuracy: 0.9752 - val_loss: 1.0989 - val_op_main_loss: 0.2346 - val_op_conv_loss: 0.3555 - val_avg_loss: 0.2356 - val_op_main_accuracy: 0.9018 - val_op_conv_accuracy: 0.9065 - val_avg_accuracy: 0.9131\n",
      "Epoch 446/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5669 - op_main_loss: 0.1291 - op_conv_loss: 0.0707 - avg_loss: 0.0935 - op_main_accuracy: 0.9571 - op_conv_accuracy: 0.9726 - avg_accuracy: 0.9697\n",
      "Epoch 00446: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5671 - op_main_loss: 0.1291 - op_conv_loss: 0.0708 - avg_loss: 0.0936 - op_main_accuracy: 0.9570 - op_conv_accuracy: 0.9726 - avg_accuracy: 0.9698 - val_loss: 1.1937 - val_op_main_loss: 0.2677 - val_op_conv_loss: 0.3769 - val_avg_loss: 0.2753 - val_op_main_accuracy: 0.8971 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9046\n",
      "Epoch 447/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5288 - op_main_loss: 0.1135 - op_conv_loss: 0.0601 - avg_loss: 0.0816 - op_main_accuracy: 0.9673 - op_conv_accuracy: 0.9777 - avg_accuracy: 0.9784\n",
      "Epoch 00447: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5285 - op_main_loss: 0.1132 - op_conv_loss: 0.0603 - avg_loss: 0.0815 - op_main_accuracy: 0.9679 - op_conv_accuracy: 0.9776 - avg_accuracy: 0.9783 - val_loss: 1.1943 - val_op_main_loss: 0.2461 - val_op_conv_loss: 0.4080 - val_avg_loss: 0.2670 - val_op_main_accuracy: 0.8980 - val_op_conv_accuracy: 0.8971 - val_avg_accuracy: 0.9018\n",
      "Epoch 448/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5484 - op_main_loss: 0.1212 - op_conv_loss: 0.0666 - avg_loss: 0.0873 - op_main_accuracy: 0.9592 - op_conv_accuracy: 0.9735 - avg_accuracy: 0.9738\n",
      "Epoch 00448: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5485 - op_main_loss: 0.1211 - op_conv_loss: 0.0668 - avg_loss: 0.0874 - op_main_accuracy: 0.9591 - op_conv_accuracy: 0.9735 - avg_accuracy: 0.9738 - val_loss: 1.4276 - val_op_main_loss: 0.2642 - val_op_conv_loss: 0.5793 - val_avg_loss: 0.3106 - val_op_main_accuracy: 0.8952 - val_op_conv_accuracy: 0.8659 - val_avg_accuracy: 0.8772\n",
      "Epoch 449/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5701 - op_main_loss: 0.1290 - op_conv_loss: 0.0740 - avg_loss: 0.0938 - op_main_accuracy: 0.9576 - op_conv_accuracy: 0.9719 - avg_accuracy: 0.9724\n",
      "Epoch 00449: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5685 - op_main_loss: 0.1280 - op_conv_loss: 0.0739 - avg_loss: 0.0933 - op_main_accuracy: 0.9582 - op_conv_accuracy: 0.9719 - avg_accuracy: 0.9726 - val_loss: 1.1649 - val_op_main_loss: 0.2397 - val_op_conv_loss: 0.3924 - val_avg_loss: 0.2597 - val_op_main_accuracy: 0.8952 - val_op_conv_accuracy: 0.8990 - val_avg_accuracy: 0.8971\n",
      "Epoch 450/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/133 [============================>.] - ETA: 0s - loss: 0.5573 - op_main_loss: 0.1233 - op_conv_loss: 0.0701 - avg_loss: 0.0906 - op_main_accuracy: 0.9593 - op_conv_accuracy: 0.9704 - avg_accuracy: 0.9697\n",
      "Epoch 00450: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5572 - op_main_loss: 0.1232 - op_conv_loss: 0.0701 - avg_loss: 0.0906 - op_main_accuracy: 0.9594 - op_conv_accuracy: 0.9705 - avg_accuracy: 0.9698 - val_loss: 1.1795 - val_op_main_loss: 0.2539 - val_op_conv_loss: 0.3820 - val_avg_loss: 0.2701 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.9008 - val_avg_accuracy: 0.8980\n",
      "Epoch 451/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5758 - op_main_loss: 0.1304 - op_conv_loss: 0.0767 - avg_loss: 0.0956 - op_main_accuracy: 0.9560 - op_conv_accuracy: 0.9721 - avg_accuracy: 0.9695\n",
      "Epoch 00451: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.5760 - op_main_loss: 0.1306 - op_conv_loss: 0.0766 - avg_loss: 0.0957 - op_main_accuracy: 0.9558 - op_conv_accuracy: 0.9721 - avg_accuracy: 0.9695 - val_loss: 1.2723 - val_op_main_loss: 0.2442 - val_op_conv_loss: 0.4821 - val_avg_loss: 0.2728 - val_op_main_accuracy: 0.9065 - val_op_conv_accuracy: 0.8829 - val_avg_accuracy: 0.8952\n",
      "Epoch 452/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5445 - op_main_loss: 0.1211 - op_conv_loss: 0.0641 - avg_loss: 0.0861 - op_main_accuracy: 0.9615 - op_conv_accuracy: 0.9769 - avg_accuracy: 0.9748\n",
      "Epoch 00452: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5458 - op_main_loss: 0.1218 - op_conv_loss: 0.0644 - avg_loss: 0.0865 - op_main_accuracy: 0.9610 - op_conv_accuracy: 0.9766 - avg_accuracy: 0.9740 - val_loss: 1.0909 - val_op_main_loss: 0.2294 - val_op_conv_loss: 0.3471 - val_avg_loss: 0.2413 - val_op_main_accuracy: 0.8999 - val_op_conv_accuracy: 0.8990 - val_avg_accuracy: 0.9027\n",
      "Epoch 453/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5596 - op_main_loss: 0.1280 - op_conv_loss: 0.0675 - avg_loss: 0.0911 - op_main_accuracy: 0.9577 - op_conv_accuracy: 0.9736 - avg_accuracy: 0.9728\n",
      "Epoch 00453: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5612 - op_main_loss: 0.1284 - op_conv_loss: 0.0681 - avg_loss: 0.0916 - op_main_accuracy: 0.9579 - op_conv_accuracy: 0.9738 - avg_accuracy: 0.9731 - val_loss: 1.1243 - val_op_main_loss: 0.2526 - val_op_conv_loss: 0.3447 - val_avg_loss: 0.2542 - val_op_main_accuracy: 0.8952 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9027\n",
      "Epoch 454/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5410 - op_main_loss: 0.1185 - op_conv_loss: 0.0636 - avg_loss: 0.0858 - op_main_accuracy: 0.9608 - op_conv_accuracy: 0.9753 - avg_accuracy: 0.9741\n",
      "Epoch 00454: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5406 - op_main_loss: 0.1185 - op_conv_loss: 0.0634 - avg_loss: 0.0857 - op_main_accuracy: 0.9605 - op_conv_accuracy: 0.9754 - avg_accuracy: 0.9740 - val_loss: 1.1014 - val_op_main_loss: 0.2458 - val_op_conv_loss: 0.3360 - val_avg_loss: 0.2465 - val_op_main_accuracy: 0.8961 - val_op_conv_accuracy: 0.9112 - val_avg_accuracy: 0.9046\n",
      "Epoch 455/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5621 - op_main_loss: 0.1221 - op_conv_loss: 0.0755 - avg_loss: 0.0917 - op_main_accuracy: 0.9610 - op_conv_accuracy: 0.9690 - avg_accuracy: 0.9714\n",
      "Epoch 00455: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5621 - op_main_loss: 0.1221 - op_conv_loss: 0.0755 - avg_loss: 0.0917 - op_main_accuracy: 0.9610 - op_conv_accuracy: 0.9690 - avg_accuracy: 0.9714 - val_loss: 1.1594 - val_op_main_loss: 0.2337 - val_op_conv_loss: 0.3992 - val_avg_loss: 0.2537 - val_op_main_accuracy: 0.9027 - val_op_conv_accuracy: 0.8980 - val_avg_accuracy: 0.8980\n",
      "Epoch 456/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5392 - op_main_loss: 0.1170 - op_conv_loss: 0.0643 - avg_loss: 0.0853 - op_main_accuracy: 0.9603 - op_conv_accuracy: 0.9745 - avg_accuracy: 0.9733\n",
      "Epoch 00456: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5421 - op_main_loss: 0.1179 - op_conv_loss: 0.0653 - avg_loss: 0.0863 - op_main_accuracy: 0.9601 - op_conv_accuracy: 0.9740 - avg_accuracy: 0.9728 - val_loss: 1.2570 - val_op_main_loss: 0.2638 - val_op_conv_loss: 0.4340 - val_avg_loss: 0.2867 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.8933 - val_avg_accuracy: 0.8980\n",
      "Epoch 457/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5711 - op_main_loss: 0.1292 - op_conv_loss: 0.0750 - avg_loss: 0.0941 - op_main_accuracy: 0.9552 - op_conv_accuracy: 0.9702 - avg_accuracy: 0.9695\n",
      "Epoch 00457: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5698 - op_main_loss: 0.1290 - op_conv_loss: 0.0742 - avg_loss: 0.0937 - op_main_accuracy: 0.9553 - op_conv_accuracy: 0.9705 - avg_accuracy: 0.9695 - val_loss: 1.2056 - val_op_main_loss: 0.2806 - val_op_conv_loss: 0.3699 - val_avg_loss: 0.2820 - val_op_main_accuracy: 0.8905 - val_op_conv_accuracy: 0.9018 - val_avg_accuracy: 0.8980\n",
      "Epoch 458/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5603 - op_main_loss: 0.1268 - op_conv_loss: 0.0697 - avg_loss: 0.0912 - op_main_accuracy: 0.9563 - op_conv_accuracy: 0.9750 - avg_accuracy: 0.9719\n",
      "Epoch 00458: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5613 - op_main_loss: 0.1269 - op_conv_loss: 0.0703 - avg_loss: 0.0916 - op_main_accuracy: 0.9563 - op_conv_accuracy: 0.9747 - avg_accuracy: 0.9716 - val_loss: 1.2762 - val_op_main_loss: 0.2744 - val_op_conv_loss: 0.4344 - val_avg_loss: 0.2943 - val_op_main_accuracy: 0.8933 - val_op_conv_accuracy: 0.8895 - val_avg_accuracy: 0.8980\n",
      "Epoch 459/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5535 - op_main_loss: 0.1224 - op_conv_loss: 0.0691 - avg_loss: 0.0884 - op_main_accuracy: 0.9578 - op_conv_accuracy: 0.9760 - avg_accuracy: 0.9748\n",
      "Epoch 00459: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5536 - op_main_loss: 0.1222 - op_conv_loss: 0.0694 - avg_loss: 0.0884 - op_main_accuracy: 0.9579 - op_conv_accuracy: 0.9757 - avg_accuracy: 0.9747 - val_loss: 1.3773 - val_op_main_loss: 0.2637 - val_op_conv_loss: 0.5368 - val_avg_loss: 0.3032 - val_op_main_accuracy: 0.8980 - val_op_conv_accuracy: 0.8754 - val_avg_accuracy: 0.8867\n",
      "Epoch 460/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5657 - op_main_loss: 0.1229 - op_conv_loss: 0.0767 - avg_loss: 0.0925 - op_main_accuracy: 0.9559 - op_conv_accuracy: 0.9697 - avg_accuracy: 0.9661\n",
      "Epoch 00460: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5654 - op_main_loss: 0.1229 - op_conv_loss: 0.0765 - avg_loss: 0.0924 - op_main_accuracy: 0.9560 - op_conv_accuracy: 0.9695 - avg_accuracy: 0.9662 - val_loss: 1.4523 - val_op_main_loss: 0.2737 - val_op_conv_loss: 0.5833 - val_avg_loss: 0.3216 - val_op_main_accuracy: 0.8933 - val_op_conv_accuracy: 0.8687 - val_avg_accuracy: 0.8763\n",
      "Epoch 461/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5395 - op_main_loss: 0.1179 - op_conv_loss: 0.0636 - avg_loss: 0.0846 - op_main_accuracy: 0.9600 - op_conv_accuracy: 0.9724 - avg_accuracy: 0.9734\n",
      "Epoch 00461: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5431 - op_main_loss: 0.1194 - op_conv_loss: 0.0645 - avg_loss: 0.0858 - op_main_accuracy: 0.9589 - op_conv_accuracy: 0.9721 - avg_accuracy: 0.9726 - val_loss: 1.0713 - val_op_main_loss: 0.2297 - val_op_conv_loss: 0.3339 - val_avg_loss: 0.2345 - val_op_main_accuracy: 0.9027 - val_op_conv_accuracy: 0.9037 - val_avg_accuracy: 0.9084\n",
      "Epoch 462/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/133 [============================>.] - ETA: 0s - loss: 0.5476 - op_main_loss: 0.1197 - op_conv_loss: 0.0674 - avg_loss: 0.0875 - op_main_accuracy: 0.9599 - op_conv_accuracy: 0.9733 - avg_accuracy: 0.9733\n",
      "Epoch 00462: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5464 - op_main_loss: 0.1195 - op_conv_loss: 0.0669 - avg_loss: 0.0872 - op_main_accuracy: 0.9601 - op_conv_accuracy: 0.9735 - avg_accuracy: 0.9735 - val_loss: 1.1222 - val_op_main_loss: 0.2481 - val_op_conv_loss: 0.3478 - val_avg_loss: 0.2540 - val_op_main_accuracy: 0.8971 - val_op_conv_accuracy: 0.9122 - val_avg_accuracy: 0.9103\n",
      "Epoch 463/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5583 - op_main_loss: 0.1229 - op_conv_loss: 0.0722 - avg_loss: 0.0908 - op_main_accuracy: 0.9610 - op_conv_accuracy: 0.9734 - avg_accuracy: 0.9714\n",
      "Epoch 00463: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5609 - op_main_loss: 0.1247 - op_conv_loss: 0.0722 - avg_loss: 0.0916 - op_main_accuracy: 0.9594 - op_conv_accuracy: 0.9733 - avg_accuracy: 0.9707 - val_loss: 1.4825 - val_op_main_loss: 0.2832 - val_op_conv_loss: 0.5915 - val_avg_loss: 0.3357 - val_op_main_accuracy: 0.8914 - val_op_conv_accuracy: 0.8574 - val_avg_accuracy: 0.8716\n",
      "Epoch 464/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5351 - op_main_loss: 0.1184 - op_conv_loss: 0.0607 - avg_loss: 0.0841 - op_main_accuracy: 0.9631 - op_conv_accuracy: 0.9782 - avg_accuracy: 0.9763\n",
      "Epoch 00464: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5350 - op_main_loss: 0.1184 - op_conv_loss: 0.0606 - avg_loss: 0.0841 - op_main_accuracy: 0.9631 - op_conv_accuracy: 0.9783 - avg_accuracy: 0.9764 - val_loss: 1.1492 - val_op_main_loss: 0.2568 - val_op_conv_loss: 0.3734 - val_avg_loss: 0.2471 - val_op_main_accuracy: 0.8905 - val_op_conv_accuracy: 0.8933 - val_avg_accuracy: 0.9027\n",
      "Epoch 465/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5386 - op_main_loss: 0.1172 - op_conv_loss: 0.0646 - avg_loss: 0.0847 - op_main_accuracy: 0.9635 - op_conv_accuracy: 0.9754 - avg_accuracy: 0.9747\n",
      "Epoch 00465: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5379 - op_main_loss: 0.1171 - op_conv_loss: 0.0643 - avg_loss: 0.0845 - op_main_accuracy: 0.9636 - op_conv_accuracy: 0.9754 - avg_accuracy: 0.9747 - val_loss: 1.3847 - val_op_main_loss: 0.2869 - val_op_conv_loss: 0.5025 - val_avg_loss: 0.3237 - val_op_main_accuracy: 0.8895 - val_op_conv_accuracy: 0.8678 - val_avg_accuracy: 0.8782\n",
      "Epoch 466/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5409 - op_main_loss: 0.1173 - op_conv_loss: 0.0658 - avg_loss: 0.0861 - op_main_accuracy: 0.9657 - op_conv_accuracy: 0.9754 - avg_accuracy: 0.9740\n",
      "Epoch 00466: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5410 - op_main_loss: 0.1173 - op_conv_loss: 0.0659 - avg_loss: 0.0861 - op_main_accuracy: 0.9657 - op_conv_accuracy: 0.9752 - avg_accuracy: 0.9740 - val_loss: 1.1175 - val_op_main_loss: 0.2430 - val_op_conv_loss: 0.3521 - val_avg_loss: 0.2508 - val_op_main_accuracy: 0.8942 - val_op_conv_accuracy: 0.9056 - val_avg_accuracy: 0.8999\n",
      "Epoch 467/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5420 - op_main_loss: 0.1168 - op_conv_loss: 0.0679 - avg_loss: 0.0855 - op_main_accuracy: 0.9641 - op_conv_accuracy: 0.9738 - avg_accuracy: 0.9738\n",
      "Epoch 00467: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5417 - op_main_loss: 0.1171 - op_conv_loss: 0.0673 - avg_loss: 0.0855 - op_main_accuracy: 0.9643 - op_conv_accuracy: 0.9742 - avg_accuracy: 0.9740 - val_loss: 1.1332 - val_op_main_loss: 0.2453 - val_op_conv_loss: 0.3627 - val_avg_loss: 0.2534 - val_op_main_accuracy: 0.8952 - val_op_conv_accuracy: 0.9037 - val_avg_accuracy: 0.9018\n",
      "Epoch 468/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5647 - op_main_loss: 0.1232 - op_conv_loss: 0.0766 - avg_loss: 0.0934 - op_main_accuracy: 0.9591 - op_conv_accuracy: 0.9690 - avg_accuracy: 0.9678\n",
      "Epoch 00468: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5625 - op_main_loss: 0.1219 - op_conv_loss: 0.0763 - avg_loss: 0.0927 - op_main_accuracy: 0.9596 - op_conv_accuracy: 0.9688 - avg_accuracy: 0.9679 - val_loss: 1.1554 - val_op_main_loss: 0.2335 - val_op_conv_loss: 0.4059 - val_avg_loss: 0.2443 - val_op_main_accuracy: 0.9018 - val_op_conv_accuracy: 0.8924 - val_avg_accuracy: 0.9037\n",
      "Epoch 469/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5426 - op_main_loss: 0.1200 - op_conv_loss: 0.0647 - avg_loss: 0.0861 - op_main_accuracy: 0.9618 - op_conv_accuracy: 0.9755 - avg_accuracy: 0.9724\n",
      "Epoch 00469: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5414 - op_main_loss: 0.1196 - op_conv_loss: 0.0643 - avg_loss: 0.0858 - op_main_accuracy: 0.9617 - op_conv_accuracy: 0.9757 - avg_accuracy: 0.9724 - val_loss: 1.0971 - val_op_main_loss: 0.2352 - val_op_conv_loss: 0.3448 - val_avg_loss: 0.2456 - val_op_main_accuracy: 0.9046 - val_op_conv_accuracy: 0.9056 - val_avg_accuracy: 0.9056\n",
      "Epoch 470/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5562 - op_main_loss: 0.1245 - op_conv_loss: 0.0699 - avg_loss: 0.0900 - op_main_accuracy: 0.9550 - op_conv_accuracy: 0.9740 - avg_accuracy: 0.9730\n",
      "Epoch 00470: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5562 - op_main_loss: 0.1244 - op_conv_loss: 0.0700 - avg_loss: 0.0900 - op_main_accuracy: 0.9551 - op_conv_accuracy: 0.9738 - avg_accuracy: 0.9728 - val_loss: 1.0742 - val_op_main_loss: 0.2275 - val_op_conv_loss: 0.3399 - val_avg_loss: 0.2351 - val_op_main_accuracy: 0.9103 - val_op_conv_accuracy: 0.9084 - val_avg_accuracy: 0.9103\n",
      "Epoch 471/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5818 - op_main_loss: 0.1302 - op_conv_loss: 0.0820 - avg_loss: 0.0980 - op_main_accuracy: 0.9545 - op_conv_accuracy: 0.9685 - avg_accuracy: 0.9661\n",
      "Epoch 00471: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5814 - op_main_loss: 0.1301 - op_conv_loss: 0.0818 - avg_loss: 0.0979 - op_main_accuracy: 0.9546 - op_conv_accuracy: 0.9686 - avg_accuracy: 0.9662 - val_loss: 1.4046 - val_op_main_loss: 0.2650 - val_op_conv_loss: 0.5546 - val_avg_loss: 0.3132 - val_op_main_accuracy: 0.8952 - val_op_conv_accuracy: 0.8650 - val_avg_accuracy: 0.8763\n",
      "Epoch 472/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5380 - op_main_loss: 0.1166 - op_conv_loss: 0.0645 - avg_loss: 0.0852 - op_main_accuracy: 0.9633 - op_conv_accuracy: 0.9754 - avg_accuracy: 0.9752\n",
      "Epoch 00472: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5373 - op_main_loss: 0.1163 - op_conv_loss: 0.0643 - avg_loss: 0.0849 - op_main_accuracy: 0.9634 - op_conv_accuracy: 0.9752 - avg_accuracy: 0.9752 - val_loss: 1.1010 - val_op_main_loss: 0.2400 - val_op_conv_loss: 0.3412 - val_avg_loss: 0.2487 - val_op_main_accuracy: 0.9018 - val_op_conv_accuracy: 0.9008 - val_avg_accuracy: 0.9046\n",
      "Epoch 473/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5489 - op_main_loss: 0.1182 - op_conv_loss: 0.0721 - avg_loss: 0.0878 - op_main_accuracy: 0.9612 - op_conv_accuracy: 0.9697 - avg_accuracy: 0.9730\n",
      "Epoch 00473: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5485 - op_main_loss: 0.1180 - op_conv_loss: 0.0720 - avg_loss: 0.0877 - op_main_accuracy: 0.9612 - op_conv_accuracy: 0.9698 - avg_accuracy: 0.9731 - val_loss: 1.0921 - val_op_main_loss: 0.2379 - val_op_conv_loss: 0.3419 - val_avg_loss: 0.2417 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.9112 - val_avg_accuracy: 0.9112\n",
      "Epoch 474/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/133 [============================>.] - ETA: 0s - loss: 0.5435 - op_main_loss: 0.1189 - op_conv_loss: 0.0671 - avg_loss: 0.0869 - op_main_accuracy: 0.9599 - op_conv_accuracy: 0.9748 - avg_accuracy: 0.9731\n",
      "Epoch 00474: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5449 - op_main_loss: 0.1194 - op_conv_loss: 0.0675 - avg_loss: 0.0874 - op_main_accuracy: 0.9594 - op_conv_accuracy: 0.9745 - avg_accuracy: 0.9726 - val_loss: 1.1718 - val_op_main_loss: 0.2493 - val_op_conv_loss: 0.3853 - val_avg_loss: 0.2667 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.8942 - val_avg_accuracy: 0.8980\n",
      "Epoch 475/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5559 - op_main_loss: 0.1243 - op_conv_loss: 0.0702 - avg_loss: 0.0908 - op_main_accuracy: 0.9579 - op_conv_accuracy: 0.9738 - avg_accuracy: 0.9704\n",
      "Epoch 00475: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5536 - op_main_loss: 0.1233 - op_conv_loss: 0.0697 - avg_loss: 0.0901 - op_main_accuracy: 0.9586 - op_conv_accuracy: 0.9740 - avg_accuracy: 0.9707 - val_loss: 1.1572 - val_op_main_loss: 0.2493 - val_op_conv_loss: 0.3770 - val_avg_loss: 0.2600 - val_op_main_accuracy: 0.8999 - val_op_conv_accuracy: 0.9065 - val_avg_accuracy: 0.9018\n",
      "Epoch 476/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5291 - op_main_loss: 0.1150 - op_conv_loss: 0.0612 - avg_loss: 0.0819 - op_main_accuracy: 0.9647 - op_conv_accuracy: 0.9780 - avg_accuracy: 0.9759\n",
      "Epoch 00476: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5287 - op_main_loss: 0.1149 - op_conv_loss: 0.0611 - avg_loss: 0.0818 - op_main_accuracy: 0.9648 - op_conv_accuracy: 0.9780 - avg_accuracy: 0.9759 - val_loss: 1.1404 - val_op_main_loss: 0.2477 - val_op_conv_loss: 0.3695 - val_avg_loss: 0.2524 - val_op_main_accuracy: 0.8980 - val_op_conv_accuracy: 0.9112 - val_avg_accuracy: 0.9027\n",
      "Epoch 477/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5568 - op_main_loss: 0.1241 - op_conv_loss: 0.0704 - avg_loss: 0.0916 - op_main_accuracy: 0.9548 - op_conv_accuracy: 0.9709 - avg_accuracy: 0.9673\n",
      "Epoch 00477: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.5548 - op_main_loss: 0.1232 - op_conv_loss: 0.0699 - avg_loss: 0.0910 - op_main_accuracy: 0.9553 - op_conv_accuracy: 0.9709 - avg_accuracy: 0.9674 - val_loss: 1.0917 - val_op_main_loss: 0.2376 - val_op_conv_loss: 0.3410 - val_avg_loss: 0.2423 - val_op_main_accuracy: 0.9037 - val_op_conv_accuracy: 0.9027 - val_avg_accuracy: 0.9018\n",
      "Epoch 478/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5428 - op_main_loss: 0.1226 - op_conv_loss: 0.0627 - avg_loss: 0.0868 - op_main_accuracy: 0.9560 - op_conv_accuracy: 0.9747 - avg_accuracy: 0.9752\n",
      "Epoch 00478: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5428 - op_main_loss: 0.1226 - op_conv_loss: 0.0627 - avg_loss: 0.0868 - op_main_accuracy: 0.9560 - op_conv_accuracy: 0.9747 - avg_accuracy: 0.9752 - val_loss: 1.1562 - val_op_main_loss: 0.2657 - val_op_conv_loss: 0.3518 - val_avg_loss: 0.2680 - val_op_main_accuracy: 0.8942 - val_op_conv_accuracy: 0.9056 - val_avg_accuracy: 0.9027\n",
      "Epoch 479/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5337 - op_main_loss: 0.1165 - op_conv_loss: 0.0626 - avg_loss: 0.0839 - op_main_accuracy: 0.9615 - op_conv_accuracy: 0.9752 - avg_accuracy: 0.9745\n",
      "Epoch 00479: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5331 - op_main_loss: 0.1164 - op_conv_loss: 0.0623 - avg_loss: 0.0837 - op_main_accuracy: 0.9617 - op_conv_accuracy: 0.9757 - avg_accuracy: 0.9747 - val_loss: 1.0886 - val_op_main_loss: 0.2334 - val_op_conv_loss: 0.3426 - val_avg_loss: 0.2419 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.8999 - val_avg_accuracy: 0.9018\n",
      "Epoch 480/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5410 - op_main_loss: 0.1167 - op_conv_loss: 0.0673 - avg_loss: 0.0863 - op_main_accuracy: 0.9632 - op_conv_accuracy: 0.9733 - avg_accuracy: 0.9738\n",
      "Epoch 00480: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.5415 - op_main_loss: 0.1170 - op_conv_loss: 0.0674 - avg_loss: 0.0864 - op_main_accuracy: 0.9629 - op_conv_accuracy: 0.9735 - avg_accuracy: 0.9735 - val_loss: 1.0829 - val_op_main_loss: 0.2406 - val_op_conv_loss: 0.3342 - val_avg_loss: 0.2375 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.9056 - val_avg_accuracy: 0.9056\n",
      "Epoch 481/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5327 - op_main_loss: 0.1165 - op_conv_loss: 0.0611 - avg_loss: 0.0843 - op_main_accuracy: 0.9627 - op_conv_accuracy: 0.9764 - avg_accuracy: 0.9752\n",
      "Epoch 00481: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.5327 - op_main_loss: 0.1165 - op_conv_loss: 0.0611 - avg_loss: 0.0843 - op_main_accuracy: 0.9627 - op_conv_accuracy: 0.9764 - avg_accuracy: 0.9752 - val_loss: 1.1195 - val_op_main_loss: 0.2389 - val_op_conv_loss: 0.3568 - val_avg_loss: 0.2530 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.9018 - val_avg_accuracy: 0.9046\n",
      "Epoch 482/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5596 - op_main_loss: 0.1233 - op_conv_loss: 0.0738 - avg_loss: 0.0919 - op_main_accuracy: 0.9574 - op_conv_accuracy: 0.9695 - avg_accuracy: 0.9709\n",
      "Epoch 00482: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.5602 - op_main_loss: 0.1236 - op_conv_loss: 0.0739 - avg_loss: 0.0921 - op_main_accuracy: 0.9572 - op_conv_accuracy: 0.9695 - avg_accuracy: 0.9707 - val_loss: 1.2145 - val_op_main_loss: 0.2766 - val_op_conv_loss: 0.3921 - val_avg_loss: 0.2750 - val_op_main_accuracy: 0.8971 - val_op_conv_accuracy: 0.9008 - val_avg_accuracy: 0.9027\n",
      "Epoch 483/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5568 - op_main_loss: 0.1278 - op_conv_loss: 0.0675 - avg_loss: 0.0903 - op_main_accuracy: 0.9527 - op_conv_accuracy: 0.9726 - avg_accuracy: 0.9716\n",
      "Epoch 00483: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 17ms/step - loss: 0.5568 - op_main_loss: 0.1278 - op_conv_loss: 0.0675 - avg_loss: 0.0903 - op_main_accuracy: 0.9527 - op_conv_accuracy: 0.9726 - avg_accuracy: 0.9716 - val_loss: 1.1568 - val_op_main_loss: 0.2552 - val_op_conv_loss: 0.3668 - val_avg_loss: 0.2637 - val_op_main_accuracy: 0.8980 - val_op_conv_accuracy: 0.9018 - val_avg_accuracy: 0.9027\n",
      "Epoch 484/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5567 - op_main_loss: 0.1202 - op_conv_loss: 0.0745 - avg_loss: 0.0911 - op_main_accuracy: 0.9618 - op_conv_accuracy: 0.9688 - avg_accuracy: 0.9707\n",
      "Epoch 00484: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5567 - op_main_loss: 0.1205 - op_conv_loss: 0.0742 - avg_loss: 0.0911 - op_main_accuracy: 0.9617 - op_conv_accuracy: 0.9688 - avg_accuracy: 0.9705 - val_loss: 1.1383 - val_op_main_loss: 0.2592 - val_op_conv_loss: 0.3490 - val_avg_loss: 0.2592 - val_op_main_accuracy: 0.8942 - val_op_conv_accuracy: 0.9103 - val_avg_accuracy: 0.9046\n",
      "Epoch 485/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5158 - op_main_loss: 0.1093 - op_conv_loss: 0.0579 - avg_loss: 0.0779 - op_main_accuracy: 0.9647 - op_conv_accuracy: 0.9785 - avg_accuracy: 0.9792\n",
      "Epoch 00485: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.5158 - op_main_loss: 0.1094 - op_conv_loss: 0.0579 - avg_loss: 0.0779 - op_main_accuracy: 0.9648 - op_conv_accuracy: 0.9785 - avg_accuracy: 0.9792 - val_loss: 1.0726 - val_op_main_loss: 0.2240 - val_op_conv_loss: 0.3459 - val_avg_loss: 0.2326 - val_op_main_accuracy: 0.9046 - val_op_conv_accuracy: 0.9008 - val_avg_accuracy: 0.9075\n",
      "Epoch 486/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - ETA: 0s - loss: 0.5205 - op_main_loss: 0.1129 - op_conv_loss: 0.0578 - avg_loss: 0.0800 - op_main_accuracy: 0.9624 - op_conv_accuracy: 0.9776 - avg_accuracy: 0.9759\n",
      "Epoch 00486: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.5205 - op_main_loss: 0.1129 - op_conv_loss: 0.0578 - avg_loss: 0.0800 - op_main_accuracy: 0.9624 - op_conv_accuracy: 0.9776 - avg_accuracy: 0.9759 - val_loss: 1.0892 - val_op_main_loss: 0.2315 - val_op_conv_loss: 0.3468 - val_avg_loss: 0.2414 - val_op_main_accuracy: 0.8980 - val_op_conv_accuracy: 0.9084 - val_avg_accuracy: 0.9027\n",
      "Epoch 487/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5212 - op_main_loss: 0.1113 - op_conv_loss: 0.0602 - avg_loss: 0.0804 - op_main_accuracy: 0.9647 - op_conv_accuracy: 0.9767 - avg_accuracy: 0.9743\n",
      "Epoch 00487: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.5217 - op_main_loss: 0.1114 - op_conv_loss: 0.0604 - avg_loss: 0.0806 - op_main_accuracy: 0.9650 - op_conv_accuracy: 0.9768 - avg_accuracy: 0.9745 - val_loss: 1.0743 - val_op_main_loss: 0.2297 - val_op_conv_loss: 0.3367 - val_avg_loss: 0.2390 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.9056 - val_avg_accuracy: 0.9046\n",
      "Epoch 488/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5182 - op_main_loss: 0.1110 - op_conv_loss: 0.0585 - avg_loss: 0.0796 - op_main_accuracy: 0.9652 - op_conv_accuracy: 0.9770 - avg_accuracy: 0.9744\n",
      "Epoch 00488: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5182 - op_main_loss: 0.1110 - op_conv_loss: 0.0585 - avg_loss: 0.0796 - op_main_accuracy: 0.9650 - op_conv_accuracy: 0.9771 - avg_accuracy: 0.9745 - val_loss: 1.2520 - val_op_main_loss: 0.2480 - val_op_conv_loss: 0.4649 - val_avg_loss: 0.2698 - val_op_main_accuracy: 0.9065 - val_op_conv_accuracy: 0.8867 - val_avg_accuracy: 0.8942\n",
      "Epoch 489/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5642 - op_main_loss: 0.1273 - op_conv_loss: 0.0756 - avg_loss: 0.0922 - op_main_accuracy: 0.9556 - op_conv_accuracy: 0.9735 - avg_accuracy: 0.9719\n",
      "Epoch 00489: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5648 - op_main_loss: 0.1278 - op_conv_loss: 0.0755 - avg_loss: 0.0925 - op_main_accuracy: 0.9556 - op_conv_accuracy: 0.9735 - avg_accuracy: 0.9719 - val_loss: 1.1997 - val_op_main_loss: 0.2438 - val_op_conv_loss: 0.4203 - val_avg_loss: 0.2666 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.8876 - val_avg_accuracy: 0.8980\n",
      "Epoch 490/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5473 - op_main_loss: 0.1183 - op_conv_loss: 0.0717 - avg_loss: 0.0886 - op_main_accuracy: 0.9615 - op_conv_accuracy: 0.9721 - avg_accuracy: 0.9702\n",
      "Epoch 00490: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5479 - op_main_loss: 0.1191 - op_conv_loss: 0.0713 - avg_loss: 0.0888 - op_main_accuracy: 0.9610 - op_conv_accuracy: 0.9721 - avg_accuracy: 0.9700 - val_loss: 1.1603 - val_op_main_loss: 0.2536 - val_op_conv_loss: 0.3700 - val_avg_loss: 0.2680 - val_op_main_accuracy: 0.8942 - val_op_conv_accuracy: 0.8961 - val_avg_accuracy: 0.9008\n",
      "Epoch 491/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5244 - op_main_loss: 0.1121 - op_conv_loss: 0.0619 - avg_loss: 0.0818 - op_main_accuracy: 0.9657 - op_conv_accuracy: 0.9761 - avg_accuracy: 0.9747\n",
      "Epoch 00491: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.5244 - op_main_loss: 0.1121 - op_conv_loss: 0.0619 - avg_loss: 0.0818 - op_main_accuracy: 0.9657 - op_conv_accuracy: 0.9761 - avg_accuracy: 0.9747 - val_loss: 1.1078 - val_op_main_loss: 0.2470 - val_op_conv_loss: 0.3374 - val_avg_loss: 0.2546 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.9056 - val_avg_accuracy: 0.9037\n",
      "Epoch 492/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5459 - op_main_loss: 0.1230 - op_conv_loss: 0.0668 - avg_loss: 0.0874 - op_main_accuracy: 0.9571 - op_conv_accuracy: 0.9731 - avg_accuracy: 0.9714\n",
      "Epoch 00492: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.5458 - op_main_loss: 0.1229 - op_conv_loss: 0.0668 - avg_loss: 0.0874 - op_main_accuracy: 0.9570 - op_conv_accuracy: 0.9728 - avg_accuracy: 0.9714 - val_loss: 1.0778 - val_op_main_loss: 0.2412 - val_op_conv_loss: 0.3280 - val_avg_loss: 0.2406 - val_op_main_accuracy: 0.8952 - val_op_conv_accuracy: 0.8952 - val_avg_accuracy: 0.9037\n",
      "Epoch 493/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5424 - op_main_loss: 0.1182 - op_conv_loss: 0.0682 - avg_loss: 0.0879 - op_main_accuracy: 0.9618 - op_conv_accuracy: 0.9719 - avg_accuracy: 0.9721\n",
      "Epoch 00493: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5422 - op_main_loss: 0.1181 - op_conv_loss: 0.0681 - avg_loss: 0.0878 - op_main_accuracy: 0.9617 - op_conv_accuracy: 0.9719 - avg_accuracy: 0.9721 - val_loss: 1.1425 - val_op_main_loss: 0.2536 - val_op_conv_loss: 0.3560 - val_avg_loss: 0.2649 - val_op_main_accuracy: 0.8999 - val_op_conv_accuracy: 0.9056 - val_avg_accuracy: 0.9046\n",
      "Epoch 494/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5258 - op_main_loss: 0.1154 - op_conv_loss: 0.0595 - avg_loss: 0.0828 - op_main_accuracy: 0.9628 - op_conv_accuracy: 0.9754 - avg_accuracy: 0.9751\n",
      "Epoch 00494: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5257 - op_main_loss: 0.1154 - op_conv_loss: 0.0595 - avg_loss: 0.0828 - op_main_accuracy: 0.9629 - op_conv_accuracy: 0.9754 - avg_accuracy: 0.9752 - val_loss: 1.1872 - val_op_main_loss: 0.2541 - val_op_conv_loss: 0.3914 - val_avg_loss: 0.2737 - val_op_main_accuracy: 0.8971 - val_op_conv_accuracy: 0.8961 - val_avg_accuracy: 0.8942\n",
      "Epoch 495/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5300 - op_main_loss: 0.1142 - op_conv_loss: 0.0636 - avg_loss: 0.0839 - op_main_accuracy: 0.9634 - op_conv_accuracy: 0.9765 - avg_accuracy: 0.9748\n",
      "Epoch 00495: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5273 - op_main_loss: 0.1135 - op_conv_loss: 0.0624 - avg_loss: 0.0830 - op_main_accuracy: 0.9638 - op_conv_accuracy: 0.9771 - avg_accuracy: 0.9754 - val_loss: 1.1592 - val_op_main_loss: 0.2472 - val_op_conv_loss: 0.3855 - val_avg_loss: 0.2581 - val_op_main_accuracy: 0.8971 - val_op_conv_accuracy: 0.8980 - val_avg_accuracy: 0.9008\n",
      "Epoch 496/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5615 - op_main_loss: 0.1241 - op_conv_loss: 0.0765 - avg_loss: 0.0928 - op_main_accuracy: 0.9605 - op_conv_accuracy: 0.9724 - avg_accuracy: 0.9712\n",
      "Epoch 00496: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5640 - op_main_loss: 0.1249 - op_conv_loss: 0.0773 - avg_loss: 0.0936 - op_main_accuracy: 0.9603 - op_conv_accuracy: 0.9721 - avg_accuracy: 0.9705 - val_loss: 1.1356 - val_op_main_loss: 0.2411 - val_op_conv_loss: 0.3690 - val_avg_loss: 0.2583 - val_op_main_accuracy: 0.8990 - val_op_conv_accuracy: 0.8961 - val_avg_accuracy: 0.9008\n",
      "Epoch 497/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5290 - op_main_loss: 0.1160 - op_conv_loss: 0.0620 - avg_loss: 0.0837 - op_main_accuracy: 0.9645 - op_conv_accuracy: 0.9763 - avg_accuracy: 0.9749\n",
      "Epoch 00497: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5287 - op_main_loss: 0.1159 - op_conv_loss: 0.0619 - avg_loss: 0.0836 - op_main_accuracy: 0.9646 - op_conv_accuracy: 0.9764 - avg_accuracy: 0.9750 - val_loss: 1.0902 - val_op_main_loss: 0.2425 - val_op_conv_loss: 0.3348 - val_avg_loss: 0.2455 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9046\n",
      "Epoch 498/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/133 [============================>.] - ETA: 0s - loss: 0.5257 - op_main_loss: 0.1125 - op_conv_loss: 0.0640 - avg_loss: 0.0821 - op_main_accuracy: 0.9645 - op_conv_accuracy: 0.9747 - avg_accuracy: 0.9761\n",
      "Epoch 00498: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.5272 - op_main_loss: 0.1135 - op_conv_loss: 0.0642 - avg_loss: 0.0825 - op_main_accuracy: 0.9638 - op_conv_accuracy: 0.9745 - avg_accuracy: 0.9757 - val_loss: 1.0677 - val_op_main_loss: 0.2352 - val_op_conv_loss: 0.3242 - val_avg_loss: 0.2415 - val_op_main_accuracy: 0.9018 - val_op_conv_accuracy: 0.9065 - val_avg_accuracy: 0.9056\n",
      "Epoch 499/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5325 - op_main_loss: 0.1144 - op_conv_loss: 0.0669 - avg_loss: 0.0847 - op_main_accuracy: 0.9633 - op_conv_accuracy: 0.9771 - avg_accuracy: 0.9766\n",
      "Epoch 00499: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5313 - op_main_loss: 0.1139 - op_conv_loss: 0.0665 - avg_loss: 0.0844 - op_main_accuracy: 0.9634 - op_conv_accuracy: 0.9771 - avg_accuracy: 0.9766 - val_loss: 1.1216 - val_op_main_loss: 0.2510 - val_op_conv_loss: 0.3530 - val_avg_loss: 0.2510 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.9046 - val_avg_accuracy: 0.9065\n",
      "Epoch 500/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5212 - op_main_loss: 0.1109 - op_conv_loss: 0.0625 - avg_loss: 0.0812 - op_main_accuracy: 0.9646 - op_conv_accuracy: 0.9754 - avg_accuracy: 0.9750\n",
      "Epoch 00500: val_avg_accuracy did not improve from 0.91501\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5212 - op_main_loss: 0.1109 - op_conv_loss: 0.0625 - avg_loss: 0.0812 - op_main_accuracy: 0.9646 - op_conv_accuracy: 0.9754 - avg_accuracy: 0.9750 - val_loss: 1.1287 - val_op_main_loss: 0.2406 - val_op_conv_loss: 0.3691 - val_avg_loss: 0.2527 - val_op_main_accuracy: 0.9008 - val_op_conv_accuracy: 0.9056 - val_avg_accuracy: 0.9027\n"
     ]
    }
   ],
   "source": [
    "def ms_lstm(w2v):\n",
    "    inputs = Input(shape=(X_train[0].shape[-1],))\n",
    "\n",
    "    embedding_layer = gensim_to_keras_embedding(w2v)\n",
    "    \n",
    "    embedding = embedding_layer(inputs)\n",
    "\n",
    "    lstm1 = LSTM(lstm_units,return_sequences=True, return_state=True, kernel_regularizer=l2(w_decay),recurrent_regularizer=l2(w_decay), dropout=dropout_rate)(embedding)\n",
    "    \n",
    "    \n",
    "    \n",
    "    output = Dense(units=1, activation='sigmoid', name='op_main')(lstm1[1])\n",
    "    \n",
    "\n",
    "    output_td_gap = GlobalAveragePooling1D(data_format='channels_first')(lstm1[0])\n",
    "    \n",
    "    output_td = TimeDistributed(Dense(units=1, activation='sigmoid'))(lstm1[0])\n",
    "    output_td = Flatten()(output_td)\n",
    "    \n",
    "    output_td = Multiply()([output_td_gap, output_td])\n",
    "    \n",
    "    output_td = Activation('relu', name='before_split')(output_td)\n",
    "    \n",
    "    output_td_splits = tf.split(output_td, 10, axis=-1)\n",
    "    \n",
    "    features = concatenate([output_td_splits[0], output_td_splits[1], output_td_splits[-2], output_td_splits[-1]])\n",
    "    \n",
    "    print(features.shape)\n",
    "    \n",
    "    output_td = Reshape((8, 10, 1))(features)\n",
    "    \n",
    "    output_td = Conv2D(2, 8, padding='same', strides=1, activation='relu', kernel_regularizer=l2(w_decay))(output_td)\n",
    "    output_td = BatchNormalization()(output_td)\n",
    "    output_td = Flatten()(output_td)\n",
    "   \n",
    "\n",
    "    output_td = Dense(units=1, activation='sigmoid', name='op_conv')(output_td)\n",
    "    \n",
    "    \n",
    "    \n",
    "    avg = tf.keras.layers.Average(name='avg')([output, output_td])\n",
    "    \n",
    "\n",
    "    model = Model(inputs, [output, output_td, avg])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = ms_lstm(w2v_model)\n",
    "\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint('./weight_cp/weight_lstm2.hdf5', save_freq=\"epoch\",  verbose=1, monitor='val_avg_accuracy', save_best_only=True,\n",
    "    save_weights_only=False)\n",
    "\n",
    "metrics = ['accuracy']\n",
    "optimizer = Adam(0.0001)\n",
    "model.compile(optimizer = optimizer, loss='binary_crossentropy', metrics=metrics)\n",
    "model.summary()\n",
    "history1 = model.fit(X_train, y_train, epochs=epochs_to_run, validation_data=(X_val, y_val), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14f4c340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT OF Multi-Supervised LSTM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91       661\n",
      "           1       0.90      0.94      0.92       662\n",
      "\n",
      "    accuracy                           0.92      1323\n",
      "   macro avg       0.92      0.92      0.92      1323\n",
      "weighted avg       0.92      0.92      0.92      1323\n",
      "\n",
      "0.9153439153439153\n"
     ]
    }
   ],
   "source": [
    "model = load_model('./weight_cp/weight_lstm2.hdf5')\n",
    "predictionss = model.predict(X_test)\n",
    "predictions = np.where(predictionss[-1] > 0.5, 1, 0)\n",
    "y_pred = []\n",
    "for p in predictions:\n",
    "    y_pred.append(p[0])\n",
    "y_pred = np.array(y_pred)\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(\"CLASSIFICATION REPORT OF Multi-Supervised LSTM\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebe85b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 80)\n",
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 200, 100)     14114800    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 200, 50), (N 30200       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 200, 1)       51          lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 200)          0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 200)          0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 200)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "before_split (Activation)       (None, 200)          0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_split_1 (TensorFlow [(None, 20), (None,  0           before_split[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 80)           0           tf_op_layer_split_1[0][0]        \n",
      "                                                                 tf_op_layer_split_1[0][1]        \n",
      "                                                                 tf_op_layer_split_1[0][8]        \n",
      "                                                                 tf_op_layer_split_1[0][9]        \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 8, 10, 1)     0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 8, 10, 2)     130         reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 8, 10, 2)     8           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 160)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "op_conv (Dense)                 (None, 1)            161         flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 14,145,350\n",
      "Trainable params: 30,546\n",
      "Non-trainable params: 14,114,804\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 8.7698 - accuracy: 0.5036\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50803, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 18ms/step - loss: 8.7510 - accuracy: 0.5038 - val_loss: 7.6336 - val_accuracy: 0.5080\n",
      "Epoch 2/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 6.7364 - accuracy: 0.5021\n",
      "Epoch 00002: val_accuracy improved from 0.50803 to 0.51180, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 6.7285 - accuracy: 0.5009 - val_loss: 5.8806 - val_accuracy: 0.5118\n",
      "Epoch 3/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 5.2080 - accuracy: 0.5015\n",
      "Epoch 00003: val_accuracy improved from 0.51180 to 0.51464, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 5.1924 - accuracy: 0.5038 - val_loss: 4.5473 - val_accuracy: 0.5146\n",
      "Epoch 4/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 4.0253 - accuracy: 0.5099\n",
      "Epoch 00004: val_accuracy improved from 0.51464 to 0.51747, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 4.0244 - accuracy: 0.5102 - val_loss: 3.5351 - val_accuracy: 0.5175\n",
      "Epoch 5/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 3.1431 - accuracy: 0.4998\n",
      "Epoch 00005: val_accuracy did not improve from 0.51747\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 3.1397 - accuracy: 0.5000 - val_loss: 2.7702 - val_accuracy: 0.5127\n",
      "Epoch 6/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 2.4757 - accuracy: 0.4998\n",
      "Epoch 00006: val_accuracy did not improve from 0.51747\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 2.4731 - accuracy: 0.4993 - val_loss: 2.1962 - val_accuracy: 0.5099\n",
      "Epoch 7/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 1.9782 - accuracy: 0.5096\n",
      "Epoch 00007: val_accuracy improved from 0.51747 to 0.52030, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 1.9747 - accuracy: 0.5087 - val_loss: 1.7690 - val_accuracy: 0.5203\n",
      "Epoch 8/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 1.6070 - accuracy: 0.5019\n",
      "Epoch 00008: val_accuracy did not improve from 0.52030\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 1.6056 - accuracy: 0.5012 - val_loss: 1.4544 - val_accuracy: 0.5071\n",
      "Epoch 9/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 1.3361 - accuracy: 0.4912\n",
      "Epoch 00009: val_accuracy did not improve from 0.52030\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 1.3351 - accuracy: 0.4891 - val_loss: 1.2252 - val_accuracy: 0.4920\n",
      "Epoch 10/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 1.1400 - accuracy: 0.4998\n",
      "Epoch 00010: val_accuracy did not improve from 0.52030\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 1.1392 - accuracy: 0.4998 - val_loss: 1.0605 - val_accuracy: 0.5005\n",
      "Epoch 11/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 1.0003 - accuracy: 0.5075\n",
      "Epoch 00011: val_accuracy improved from 0.52030 to 0.52408, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.9993 - accuracy: 0.5069 - val_loss: 0.9434 - val_accuracy: 0.5241\n",
      "Epoch 12/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.8980 - accuracy: 0.5515\n",
      "Epoch 00012: val_accuracy did not improve from 0.52408\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.8976 - accuracy: 0.5513 - val_loss: 0.8558 - val_accuracy: 0.5099\n",
      "Epoch 13/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.8075 - accuracy: 0.6293\n",
      "Epoch 00013: val_accuracy did not improve from 0.52408\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.8065 - accuracy: 0.6302 - val_loss: 0.8466 - val_accuracy: 0.5137\n",
      "Epoch 14/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.7148 - accuracy: 0.6921\n",
      "Epoch 00014: val_accuracy improved from 0.52408 to 0.54297, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.7148 - accuracy: 0.6921 - val_loss: 0.8546 - val_accuracy: 0.5430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.6554 - accuracy: 0.7238\n",
      "Epoch 00015: val_accuracy did not improve from 0.54297\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.6571 - accuracy: 0.7226 - val_loss: 1.0013 - val_accuracy: 0.5392\n",
      "Epoch 16/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.6253 - accuracy: 0.7381\n",
      "Epoch 00016: val_accuracy improved from 0.54297 to 0.78659, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 16ms/step - loss: 0.6241 - accuracy: 0.7391 - val_loss: 0.5839 - val_accuracy: 0.7866\n",
      "Epoch 17/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.6000 - accuracy: 0.7479\n",
      "Epoch 00017: val_accuracy did not improve from 0.78659\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.5994 - accuracy: 0.7481 - val_loss: 0.5652 - val_accuracy: 0.7828\n",
      "Epoch 18/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5816 - accuracy: 0.7505\n",
      "Epoch 00018: val_accuracy did not improve from 0.78659\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.5826 - accuracy: 0.7495 - val_loss: 0.5613 - val_accuracy: 0.7611\n",
      "Epoch 19/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5802 - accuracy: 0.7459\n",
      "Epoch 00019: val_accuracy did not improve from 0.78659\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.5805 - accuracy: 0.7462 - val_loss: 0.5643 - val_accuracy: 0.7413\n",
      "Epoch 20/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5716 - accuracy: 0.7562\n",
      "Epoch 00020: val_accuracy did not improve from 0.78659\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.5720 - accuracy: 0.7557 - val_loss: 0.5362 - val_accuracy: 0.7838\n",
      "Epoch 21/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5558 - accuracy: 0.7561\n",
      "Epoch 00021: val_accuracy did not improve from 0.78659\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5558 - accuracy: 0.7561 - val_loss: 0.5737 - val_accuracy: 0.7167\n",
      "Epoch 22/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5628 - accuracy: 0.7500\n",
      "Epoch 00022: val_accuracy did not improve from 0.78659\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.5610 - accuracy: 0.7514 - val_loss: 0.5435 - val_accuracy: 0.7554\n",
      "Epoch 23/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.5482 - accuracy: 0.7678\n",
      "Epoch 00023: val_accuracy did not improve from 0.78659\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.5484 - accuracy: 0.7675 - val_loss: 0.5930 - val_accuracy: 0.6959\n",
      "Epoch 24/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5416 - accuracy: 0.7747\n",
      "Epoch 00024: val_accuracy did not improve from 0.78659\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.5424 - accuracy: 0.7743 - val_loss: 0.6104 - val_accuracy: 0.6884\n",
      "Epoch 25/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.5402 - accuracy: 0.7699\n",
      "Epoch 00025: val_accuracy improved from 0.78659 to 0.78942, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5391 - accuracy: 0.7703 - val_loss: 0.5217 - val_accuracy: 0.7894\n",
      "Epoch 26/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5347 - accuracy: 0.7762\n",
      "Epoch 00026: val_accuracy improved from 0.78942 to 0.80642, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5347 - accuracy: 0.7762 - val_loss: 0.5095 - val_accuracy: 0.8064\n",
      "Epoch 27/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5283 - accuracy: 0.7821\n",
      "Epoch 00027: val_accuracy improved from 0.80642 to 0.81114, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5283 - accuracy: 0.7821 - val_loss: 0.4960 - val_accuracy: 0.8111\n",
      "Epoch 28/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5244 - accuracy: 0.7772\n",
      "Epoch 00028: val_accuracy did not improve from 0.81114\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.5245 - accuracy: 0.7767 - val_loss: 0.5472 - val_accuracy: 0.7649\n",
      "Epoch 29/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5149 - accuracy: 0.7889\n",
      "Epoch 00029: val_accuracy improved from 0.81114 to 0.81964, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.5151 - accuracy: 0.7885 - val_loss: 0.4890 - val_accuracy: 0.8196\n",
      "Epoch 30/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5207 - accuracy: 0.7913\n",
      "Epoch 00030: val_accuracy did not improve from 0.81964\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.5207 - accuracy: 0.7909 - val_loss: 0.4941 - val_accuracy: 0.8093\n",
      "Epoch 31/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5066 - accuracy: 0.7963\n",
      "Epoch 00031: val_accuracy improved from 0.81964 to 0.82436, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.5062 - accuracy: 0.7966 - val_loss: 0.4750 - val_accuracy: 0.8244\n",
      "Epoch 32/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.5101 - accuracy: 0.7913\n",
      "Epoch 00032: val_accuracy did not improve from 0.82436\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.5101 - accuracy: 0.7914 - val_loss: 0.5111 - val_accuracy: 0.7923\n",
      "Epoch 33/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4996 - accuracy: 0.8063\n",
      "Epoch 00033: val_accuracy did not improve from 0.82436\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.5005 - accuracy: 0.8053 - val_loss: 0.4948 - val_accuracy: 0.8064\n",
      "Epoch 34/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4974 - accuracy: 0.7953\n",
      "Epoch 00034: val_accuracy did not improve from 0.82436\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.4980 - accuracy: 0.7949 - val_loss: 0.5516 - val_accuracy: 0.7696\n",
      "Epoch 35/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4880 - accuracy: 0.8075\n",
      "Epoch 00035: val_accuracy improved from 0.82436 to 0.83097, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.4877 - accuracy: 0.8077 - val_loss: 0.4680 - val_accuracy: 0.8310\n",
      "Epoch 36/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4883 - accuracy: 0.8032\n",
      "Epoch 00036: val_accuracy did not improve from 0.83097\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.4874 - accuracy: 0.8043 - val_loss: 0.6410 - val_accuracy: 0.7110\n",
      "Epoch 37/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4811 - accuracy: 0.8151\n",
      "Epoch 00037: val_accuracy did not improve from 0.83097\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.4818 - accuracy: 0.8155 - val_loss: 0.4879 - val_accuracy: 0.8083\n",
      "Epoch 38/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4850 - accuracy: 0.8120\n",
      "Epoch 00038: val_accuracy did not improve from 0.83097\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.4845 - accuracy: 0.8129 - val_loss: 0.4817 - val_accuracy: 0.8196\n",
      "Epoch 39/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4796 - accuracy: 0.8170\n",
      "Epoch 00039: val_accuracy did not improve from 0.83097\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.4791 - accuracy: 0.8178 - val_loss: 0.4763 - val_accuracy: 0.8196\n",
      "Epoch 40/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4717 - accuracy: 0.8213\n",
      "Epoch 00040: val_accuracy did not improve from 0.83097\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.4713 - accuracy: 0.8218 - val_loss: 0.5485 - val_accuracy: 0.7677\n",
      "Epoch 41/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4679 - accuracy: 0.8199\n",
      "Epoch 00041: val_accuracy did not improve from 0.83097\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.4682 - accuracy: 0.8199 - val_loss: 0.4787 - val_accuracy: 0.8187\n",
      "Epoch 42/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4692 - accuracy: 0.8158\n",
      "Epoch 00042: val_accuracy did not improve from 0.83097\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.4690 - accuracy: 0.8164 - val_loss: 0.4616 - val_accuracy: 0.8281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4653 - accuracy: 0.8230\n",
      "Epoch 00043: val_accuracy did not improve from 0.83097\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.4667 - accuracy: 0.8223 - val_loss: 0.6013 - val_accuracy: 0.7479\n",
      "Epoch 44/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4702 - accuracy: 0.8197\n",
      "Epoch 00044: val_accuracy improved from 0.83097 to 0.84136, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.4694 - accuracy: 0.8197 - val_loss: 0.4401 - val_accuracy: 0.8414\n",
      "Epoch 45/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4588 - accuracy: 0.8254\n",
      "Epoch 00045: val_accuracy did not improve from 0.84136\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.4594 - accuracy: 0.8249 - val_loss: 0.5425 - val_accuracy: 0.7762\n",
      "Epoch 46/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4557 - accuracy: 0.8344\n",
      "Epoch 00046: val_accuracy improved from 0.84136 to 0.84514, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.4564 - accuracy: 0.8339 - val_loss: 0.4320 - val_accuracy: 0.8451\n",
      "Epoch 47/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4576 - accuracy: 0.8333\n",
      "Epoch 00047: val_accuracy improved from 0.84514 to 0.85647, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.4559 - accuracy: 0.8346 - val_loss: 0.4260 - val_accuracy: 0.8565\n",
      "Epoch 48/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4428 - accuracy: 0.8383\n",
      "Epoch 00048: val_accuracy did not improve from 0.85647\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.4425 - accuracy: 0.8384 - val_loss: 0.4403 - val_accuracy: 0.8414\n",
      "Epoch 49/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4400 - accuracy: 0.8461\n",
      "Epoch 00049: val_accuracy did not improve from 0.85647\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.4403 - accuracy: 0.8462 - val_loss: 0.4851 - val_accuracy: 0.8055\n",
      "Epoch 50/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4410 - accuracy: 0.8454\n",
      "Epoch 00050: val_accuracy did not improve from 0.85647\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.4415 - accuracy: 0.8457 - val_loss: 0.4986 - val_accuracy: 0.7970\n",
      "Epoch 51/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4442 - accuracy: 0.8404\n",
      "Epoch 00051: val_accuracy improved from 0.85647 to 0.85741, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.4439 - accuracy: 0.8405 - val_loss: 0.4286 - val_accuracy: 0.8574\n",
      "Epoch 52/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4306 - accuracy: 0.8459\n",
      "Epoch 00052: val_accuracy did not improve from 0.85741\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.4316 - accuracy: 0.8452 - val_loss: 0.4871 - val_accuracy: 0.8168\n",
      "Epoch 53/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4283 - accuracy: 0.8457\n",
      "Epoch 00053: val_accuracy did not improve from 0.85741\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.4278 - accuracy: 0.8459 - val_loss: 0.4893 - val_accuracy: 0.8196\n",
      "Epoch 54/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4328 - accuracy: 0.8500\n",
      "Epoch 00054: val_accuracy improved from 0.85741 to 0.86874, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.4334 - accuracy: 0.8497 - val_loss: 0.4085 - val_accuracy: 0.8687\n",
      "Epoch 55/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4286 - accuracy: 0.8507\n",
      "Epoch 00055: val_accuracy did not improve from 0.86874\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.4293 - accuracy: 0.8502 - val_loss: 0.4152 - val_accuracy: 0.8612\n",
      "Epoch 56/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4239 - accuracy: 0.8514\n",
      "Epoch 00056: val_accuracy did not improve from 0.86874\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.4236 - accuracy: 0.8521 - val_loss: 0.4134 - val_accuracy: 0.8621\n",
      "Epoch 57/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4209 - accuracy: 0.8521\n",
      "Epoch 00057: val_accuracy did not improve from 0.86874\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.4209 - accuracy: 0.8516 - val_loss: 0.5793 - val_accuracy: 0.7734\n",
      "Epoch 58/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.4175 - accuracy: 0.8583\n",
      "Epoch 00058: val_accuracy did not improve from 0.86874\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.4163 - accuracy: 0.8596 - val_loss: 0.4116 - val_accuracy: 0.8659\n",
      "Epoch 59/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4237 - accuracy: 0.8583\n",
      "Epoch 00059: val_accuracy did not improve from 0.86874\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.4231 - accuracy: 0.8587 - val_loss: 0.4122 - val_accuracy: 0.8621\n",
      "Epoch 60/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.4181 - accuracy: 0.8539\n",
      "Epoch 00060: val_accuracy did not improve from 0.86874\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.4179 - accuracy: 0.8542 - val_loss: 0.4327 - val_accuracy: 0.8499\n",
      "Epoch 61/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.4108 - accuracy: 0.8596\n",
      "Epoch 00061: val_accuracy did not improve from 0.86874\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.4102 - accuracy: 0.8599 - val_loss: 0.8526 - val_accuracy: 0.6364\n",
      "Epoch 62/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.4141 - accuracy: 0.8599\n",
      "Epoch 00062: val_accuracy did not improve from 0.86874\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.4131 - accuracy: 0.8606 - val_loss: 0.4216 - val_accuracy: 0.8432\n",
      "Epoch 63/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.4018 - accuracy: 0.8680\n",
      "Epoch 00063: val_accuracy did not improve from 0.86874\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.4017 - accuracy: 0.8679 - val_loss: 0.6578 - val_accuracy: 0.7356\n",
      "Epoch 64/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.4127 - accuracy: 0.8658\n",
      "Epoch 00064: val_accuracy did not improve from 0.86874\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.4127 - accuracy: 0.8658 - val_loss: 0.4068 - val_accuracy: 0.8687\n",
      "Epoch 65/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.4054 - accuracy: 0.8637\n",
      "Epoch 00065: val_accuracy did not improve from 0.86874\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.4061 - accuracy: 0.8627 - val_loss: 0.4731 - val_accuracy: 0.8225\n",
      "Epoch 66/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3995 - accuracy: 0.8702\n",
      "Epoch 00066: val_accuracy did not improve from 0.86874\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.4002 - accuracy: 0.8705 - val_loss: 0.4611 - val_accuracy: 0.8281\n",
      "Epoch 67/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4015 - accuracy: 0.8657\n",
      "Epoch 00067: val_accuracy did not improve from 0.86874\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.4015 - accuracy: 0.8651 - val_loss: 0.4428 - val_accuracy: 0.8451\n",
      "Epoch 68/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3912 - accuracy: 0.8729\n",
      "Epoch 00068: val_accuracy did not improve from 0.86874\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3922 - accuracy: 0.8719 - val_loss: 0.4651 - val_accuracy: 0.8196\n",
      "Epoch 69/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3979 - accuracy: 0.8698\n",
      "Epoch 00069: val_accuracy did not improve from 0.86874\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3966 - accuracy: 0.8707 - val_loss: 0.4467 - val_accuracy: 0.8338\n",
      "Epoch 70/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.4028 - accuracy: 0.8664\n",
      "Epoch 00070: val_accuracy did not improve from 0.86874\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.4036 - accuracy: 0.8660 - val_loss: 0.6281 - val_accuracy: 0.7583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3892 - accuracy: 0.8750\n",
      "Epoch 00071: val_accuracy did not improve from 0.86874\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3901 - accuracy: 0.8748 - val_loss: 0.4730 - val_accuracy: 0.8244\n",
      "Epoch 72/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.4006 - accuracy: 0.8636\n",
      "Epoch 00072: val_accuracy did not improve from 0.86874\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.3979 - accuracy: 0.8653 - val_loss: 0.4085 - val_accuracy: 0.8650\n",
      "Epoch 73/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3892 - accuracy: 0.8771\n",
      "Epoch 00073: val_accuracy improved from 0.86874 to 0.87441, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 15ms/step - loss: 0.3894 - accuracy: 0.8767 - val_loss: 0.3878 - val_accuracy: 0.8744\n",
      "Epoch 74/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3916 - accuracy: 0.8743\n",
      "Epoch 00074: val_accuracy did not improve from 0.87441\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3917 - accuracy: 0.8743 - val_loss: 0.6951 - val_accuracy: 0.7347\n",
      "Epoch 75/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3893 - accuracy: 0.8779\n",
      "Epoch 00075: val_accuracy did not improve from 0.87441\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3897 - accuracy: 0.8778 - val_loss: 0.4178 - val_accuracy: 0.8593\n",
      "Epoch 76/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8793\n",
      "Epoch 00076: val_accuracy did not improve from 0.87441\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3862 - accuracy: 0.8800 - val_loss: 0.4573 - val_accuracy: 0.8263\n",
      "Epoch 77/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8745\n",
      "Epoch 00077: val_accuracy did not improve from 0.87441\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3844 - accuracy: 0.8748 - val_loss: 0.9814 - val_accuracy: 0.6393\n",
      "Epoch 78/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8800\n",
      "Epoch 00078: val_accuracy did not improve from 0.87441\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3811 - accuracy: 0.8800 - val_loss: 1.1076 - val_accuracy: 0.6176\n",
      "Epoch 79/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3793 - accuracy: 0.8833\n",
      "Epoch 00079: val_accuracy did not improve from 0.87441\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3791 - accuracy: 0.8837 - val_loss: 0.3829 - val_accuracy: 0.8725\n",
      "Epoch 80/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3743 - accuracy: 0.8812\n",
      "Epoch 00080: val_accuracy did not improve from 0.87441\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3744 - accuracy: 0.8811 - val_loss: 0.5704 - val_accuracy: 0.7809\n",
      "Epoch 81/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3726 - accuracy: 0.8850\n",
      "Epoch 00081: val_accuracy did not improve from 0.87441\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3722 - accuracy: 0.8854 - val_loss: 0.3963 - val_accuracy: 0.8602\n",
      "Epoch 82/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3736 - accuracy: 0.8812\n",
      "Epoch 00082: val_accuracy did not improve from 0.87441\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3743 - accuracy: 0.8804 - val_loss: 0.3740 - val_accuracy: 0.8744\n",
      "Epoch 83/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3715 - accuracy: 0.8857\n",
      "Epoch 00083: val_accuracy did not improve from 0.87441\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3722 - accuracy: 0.8856 - val_loss: 0.4004 - val_accuracy: 0.8631\n",
      "Epoch 84/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3697 - accuracy: 0.8810\n",
      "Epoch 00084: val_accuracy did not improve from 0.87441\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3699 - accuracy: 0.8809 - val_loss: 0.4456 - val_accuracy: 0.8423\n",
      "Epoch 85/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3729 - accuracy: 0.8855\n",
      "Epoch 00085: val_accuracy did not improve from 0.87441\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3735 - accuracy: 0.8854 - val_loss: 0.3925 - val_accuracy: 0.8669\n",
      "Epoch 86/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3697 - accuracy: 0.8845\n",
      "Epoch 00086: val_accuracy improved from 0.87441 to 0.87535, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.3696 - accuracy: 0.8842 - val_loss: 0.3921 - val_accuracy: 0.8754\n",
      "Epoch 87/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3676 - accuracy: 0.8867\n",
      "Epoch 00087: val_accuracy did not improve from 0.87535\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3668 - accuracy: 0.8873 - val_loss: 0.4947 - val_accuracy: 0.8253\n",
      "Epoch 88/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3739 - accuracy: 0.8860\n",
      "Epoch 00088: val_accuracy improved from 0.87535 to 0.88291, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.3742 - accuracy: 0.8859 - val_loss: 0.3777 - val_accuracy: 0.8829\n",
      "Epoch 89/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3610 - accuracy: 0.8872\n",
      "Epoch 00089: val_accuracy did not improve from 0.88291\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3603 - accuracy: 0.8873 - val_loss: 0.4081 - val_accuracy: 0.8593\n",
      "Epoch 90/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3584 - accuracy: 0.8938\n",
      "Epoch 00090: val_accuracy did not improve from 0.88291\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.3590 - accuracy: 0.8932 - val_loss: 0.4209 - val_accuracy: 0.8640\n",
      "Epoch 91/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3731 - accuracy: 0.8798\n",
      "Epoch 00091: val_accuracy did not improve from 0.88291\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3730 - accuracy: 0.8797 - val_loss: 0.4174 - val_accuracy: 0.8527\n",
      "Epoch 92/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3675 - accuracy: 0.8850\n",
      "Epoch 00092: val_accuracy did not improve from 0.88291\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3669 - accuracy: 0.8852 - val_loss: 0.5101 - val_accuracy: 0.8055\n",
      "Epoch 93/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3664 - accuracy: 0.8912\n",
      "Epoch 00093: val_accuracy did not improve from 0.88291\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3657 - accuracy: 0.8915 - val_loss: 1.2268 - val_accuracy: 0.6261\n",
      "Epoch 94/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3684 - accuracy: 0.8898\n",
      "Epoch 00094: val_accuracy improved from 0.88291 to 0.88574, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.3679 - accuracy: 0.8904 - val_loss: 0.3741 - val_accuracy: 0.8857\n",
      "Epoch 95/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3597 - accuracy: 0.8953\n",
      "Epoch 00095: val_accuracy did not improve from 0.88574\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3594 - accuracy: 0.8956 - val_loss: 0.8717 - val_accuracy: 0.6884\n",
      "Epoch 96/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3594 - accuracy: 0.8927\n",
      "Epoch 00096: val_accuracy did not improve from 0.88574\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3591 - accuracy: 0.8930 - val_loss: 0.4086 - val_accuracy: 0.8669\n",
      "Epoch 97/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3577 - accuracy: 0.8898\n",
      "Epoch 00097: val_accuracy did not improve from 0.88574\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3571 - accuracy: 0.8901 - val_loss: 0.4549 - val_accuracy: 0.8366\n",
      "Epoch 98/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3611 - accuracy: 0.8915\n",
      "Epoch 00098: val_accuracy did not improve from 0.88574\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3611 - accuracy: 0.8918 - val_loss: 0.3995 - val_accuracy: 0.8744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3532 - accuracy: 0.8950\n",
      "Epoch 00099: val_accuracy did not improve from 0.88574\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3532 - accuracy: 0.8953 - val_loss: 0.3793 - val_accuracy: 0.8744\n",
      "Epoch 100/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3536 - accuracy: 0.8934\n",
      "Epoch 00100: val_accuracy improved from 0.88574 to 0.88763, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.3534 - accuracy: 0.8934 - val_loss: 0.3722 - val_accuracy: 0.8876\n",
      "Epoch 101/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3564 - accuracy: 0.8953\n",
      "Epoch 00101: val_accuracy did not improve from 0.88763\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3563 - accuracy: 0.8953 - val_loss: 0.4779 - val_accuracy: 0.8442\n",
      "Epoch 102/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3569 - accuracy: 0.8922\n",
      "Epoch 00102: val_accuracy improved from 0.88763 to 0.88952, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.3575 - accuracy: 0.8922 - val_loss: 0.3746 - val_accuracy: 0.8895\n",
      "Epoch 103/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3490 - accuracy: 0.8943\n",
      "Epoch 00103: val_accuracy did not improve from 0.88952\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3490 - accuracy: 0.8939 - val_loss: 0.3912 - val_accuracy: 0.8772\n",
      "Epoch 104/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3535 - accuracy: 0.8953\n",
      "Epoch 00104: val_accuracy did not improve from 0.88952\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3534 - accuracy: 0.8958 - val_loss: 0.4202 - val_accuracy: 0.8621\n",
      "Epoch 105/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3486 - accuracy: 0.8934\n",
      "Epoch 00105: val_accuracy did not improve from 0.88952\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3487 - accuracy: 0.8937 - val_loss: 0.4704 - val_accuracy: 0.8319\n",
      "Epoch 106/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3624 - accuracy: 0.8872\n",
      "Epoch 00106: val_accuracy did not improve from 0.88952\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3618 - accuracy: 0.8875 - val_loss: 0.7313 - val_accuracy: 0.7224\n",
      "Epoch 107/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3381 - accuracy: 0.9022\n",
      "Epoch 00107: val_accuracy improved from 0.88952 to 0.89613, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.3383 - accuracy: 0.9022 - val_loss: 0.3704 - val_accuracy: 0.8961\n",
      "Epoch 108/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3415 - accuracy: 0.9036\n",
      "Epoch 00108: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3415 - accuracy: 0.9034 - val_loss: 0.3704 - val_accuracy: 0.8857\n",
      "Epoch 109/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3426 - accuracy: 0.9012\n",
      "Epoch 00109: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3433 - accuracy: 0.9000 - val_loss: 0.4540 - val_accuracy: 0.8470\n",
      "Epoch 110/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3429 - accuracy: 0.8986\n",
      "Epoch 00110: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3426 - accuracy: 0.8991 - val_loss: 0.4022 - val_accuracy: 0.8782\n",
      "Epoch 111/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3395 - accuracy: 0.9024\n",
      "Epoch 00111: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3411 - accuracy: 0.9012 - val_loss: 0.4728 - val_accuracy: 0.8451\n",
      "Epoch 112/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3490 - accuracy: 0.8948\n",
      "Epoch 00112: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3498 - accuracy: 0.8944 - val_loss: 0.4119 - val_accuracy: 0.8565\n",
      "Epoch 113/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3394 - accuracy: 0.9005\n",
      "Epoch 00113: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3397 - accuracy: 0.9003 - val_loss: 0.4551 - val_accuracy: 0.8281\n",
      "Epoch 114/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3369 - accuracy: 0.9048\n",
      "Epoch 00114: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3370 - accuracy: 0.9048 - val_loss: 0.4996 - val_accuracy: 0.8291\n",
      "Epoch 115/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3488 - accuracy: 0.8960\n",
      "Epoch 00115: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3489 - accuracy: 0.8960 - val_loss: 0.5438 - val_accuracy: 0.8130\n",
      "Epoch 116/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3409 - accuracy: 0.9003\n",
      "Epoch 00116: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3403 - accuracy: 0.9005 - val_loss: 0.3863 - val_accuracy: 0.8820\n",
      "Epoch 117/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3265 - accuracy: 0.9079\n",
      "Epoch 00117: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3258 - accuracy: 0.9081 - val_loss: 0.3612 - val_accuracy: 0.8886\n",
      "Epoch 118/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3321 - accuracy: 0.9041\n",
      "Epoch 00118: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3329 - accuracy: 0.9036 - val_loss: 0.5518 - val_accuracy: 0.7998\n",
      "Epoch 119/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3291 - accuracy: 0.9072\n",
      "Epoch 00119: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3289 - accuracy: 0.9076 - val_loss: 0.3627 - val_accuracy: 0.8857\n",
      "Epoch 120/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3352 - accuracy: 0.9034\n",
      "Epoch 00120: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3349 - accuracy: 0.9036 - val_loss: 0.4858 - val_accuracy: 0.8319\n",
      "Epoch 121/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3393 - accuracy: 0.9022\n",
      "Epoch 00121: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3402 - accuracy: 0.9010 - val_loss: 0.3662 - val_accuracy: 0.8942\n",
      "Epoch 122/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.3305 - accuracy: 0.9075\n",
      "Epoch 00122: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3301 - accuracy: 0.9076 - val_loss: 0.3944 - val_accuracy: 0.8820\n",
      "Epoch 123/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3314 - accuracy: 0.9079\n",
      "Epoch 00123: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3311 - accuracy: 0.9076 - val_loss: 0.4551 - val_accuracy: 0.8442\n",
      "Epoch 124/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3398 - accuracy: 0.8979\n",
      "Epoch 00124: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3394 - accuracy: 0.8982 - val_loss: 0.9321 - val_accuracy: 0.6922\n",
      "Epoch 125/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3281 - accuracy: 0.9070\n",
      "Epoch 00125: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3277 - accuracy: 0.9067 - val_loss: 0.4144 - val_accuracy: 0.8716\n",
      "Epoch 126/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3332 - accuracy: 0.9055\n",
      "Epoch 00126: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3329 - accuracy: 0.9052 - val_loss: 1.1517 - val_accuracy: 0.6468\n",
      "Epoch 127/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/133 [============================>.] - ETA: 0s - loss: 0.3370 - accuracy: 0.9022\n",
      "Epoch 00127: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3381 - accuracy: 0.9015 - val_loss: 0.4025 - val_accuracy: 0.8772\n",
      "Epoch 128/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3261 - accuracy: 0.9046\n",
      "Epoch 00128: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3252 - accuracy: 0.9055 - val_loss: 0.4428 - val_accuracy: 0.8508\n",
      "Epoch 129/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3260 - accuracy: 0.9060\n",
      "Epoch 00129: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3258 - accuracy: 0.9057 - val_loss: 0.3769 - val_accuracy: 0.8801\n",
      "Epoch 130/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3196 - accuracy: 0.9127\n",
      "Epoch 00130: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3200 - accuracy: 0.9123 - val_loss: 0.3800 - val_accuracy: 0.8725\n",
      "Epoch 131/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3231 - accuracy: 0.9062\n",
      "Epoch 00131: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3232 - accuracy: 0.9062 - val_loss: 0.3581 - val_accuracy: 0.8857\n",
      "Epoch 132/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3244 - accuracy: 0.9125\n",
      "Epoch 00132: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3244 - accuracy: 0.9123 - val_loss: 0.3818 - val_accuracy: 0.8895\n",
      "Epoch 133/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3330 - accuracy: 0.9051\n",
      "Epoch 00133: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3352 - accuracy: 0.9045 - val_loss: 0.9467 - val_accuracy: 0.7073\n",
      "Epoch 134/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3194 - accuracy: 0.9051\n",
      "Epoch 00134: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.3191 - accuracy: 0.9055 - val_loss: 0.8006 - val_accuracy: 0.7224\n",
      "Epoch 135/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3322 - accuracy: 0.9055\n",
      "Epoch 00135: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3312 - accuracy: 0.9060 - val_loss: 0.3596 - val_accuracy: 0.8895\n",
      "Epoch 136/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3167 - accuracy: 0.9148\n",
      "Epoch 00136: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3158 - accuracy: 0.9152 - val_loss: 0.3578 - val_accuracy: 0.8810\n",
      "Epoch 137/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3275 - accuracy: 0.9082\n",
      "Epoch 00137: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3266 - accuracy: 0.9086 - val_loss: 1.0942 - val_accuracy: 0.6487\n",
      "Epoch 138/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3142 - accuracy: 0.9189\n",
      "Epoch 00138: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3147 - accuracy: 0.9187 - val_loss: 0.6294 - val_accuracy: 0.7923\n",
      "Epoch 139/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3276 - accuracy: 0.9086\n",
      "Epoch 00139: val_accuracy did not improve from 0.89613\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3265 - accuracy: 0.9093 - val_loss: 0.3856 - val_accuracy: 0.8914\n",
      "Epoch 140/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3144 - accuracy: 0.9125\n",
      "Epoch 00140: val_accuracy improved from 0.89613 to 0.89896, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.3164 - accuracy: 0.9121 - val_loss: 0.3554 - val_accuracy: 0.8990\n",
      "Epoch 141/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3189 - accuracy: 0.9094\n",
      "Epoch 00141: val_accuracy did not improve from 0.89896\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3184 - accuracy: 0.9095 - val_loss: 0.4905 - val_accuracy: 0.8451\n",
      "Epoch 142/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3419 - accuracy: 0.9020\n",
      "Epoch 00142: val_accuracy did not improve from 0.89896\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3411 - accuracy: 0.9024 - val_loss: 0.4598 - val_accuracy: 0.8423\n",
      "Epoch 143/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3110 - accuracy: 0.9175\n",
      "Epoch 00143: val_accuracy did not improve from 0.89896\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3109 - accuracy: 0.9178 - val_loss: 0.4875 - val_accuracy: 0.8366\n",
      "Epoch 144/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3115 - accuracy: 0.9132\n",
      "Epoch 00144: val_accuracy did not improve from 0.89896\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3113 - accuracy: 0.9133 - val_loss: 0.6414 - val_accuracy: 0.7951\n",
      "Epoch 145/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3217 - accuracy: 0.9091\n",
      "Epoch 00145: val_accuracy did not improve from 0.89896\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3219 - accuracy: 0.9095 - val_loss: 0.4142 - val_accuracy: 0.8697\n",
      "Epoch 146/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3130 - accuracy: 0.9175\n",
      "Epoch 00146: val_accuracy did not improve from 0.89896\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3126 - accuracy: 0.9178 - val_loss: 0.3675 - val_accuracy: 0.8886\n",
      "Epoch 147/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3071 - accuracy: 0.9163\n",
      "Epoch 00147: val_accuracy did not improve from 0.89896\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3080 - accuracy: 0.9164 - val_loss: 0.8528 - val_accuracy: 0.7082\n",
      "Epoch 148/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3125 - accuracy: 0.9160\n",
      "Epoch 00148: val_accuracy did not improve from 0.89896\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3118 - accuracy: 0.9168 - val_loss: 0.5167 - val_accuracy: 0.8291\n",
      "Epoch 149/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3086 - accuracy: 0.9165\n",
      "Epoch 00149: val_accuracy did not improve from 0.89896\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3079 - accuracy: 0.9166 - val_loss: 0.3712 - val_accuracy: 0.8857\n",
      "Epoch 150/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3197 - accuracy: 0.9110\n",
      "Epoch 00150: val_accuracy did not improve from 0.89896\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3194 - accuracy: 0.9112 - val_loss: 0.4170 - val_accuracy: 0.8640\n",
      "Epoch 151/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3165 - accuracy: 0.9129\n",
      "Epoch 00151: val_accuracy did not improve from 0.89896\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3159 - accuracy: 0.9133 - val_loss: 0.4723 - val_accuracy: 0.8357\n",
      "Epoch 152/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3185 - accuracy: 0.9110\n",
      "Epoch 00152: val_accuracy did not improve from 0.89896\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3186 - accuracy: 0.9114 - val_loss: 0.3668 - val_accuracy: 0.8886\n",
      "Epoch 153/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3100 - accuracy: 0.9179\n",
      "Epoch 00153: val_accuracy improved from 0.89896 to 0.90274, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.3096 - accuracy: 0.9178 - val_loss: 0.3582 - val_accuracy: 0.9027\n",
      "Epoch 154/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3041 - accuracy: 0.9239\n",
      "Epoch 00154: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3046 - accuracy: 0.9234 - val_loss: 0.4323 - val_accuracy: 0.8565\n",
      "Epoch 155/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/133 [============================>.] - ETA: 0s - loss: 0.3061 - accuracy: 0.9153\n",
      "Epoch 00155: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3053 - accuracy: 0.9159 - val_loss: 0.4145 - val_accuracy: 0.8602\n",
      "Epoch 156/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3030 - accuracy: 0.9208\n",
      "Epoch 00156: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3021 - accuracy: 0.9213 - val_loss: 0.3850 - val_accuracy: 0.8706\n",
      "Epoch 157/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3080 - accuracy: 0.9163\n",
      "Epoch 00157: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3076 - accuracy: 0.9168 - val_loss: 0.6125 - val_accuracy: 0.7989\n",
      "Epoch 158/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3103 - accuracy: 0.9146\n",
      "Epoch 00158: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3104 - accuracy: 0.9145 - val_loss: 0.6820 - val_accuracy: 0.7828\n",
      "Epoch 159/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3017 - accuracy: 0.9184\n",
      "Epoch 00159: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3016 - accuracy: 0.9182 - val_loss: 0.7533 - val_accuracy: 0.7620\n",
      "Epoch 160/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2998 - accuracy: 0.9222\n",
      "Epoch 00160: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2997 - accuracy: 0.9220 - val_loss: 0.5909 - val_accuracy: 0.8159\n",
      "Epoch 161/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3082 - accuracy: 0.9141\n",
      "Epoch 00161: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3086 - accuracy: 0.9135 - val_loss: 0.3691 - val_accuracy: 0.8857\n",
      "Epoch 162/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3048 - accuracy: 0.9167\n",
      "Epoch 00162: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3037 - accuracy: 0.9175 - val_loss: 0.5936 - val_accuracy: 0.8140\n",
      "Epoch 163/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3049 - accuracy: 0.9206\n",
      "Epoch 00163: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3059 - accuracy: 0.9199 - val_loss: 0.7688 - val_accuracy: 0.7422\n",
      "Epoch 164/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3171 - accuracy: 0.9144\n",
      "Epoch 00164: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3168 - accuracy: 0.9147 - val_loss: 0.4754 - val_accuracy: 0.8470\n",
      "Epoch 165/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2963 - accuracy: 0.9227\n",
      "Epoch 00165: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2966 - accuracy: 0.9227 - val_loss: 0.3924 - val_accuracy: 0.8687\n",
      "Epoch 166/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2944 - accuracy: 0.9189\n",
      "Epoch 00166: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2947 - accuracy: 0.9187 - val_loss: 0.4441 - val_accuracy: 0.8725\n",
      "Epoch 167/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3026 - accuracy: 0.9187\n",
      "Epoch 00167: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3029 - accuracy: 0.9185 - val_loss: 0.5442 - val_accuracy: 0.8329\n",
      "Epoch 168/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3145 - accuracy: 0.9148\n",
      "Epoch 00168: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3139 - accuracy: 0.9149 - val_loss: 0.9991 - val_accuracy: 0.7016\n",
      "Epoch 169/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3048 - accuracy: 0.9172\n",
      "Epoch 00169: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3047 - accuracy: 0.9175 - val_loss: 0.4004 - val_accuracy: 0.8848\n",
      "Epoch 170/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3060 - accuracy: 0.9198\n",
      "Epoch 00170: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3064 - accuracy: 0.9194 - val_loss: 0.4183 - val_accuracy: 0.8602\n",
      "Epoch 171/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3034 - accuracy: 0.9253\n",
      "Epoch 00171: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3029 - accuracy: 0.9256 - val_loss: 0.4366 - val_accuracy: 0.8574\n",
      "Epoch 172/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3036 - accuracy: 0.9232\n",
      "Epoch 00172: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3039 - accuracy: 0.9232 - val_loss: 0.5692 - val_accuracy: 0.8055\n",
      "Epoch 173/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2990 - accuracy: 0.9220\n",
      "Epoch 00173: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2994 - accuracy: 0.9216 - val_loss: 0.4132 - val_accuracy: 0.8763\n",
      "Epoch 174/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2916 - accuracy: 0.9313\n",
      "Epoch 00174: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2925 - accuracy: 0.9308 - val_loss: 0.5590 - val_accuracy: 0.8055\n",
      "Epoch 175/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3047 - accuracy: 0.9175\n",
      "Epoch 00175: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3045 - accuracy: 0.9173 - val_loss: 0.3732 - val_accuracy: 0.8933\n",
      "Epoch 176/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3004 - accuracy: 0.9244\n",
      "Epoch 00176: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3000 - accuracy: 0.9246 - val_loss: 0.5768 - val_accuracy: 0.8225\n",
      "Epoch 177/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3082 - accuracy: 0.9170\n",
      "Epoch 00177: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3077 - accuracy: 0.9173 - val_loss: 0.4209 - val_accuracy: 0.8801\n",
      "Epoch 178/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3006 - accuracy: 0.9241\n",
      "Epoch 00178: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3002 - accuracy: 0.9241 - val_loss: 0.4040 - val_accuracy: 0.8886\n",
      "Epoch 179/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2900 - accuracy: 0.9284\n",
      "Epoch 00179: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2892 - accuracy: 0.9291 - val_loss: 0.4944 - val_accuracy: 0.8451\n",
      "Epoch 180/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2936 - accuracy: 0.9258\n",
      "Epoch 00180: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2939 - accuracy: 0.9258 - val_loss: 0.3711 - val_accuracy: 0.8933\n",
      "Epoch 181/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2956 - accuracy: 0.9275\n",
      "Epoch 00181: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2943 - accuracy: 0.9282 - val_loss: 0.3759 - val_accuracy: 0.8933\n",
      "Epoch 182/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2923 - accuracy: 0.9253\n",
      "Epoch 00182: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2927 - accuracy: 0.9249 - val_loss: 1.1775 - val_accuracy: 0.6563\n",
      "Epoch 183/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3001 - accuracy: 0.9237\n",
      "Epoch 00183: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2996 - accuracy: 0.9239 - val_loss: 0.4507 - val_accuracy: 0.8480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3095 - accuracy: 0.9151\n",
      "Epoch 00184: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3097 - accuracy: 0.9147 - val_loss: 0.3814 - val_accuracy: 0.8772\n",
      "Epoch 185/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3055 - accuracy: 0.9225\n",
      "Epoch 00185: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3052 - accuracy: 0.9225 - val_loss: 0.4069 - val_accuracy: 0.8829\n",
      "Epoch 186/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2968 - accuracy: 0.9218\n",
      "Epoch 00186: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2954 - accuracy: 0.9225 - val_loss: 0.8041 - val_accuracy: 0.7545\n",
      "Epoch 187/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2853 - accuracy: 0.9270\n",
      "Epoch 00187: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2856 - accuracy: 0.9267 - val_loss: 0.3701 - val_accuracy: 0.8867\n",
      "Epoch 188/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.3117 - accuracy: 0.9210\n",
      "Epoch 00188: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.3129 - accuracy: 0.9206 - val_loss: 0.6818 - val_accuracy: 0.7866\n",
      "Epoch 189/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2899 - accuracy: 0.9258\n",
      "Epoch 00189: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2909 - accuracy: 0.9251 - val_loss: 0.5347 - val_accuracy: 0.8432\n",
      "Epoch 190/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2828 - accuracy: 0.9301\n",
      "Epoch 00190: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2839 - accuracy: 0.9293 - val_loss: 0.6884 - val_accuracy: 0.7941\n",
      "Epoch 191/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2815 - accuracy: 0.9280\n",
      "Epoch 00191: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2815 - accuracy: 0.9282 - val_loss: 0.3663 - val_accuracy: 0.8999\n",
      "Epoch 192/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2832 - accuracy: 0.9301\n",
      "Epoch 00192: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2831 - accuracy: 0.9301 - val_loss: 0.5748 - val_accuracy: 0.8178\n",
      "Epoch 193/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2949 - accuracy: 0.9234\n",
      "Epoch 00193: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2953 - accuracy: 0.9237 - val_loss: 0.4982 - val_accuracy: 0.8319\n",
      "Epoch 194/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2956 - accuracy: 0.9234\n",
      "Epoch 00194: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2949 - accuracy: 0.9239 - val_loss: 0.4031 - val_accuracy: 0.8933\n",
      "Epoch 195/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2826 - accuracy: 0.9320\n",
      "Epoch 00195: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2820 - accuracy: 0.9322 - val_loss: 0.5003 - val_accuracy: 0.8536\n",
      "Epoch 196/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2904 - accuracy: 0.9282\n",
      "Epoch 00196: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2902 - accuracy: 0.9284 - val_loss: 0.4295 - val_accuracy: 0.8725\n",
      "Epoch 197/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2886 - accuracy: 0.9277\n",
      "Epoch 00197: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2897 - accuracy: 0.9277 - val_loss: 0.4127 - val_accuracy: 0.8602\n",
      "Epoch 198/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2869 - accuracy: 0.9289\n",
      "Epoch 00198: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2897 - accuracy: 0.9270 - val_loss: 0.4113 - val_accuracy: 0.8801\n",
      "Epoch 199/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.2820 - accuracy: 0.9334\n",
      "Epoch 00199: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2817 - accuracy: 0.9334 - val_loss: 0.7187 - val_accuracy: 0.7734\n",
      "Epoch 200/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2880 - accuracy: 0.9251\n",
      "Epoch 00200: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2874 - accuracy: 0.9256 - val_loss: 0.5358 - val_accuracy: 0.8281\n",
      "Epoch 201/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2876 - accuracy: 0.9282\n",
      "Epoch 00201: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2874 - accuracy: 0.9284 - val_loss: 0.4327 - val_accuracy: 0.8744\n",
      "Epoch 202/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2828 - accuracy: 0.9294\n",
      "Epoch 00202: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2824 - accuracy: 0.9293 - val_loss: 0.3792 - val_accuracy: 0.8961\n",
      "Epoch 203/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2793 - accuracy: 0.9332\n",
      "Epoch 00203: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2797 - accuracy: 0.9329 - val_loss: 0.3996 - val_accuracy: 0.8706\n",
      "Epoch 204/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2840 - accuracy: 0.9313\n",
      "Epoch 00204: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2847 - accuracy: 0.9305 - val_loss: 0.4507 - val_accuracy: 0.8565\n",
      "Epoch 205/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2899 - accuracy: 0.9246\n",
      "Epoch 00205: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2895 - accuracy: 0.9251 - val_loss: 0.3947 - val_accuracy: 0.8876\n",
      "Epoch 206/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2865 - accuracy: 0.9265\n",
      "Epoch 00206: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2854 - accuracy: 0.9272 - val_loss: 0.3542 - val_accuracy: 0.8999\n",
      "Epoch 207/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2880 - accuracy: 0.9277\n",
      "Epoch 00207: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2874 - accuracy: 0.9279 - val_loss: 0.3733 - val_accuracy: 0.8942\n",
      "Epoch 208/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2777 - accuracy: 0.9313\n",
      "Epoch 00208: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2786 - accuracy: 0.9312 - val_loss: 0.5708 - val_accuracy: 0.8130\n",
      "Epoch 209/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2814 - accuracy: 0.9325\n",
      "Epoch 00209: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2806 - accuracy: 0.9329 - val_loss: 0.3749 - val_accuracy: 0.8886\n",
      "Epoch 210/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2793 - accuracy: 0.9332\n",
      "Epoch 00210: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2800 - accuracy: 0.9327 - val_loss: 0.4744 - val_accuracy: 0.8423\n",
      "Epoch 211/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2917 - accuracy: 0.9277\n",
      "Epoch 00211: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2916 - accuracy: 0.9277 - val_loss: 0.3942 - val_accuracy: 0.8857\n",
      "Epoch 212/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2793 - accuracy: 0.9354\n",
      "Epoch 00212: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2792 - accuracy: 0.9353 - val_loss: 0.6528 - val_accuracy: 0.7960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2729 - accuracy: 0.9323\n",
      "Epoch 00213: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2724 - accuracy: 0.9324 - val_loss: 0.3538 - val_accuracy: 0.9018\n",
      "Epoch 214/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2780 - accuracy: 0.9354\n",
      "Epoch 00214: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2775 - accuracy: 0.9357 - val_loss: 0.5170 - val_accuracy: 0.8517\n",
      "Epoch 215/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2842 - accuracy: 0.9320\n",
      "Epoch 00215: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2830 - accuracy: 0.9327 - val_loss: 0.4969 - val_accuracy: 0.8432\n",
      "Epoch 216/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2787 - accuracy: 0.9346\n",
      "Epoch 00216: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2791 - accuracy: 0.9341 - val_loss: 0.3559 - val_accuracy: 0.9027\n",
      "Epoch 217/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2864 - accuracy: 0.9282\n",
      "Epoch 00217: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2857 - accuracy: 0.9286 - val_loss: 0.4027 - val_accuracy: 0.8782\n",
      "Epoch 218/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2800 - accuracy: 0.9299\n",
      "Epoch 00218: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2795 - accuracy: 0.9301 - val_loss: 0.3724 - val_accuracy: 0.8924\n",
      "Epoch 219/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2830 - accuracy: 0.9313\n",
      "Epoch 00219: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2829 - accuracy: 0.9308 - val_loss: 0.9527 - val_accuracy: 0.7271\n",
      "Epoch 220/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2880 - accuracy: 0.9265\n",
      "Epoch 00220: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2873 - accuracy: 0.9267 - val_loss: 0.3790 - val_accuracy: 0.8829\n",
      "Epoch 221/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2761 - accuracy: 0.9282\n",
      "Epoch 00221: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2764 - accuracy: 0.9282 - val_loss: 0.3793 - val_accuracy: 0.8952\n",
      "Epoch 222/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2746 - accuracy: 0.9334\n",
      "Epoch 00222: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2752 - accuracy: 0.9329 - val_loss: 0.3837 - val_accuracy: 0.8924\n",
      "Epoch 223/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2820 - accuracy: 0.9296\n",
      "Epoch 00223: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2820 - accuracy: 0.9296 - val_loss: 0.4244 - val_accuracy: 0.8631\n",
      "Epoch 224/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2760 - accuracy: 0.9289\n",
      "Epoch 00224: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2751 - accuracy: 0.9293 - val_loss: 0.4443 - val_accuracy: 0.8716\n",
      "Epoch 225/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2685 - accuracy: 0.9380\n",
      "Epoch 00225: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2691 - accuracy: 0.9376 - val_loss: 0.4598 - val_accuracy: 0.8640\n",
      "Epoch 226/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.2855 - accuracy: 0.9267\n",
      "Epoch 00226: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2855 - accuracy: 0.9267 - val_loss: 0.4204 - val_accuracy: 0.8678\n",
      "Epoch 227/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.2752 - accuracy: 0.9322\n",
      "Epoch 00227: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2759 - accuracy: 0.9324 - val_loss: 1.0020 - val_accuracy: 0.7214\n",
      "Epoch 228/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2697 - accuracy: 0.9363\n",
      "Epoch 00228: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2703 - accuracy: 0.9357 - val_loss: 0.3858 - val_accuracy: 0.8876\n",
      "Epoch 229/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2599 - accuracy: 0.9358\n",
      "Epoch 00229: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2592 - accuracy: 0.9362 - val_loss: 0.3802 - val_accuracy: 0.8942\n",
      "Epoch 230/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2765 - accuracy: 0.9296\n",
      "Epoch 00230: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2757 - accuracy: 0.9301 - val_loss: 0.5456 - val_accuracy: 0.8329\n",
      "Epoch 231/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.2799 - accuracy: 0.9295\n",
      "Epoch 00231: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.2797 - accuracy: 0.9296 - val_loss: 0.5344 - val_accuracy: 0.8385\n",
      "Epoch 232/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.2756 - accuracy: 0.9329\n",
      "Epoch 00232: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2751 - accuracy: 0.9336 - val_loss: 0.5096 - val_accuracy: 0.8461\n",
      "Epoch 233/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2723 - accuracy: 0.9349\n",
      "Epoch 00233: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2721 - accuracy: 0.9348 - val_loss: 0.5610 - val_accuracy: 0.8196\n",
      "Epoch 234/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.2691 - accuracy: 0.9371\n",
      "Epoch 00234: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2691 - accuracy: 0.9371 - val_loss: 0.5296 - val_accuracy: 0.8423\n",
      "Epoch 235/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.2672 - accuracy: 0.9377\n",
      "Epoch 00235: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2676 - accuracy: 0.9374 - val_loss: 0.5586 - val_accuracy: 0.8234\n",
      "Epoch 236/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2766 - accuracy: 0.9346\n",
      "Epoch 00236: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2773 - accuracy: 0.9341 - val_loss: 0.5093 - val_accuracy: 0.8319\n",
      "Epoch 237/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.2718 - accuracy: 0.9363\n",
      "Epoch 00237: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2764 - accuracy: 0.9355 - val_loss: 0.4899 - val_accuracy: 0.8584\n",
      "Epoch 238/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.2797 - accuracy: 0.9250\n",
      "Epoch 00238: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2794 - accuracy: 0.9256 - val_loss: 0.6527 - val_accuracy: 0.8036\n",
      "Epoch 239/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2684 - accuracy: 0.9358\n",
      "Epoch 00239: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2684 - accuracy: 0.9357 - val_loss: 0.5622 - val_accuracy: 0.8178\n",
      "Epoch 240/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2664 - accuracy: 0.9411\n",
      "Epoch 00240: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2668 - accuracy: 0.9409 - val_loss: 0.3755 - val_accuracy: 0.8791\n",
      "Epoch 241/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2648 - accuracy: 0.9365\n",
      "Epoch 00241: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2650 - accuracy: 0.9364 - val_loss: 0.3667 - val_accuracy: 0.8924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.2728 - accuracy: 0.9329\n",
      "Epoch 00242: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2718 - accuracy: 0.9334 - val_loss: 0.4045 - val_accuracy: 0.8848\n",
      "Epoch 243/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2780 - accuracy: 0.9323\n",
      "Epoch 00243: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2783 - accuracy: 0.9327 - val_loss: 0.5765 - val_accuracy: 0.8291\n",
      "Epoch 244/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.2682 - accuracy: 0.9365\n",
      "Epoch 00244: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2682 - accuracy: 0.9360 - val_loss: 0.4447 - val_accuracy: 0.8574\n",
      "Epoch 245/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.2744 - accuracy: 0.9344\n",
      "Epoch 00245: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2740 - accuracy: 0.9345 - val_loss: 0.6286 - val_accuracy: 0.8196\n",
      "Epoch 246/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2630 - accuracy: 0.9430\n",
      "Epoch 00246: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2620 - accuracy: 0.9435 - val_loss: 0.4272 - val_accuracy: 0.8810\n",
      "Epoch 247/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2580 - accuracy: 0.9416\n",
      "Epoch 00247: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2582 - accuracy: 0.9414 - val_loss: 0.4134 - val_accuracy: 0.8839\n",
      "Epoch 248/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.2651 - accuracy: 0.9389\n",
      "Epoch 00248: val_accuracy did not improve from 0.90274\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2654 - accuracy: 0.9388 - val_loss: 0.3806 - val_accuracy: 0.8839\n",
      "Epoch 249/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2609 - accuracy: 0.9399\n",
      "Epoch 00249: val_accuracy improved from 0.90274 to 0.90368, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.2619 - accuracy: 0.9390 - val_loss: 0.3497 - val_accuracy: 0.9037\n",
      "Epoch 250/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2701 - accuracy: 0.9354\n",
      "Epoch 00250: val_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2698 - accuracy: 0.9355 - val_loss: 0.3981 - val_accuracy: 0.8867\n",
      "Epoch 251/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2783 - accuracy: 0.9337\n",
      "Epoch 00251: val_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2780 - accuracy: 0.9338 - val_loss: 0.3891 - val_accuracy: 0.8971\n",
      "Epoch 252/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2664 - accuracy: 0.9370\n",
      "Epoch 00252: val_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2662 - accuracy: 0.9371 - val_loss: 0.3784 - val_accuracy: 0.8952\n",
      "Epoch 253/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2607 - accuracy: 0.9373\n",
      "Epoch 00253: val_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2604 - accuracy: 0.9374 - val_loss: 0.7031 - val_accuracy: 0.7998\n",
      "Epoch 254/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2741 - accuracy: 0.9339\n",
      "Epoch 00254: val_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2746 - accuracy: 0.9334 - val_loss: 0.6602 - val_accuracy: 0.7998\n",
      "Epoch 255/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2792 - accuracy: 0.9346\n",
      "Epoch 00255: val_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2786 - accuracy: 0.9348 - val_loss: 0.4576 - val_accuracy: 0.8744\n",
      "Epoch 256/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2613 - accuracy: 0.9413\n",
      "Epoch 00256: val_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2617 - accuracy: 0.9412 - val_loss: 0.3669 - val_accuracy: 0.8952\n",
      "Epoch 257/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2741 - accuracy: 0.9354\n",
      "Epoch 00257: val_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2751 - accuracy: 0.9353 - val_loss: 0.3778 - val_accuracy: 0.8942\n",
      "Epoch 258/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2621 - accuracy: 0.9411\n",
      "Epoch 00258: val_accuracy did not improve from 0.90368\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2625 - accuracy: 0.9412 - val_loss: 0.9576 - val_accuracy: 0.7460\n",
      "Epoch 259/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2780 - accuracy: 0.9356\n",
      "Epoch 00259: val_accuracy improved from 0.90368 to 0.90746, saving model to ./weight_cp\\weight_lstm2_noms.hdf5\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.2783 - accuracy: 0.9357 - val_loss: 0.3842 - val_accuracy: 0.9075\n",
      "Epoch 260/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2666 - accuracy: 0.9356\n",
      "Epoch 00260: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2685 - accuracy: 0.9353 - val_loss: 0.3888 - val_accuracy: 0.8933\n",
      "Epoch 261/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2569 - accuracy: 0.9451\n",
      "Epoch 00261: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2564 - accuracy: 0.9454 - val_loss: 0.4137 - val_accuracy: 0.8839\n",
      "Epoch 262/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.2795 - accuracy: 0.9335\n",
      "Epoch 00262: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2794 - accuracy: 0.9336 - val_loss: 0.4592 - val_accuracy: 0.8706\n",
      "Epoch 263/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.2763 - accuracy: 0.9353\n",
      "Epoch 00263: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2756 - accuracy: 0.9355 - val_loss: 0.4583 - val_accuracy: 0.8678\n",
      "Epoch 264/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2572 - accuracy: 0.9437\n",
      "Epoch 00264: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2572 - accuracy: 0.9438 - val_loss: 0.3716 - val_accuracy: 0.8886\n",
      "Epoch 265/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2762 - accuracy: 0.9296\n",
      "Epoch 00265: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2755 - accuracy: 0.9301 - val_loss: 0.5353 - val_accuracy: 0.8329\n",
      "Epoch 266/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2615 - accuracy: 0.9401\n",
      "Epoch 00266: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2622 - accuracy: 0.9400 - val_loss: 0.5523 - val_accuracy: 0.8319\n",
      "Epoch 267/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2547 - accuracy: 0.9401\n",
      "Epoch 00267: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2549 - accuracy: 0.9400 - val_loss: 0.5037 - val_accuracy: 0.8329\n",
      "Epoch 268/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2575 - accuracy: 0.9408\n",
      "Epoch 00268: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2580 - accuracy: 0.9407 - val_loss: 0.8298 - val_accuracy: 0.7724\n",
      "Epoch 269/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2718 - accuracy: 0.9361\n",
      "Epoch 00269: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2715 - accuracy: 0.9364 - val_loss: 0.4304 - val_accuracy: 0.8678\n",
      "Epoch 270/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/133 [============================>.] - ETA: 0s - loss: 0.2650 - accuracy: 0.9365\n",
      "Epoch 00270: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2650 - accuracy: 0.9367 - val_loss: 0.9068 - val_accuracy: 0.7668\n",
      "Epoch 271/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2719 - accuracy: 0.9375\n",
      "Epoch 00271: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2719 - accuracy: 0.9379 - val_loss: 0.3865 - val_accuracy: 0.8886\n",
      "Epoch 272/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2591 - accuracy: 0.9449\n",
      "Epoch 00272: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2588 - accuracy: 0.9452 - val_loss: 0.3844 - val_accuracy: 0.8876\n",
      "Epoch 273/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2564 - accuracy: 0.9442\n",
      "Epoch 00273: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2557 - accuracy: 0.9445 - val_loss: 0.3822 - val_accuracy: 0.8990\n",
      "Epoch 274/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2556 - accuracy: 0.9406\n",
      "Epoch 00274: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2559 - accuracy: 0.9405 - val_loss: 0.4048 - val_accuracy: 0.8886\n",
      "Epoch 275/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2607 - accuracy: 0.9401\n",
      "Epoch 00275: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2603 - accuracy: 0.9405 - val_loss: 0.3965 - val_accuracy: 0.8942\n",
      "Epoch 276/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2597 - accuracy: 0.9416\n",
      "Epoch 00276: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2590 - accuracy: 0.9421 - val_loss: 0.4555 - val_accuracy: 0.8631\n",
      "Epoch 277/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2610 - accuracy: 0.9416\n",
      "Epoch 00277: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2617 - accuracy: 0.9414 - val_loss: 0.3645 - val_accuracy: 0.8933\n",
      "Epoch 278/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2574 - accuracy: 0.9413\n",
      "Epoch 00278: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2574 - accuracy: 0.9414 - val_loss: 0.4861 - val_accuracy: 0.8499\n",
      "Epoch 279/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2549 - accuracy: 0.9432\n",
      "Epoch 00279: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2551 - accuracy: 0.9431 - val_loss: 0.4087 - val_accuracy: 0.8905\n",
      "Epoch 280/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2711 - accuracy: 0.9346\n",
      "Epoch 00280: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2699 - accuracy: 0.9353 - val_loss: 0.3993 - val_accuracy: 0.8914\n",
      "Epoch 281/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2603 - accuracy: 0.9375\n",
      "Epoch 00281: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2613 - accuracy: 0.9369 - val_loss: 2.2571 - val_accuracy: 0.5958\n",
      "Epoch 282/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2641 - accuracy: 0.9375\n",
      "Epoch 00282: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2648 - accuracy: 0.9374 - val_loss: 0.3857 - val_accuracy: 0.8952\n",
      "Epoch 283/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2671 - accuracy: 0.9406\n",
      "Epoch 00283: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2667 - accuracy: 0.9407 - val_loss: 0.5006 - val_accuracy: 0.8621\n",
      "Epoch 284/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2618 - accuracy: 0.9375\n",
      "Epoch 00284: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2622 - accuracy: 0.9371 - val_loss: 0.7660 - val_accuracy: 0.7904\n",
      "Epoch 285/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2585 - accuracy: 0.9418\n",
      "Epoch 00285: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2585 - accuracy: 0.9419 - val_loss: 0.6314 - val_accuracy: 0.8281\n",
      "Epoch 286/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2581 - accuracy: 0.9408\n",
      "Epoch 00286: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2591 - accuracy: 0.9405 - val_loss: 0.3759 - val_accuracy: 0.8980\n",
      "Epoch 287/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2612 - accuracy: 0.9385\n",
      "Epoch 00287: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2615 - accuracy: 0.9386 - val_loss: 0.4011 - val_accuracy: 0.8895\n",
      "Epoch 288/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2547 - accuracy: 0.9475\n",
      "Epoch 00288: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2545 - accuracy: 0.9478 - val_loss: 0.5826 - val_accuracy: 0.8253\n",
      "Epoch 289/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2567 - accuracy: 0.9435\n",
      "Epoch 00289: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2569 - accuracy: 0.9435 - val_loss: 0.3791 - val_accuracy: 0.8886\n",
      "Epoch 290/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2482 - accuracy: 0.9432\n",
      "Epoch 00290: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2477 - accuracy: 0.9433 - val_loss: 0.4024 - val_accuracy: 0.8886\n",
      "Epoch 291/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2558 - accuracy: 0.9456\n",
      "Epoch 00291: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2554 - accuracy: 0.9454 - val_loss: 0.3763 - val_accuracy: 0.8952\n",
      "Epoch 292/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2548 - accuracy: 0.9456\n",
      "Epoch 00292: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2549 - accuracy: 0.9452 - val_loss: 0.3723 - val_accuracy: 0.8999\n",
      "Epoch 293/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2534 - accuracy: 0.9435\n",
      "Epoch 00293: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2538 - accuracy: 0.9433 - val_loss: 0.4040 - val_accuracy: 0.8848\n",
      "Epoch 294/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2517 - accuracy: 0.9461\n",
      "Epoch 00294: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2517 - accuracy: 0.9459 - val_loss: 0.4574 - val_accuracy: 0.8763\n",
      "Epoch 295/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2507 - accuracy: 0.9473\n",
      "Epoch 00295: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2513 - accuracy: 0.9471 - val_loss: 0.3707 - val_accuracy: 0.8886\n",
      "Epoch 296/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2542 - accuracy: 0.9437\n",
      "Epoch 00296: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2539 - accuracy: 0.9438 - val_loss: 0.3776 - val_accuracy: 0.8839\n",
      "Epoch 297/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2526 - accuracy: 0.9451\n",
      "Epoch 00297: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2526 - accuracy: 0.9449 - val_loss: 0.3735 - val_accuracy: 0.8905\n",
      "Epoch 298/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2519 - accuracy: 0.9406\n",
      "Epoch 00298: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2521 - accuracy: 0.9407 - val_loss: 0.3784 - val_accuracy: 0.8990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2589 - accuracy: 0.9394\n",
      "Epoch 00299: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2601 - accuracy: 0.9383 - val_loss: 0.4691 - val_accuracy: 0.8763\n",
      "Epoch 300/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2492 - accuracy: 0.9470\n",
      "Epoch 00300: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2495 - accuracy: 0.9468 - val_loss: 0.7574 - val_accuracy: 0.7960\n",
      "Epoch 301/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2500 - accuracy: 0.9470\n",
      "Epoch 00301: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2503 - accuracy: 0.9466 - val_loss: 0.4472 - val_accuracy: 0.8612\n",
      "Epoch 302/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2559 - accuracy: 0.9463\n",
      "Epoch 00302: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2559 - accuracy: 0.9461 - val_loss: 0.4254 - val_accuracy: 0.8772\n",
      "Epoch 303/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2612 - accuracy: 0.9406\n",
      "Epoch 00303: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2615 - accuracy: 0.9402 - val_loss: 0.3739 - val_accuracy: 0.8848\n",
      "Epoch 304/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2553 - accuracy: 0.9454\n",
      "Epoch 00304: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2555 - accuracy: 0.9449 - val_loss: 0.4160 - val_accuracy: 0.8886\n",
      "Epoch 305/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2415 - accuracy: 0.9454\n",
      "Epoch 00305: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2418 - accuracy: 0.9454 - val_loss: 1.1743 - val_accuracy: 0.7035\n",
      "Epoch 306/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2560 - accuracy: 0.9442\n",
      "Epoch 00306: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2565 - accuracy: 0.9440 - val_loss: 0.7154 - val_accuracy: 0.8008\n",
      "Epoch 307/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2469 - accuracy: 0.9463\n",
      "Epoch 00307: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2464 - accuracy: 0.9464 - val_loss: 0.4218 - val_accuracy: 0.8725\n",
      "Epoch 308/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2629 - accuracy: 0.9394\n",
      "Epoch 00308: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2625 - accuracy: 0.9395 - val_loss: 0.4034 - val_accuracy: 0.8810\n",
      "Epoch 309/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2474 - accuracy: 0.9487\n",
      "Epoch 00309: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2473 - accuracy: 0.9490 - val_loss: 0.4194 - val_accuracy: 0.8933\n",
      "Epoch 310/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2420 - accuracy: 0.9492\n",
      "Epoch 00310: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2418 - accuracy: 0.9492 - val_loss: 0.5090 - val_accuracy: 0.8555\n",
      "Epoch 311/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2444 - accuracy: 0.9463\n",
      "Epoch 00311: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2448 - accuracy: 0.9459 - val_loss: 0.3732 - val_accuracy: 0.8980\n",
      "Epoch 312/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2550 - accuracy: 0.9478\n",
      "Epoch 00312: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2550 - accuracy: 0.9478 - val_loss: 0.5438 - val_accuracy: 0.8357\n",
      "Epoch 313/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2373 - accuracy: 0.9518\n",
      "Epoch 00313: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2371 - accuracy: 0.9520 - val_loss: 0.4624 - val_accuracy: 0.8810\n",
      "Epoch 314/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2539 - accuracy: 0.9432\n",
      "Epoch 00314: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2532 - accuracy: 0.9435 - val_loss: 0.7713 - val_accuracy: 0.7904\n",
      "Epoch 315/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2551 - accuracy: 0.9418\n",
      "Epoch 00315: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2554 - accuracy: 0.9416 - val_loss: 0.3899 - val_accuracy: 0.8839\n",
      "Epoch 316/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2560 - accuracy: 0.9423\n",
      "Epoch 00316: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2561 - accuracy: 0.9423 - val_loss: 0.7382 - val_accuracy: 0.8017\n",
      "Epoch 317/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2638 - accuracy: 0.9394\n",
      "Epoch 00317: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2651 - accuracy: 0.9390 - val_loss: 0.4308 - val_accuracy: 0.8810\n",
      "Epoch 318/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2615 - accuracy: 0.9401\n",
      "Epoch 00318: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2612 - accuracy: 0.9402 - val_loss: 0.5503 - val_accuracy: 0.8489\n",
      "Epoch 319/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2553 - accuracy: 0.9439\n",
      "Epoch 00319: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2554 - accuracy: 0.9440 - val_loss: 0.4170 - val_accuracy: 0.8848\n",
      "Epoch 320/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2524 - accuracy: 0.9463\n",
      "Epoch 00320: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2518 - accuracy: 0.9466 - val_loss: 0.4012 - val_accuracy: 0.8829\n",
      "Epoch 321/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2449 - accuracy: 0.9473\n",
      "Epoch 00321: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2454 - accuracy: 0.9471 - val_loss: 0.5374 - val_accuracy: 0.8357\n",
      "Epoch 322/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2438 - accuracy: 0.9463\n",
      "Epoch 00322: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2441 - accuracy: 0.9461 - val_loss: 0.3843 - val_accuracy: 0.8961\n",
      "Epoch 323/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2608 - accuracy: 0.9439\n",
      "Epoch 00323: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2600 - accuracy: 0.9445 - val_loss: 0.7401 - val_accuracy: 0.7894\n",
      "Epoch 324/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2455 - accuracy: 0.9480\n",
      "Epoch 00324: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2456 - accuracy: 0.9475 - val_loss: 0.4301 - val_accuracy: 0.8829\n",
      "Epoch 325/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2474 - accuracy: 0.9437\n",
      "Epoch 00325: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2467 - accuracy: 0.9440 - val_loss: 0.3837 - val_accuracy: 0.9008\n",
      "Epoch 326/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2385 - accuracy: 0.9518\n",
      "Epoch 00326: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2394 - accuracy: 0.9516 - val_loss: 0.4267 - val_accuracy: 0.8716\n",
      "Epoch 327/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2618 - accuracy: 0.9389\n",
      "Epoch 00327: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2616 - accuracy: 0.9390 - val_loss: 1.3369 - val_accuracy: 0.6591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 328/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2496 - accuracy: 0.9435\n",
      "Epoch 00328: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2491 - accuracy: 0.9438 - val_loss: 0.3735 - val_accuracy: 0.8971\n",
      "Epoch 329/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2469 - accuracy: 0.9451\n",
      "Epoch 00329: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2477 - accuracy: 0.9445 - val_loss: 0.4191 - val_accuracy: 0.8857\n",
      "Epoch 330/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2680 - accuracy: 0.9358\n",
      "Epoch 00330: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2691 - accuracy: 0.9353 - val_loss: 0.6721 - val_accuracy: 0.8017\n",
      "Epoch 331/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2492 - accuracy: 0.9468\n",
      "Epoch 00331: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2498 - accuracy: 0.9464 - val_loss: 0.7109 - val_accuracy: 0.8045\n",
      "Epoch 332/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2431 - accuracy: 0.9494\n",
      "Epoch 00332: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2441 - accuracy: 0.9492 - val_loss: 0.5434 - val_accuracy: 0.8555\n",
      "Epoch 333/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2531 - accuracy: 0.9458\n",
      "Epoch 00333: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2525 - accuracy: 0.9461 - val_loss: 0.4882 - val_accuracy: 0.8451\n",
      "Epoch 334/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2532 - accuracy: 0.9416\n",
      "Epoch 00334: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2540 - accuracy: 0.9412 - val_loss: 0.4856 - val_accuracy: 0.8499\n",
      "Epoch 335/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2406 - accuracy: 0.9511\n",
      "Epoch 00335: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2407 - accuracy: 0.9511 - val_loss: 0.7596 - val_accuracy: 0.7913\n",
      "Epoch 336/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2460 - accuracy: 0.9482\n",
      "Epoch 00336: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2462 - accuracy: 0.9483 - val_loss: 0.3814 - val_accuracy: 0.8971\n",
      "Epoch 337/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2447 - accuracy: 0.9490\n",
      "Epoch 00337: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2448 - accuracy: 0.9490 - val_loss: 0.5913 - val_accuracy: 0.8300\n",
      "Epoch 338/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2345 - accuracy: 0.9513\n",
      "Epoch 00338: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2344 - accuracy: 0.9518 - val_loss: 1.3711 - val_accuracy: 0.6723\n",
      "Epoch 339/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2410 - accuracy: 0.9521\n",
      "Epoch 00339: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2415 - accuracy: 0.9516 - val_loss: 0.6248 - val_accuracy: 0.8319\n",
      "Epoch 340/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.2454 - accuracy: 0.9474\n",
      "Epoch 00340: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2460 - accuracy: 0.9471 - val_loss: 0.3811 - val_accuracy: 0.8990\n",
      "Epoch 341/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2584 - accuracy: 0.9423\n",
      "Epoch 00341: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2587 - accuracy: 0.9419 - val_loss: 0.3780 - val_accuracy: 0.8886\n",
      "Epoch 342/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2386 - accuracy: 0.9492\n",
      "Epoch 00342: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2389 - accuracy: 0.9490 - val_loss: 0.3772 - val_accuracy: 0.8886\n",
      "Epoch 343/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.2382 - accuracy: 0.9530\n",
      "Epoch 00343: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2382 - accuracy: 0.9530 - val_loss: 0.3825 - val_accuracy: 0.8829\n",
      "Epoch 344/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.2534 - accuracy: 0.9458\n",
      "Epoch 00344: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2532 - accuracy: 0.9459 - val_loss: 0.3620 - val_accuracy: 0.8942\n",
      "Epoch 345/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.2482 - accuracy: 0.9447\n",
      "Epoch 00345: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2482 - accuracy: 0.9447 - val_loss: 0.3995 - val_accuracy: 0.8876\n",
      "Epoch 346/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.2361 - accuracy: 0.9508\n",
      "Epoch 00346: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2378 - accuracy: 0.9501 - val_loss: 0.6118 - val_accuracy: 0.8196\n",
      "Epoch 347/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.2590 - accuracy: 0.9430\n",
      "Epoch 00347: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2581 - accuracy: 0.9433 - val_loss: 0.4072 - val_accuracy: 0.8867\n",
      "Epoch 348/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.2508 - accuracy: 0.9445\n",
      "Epoch 00348: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2508 - accuracy: 0.9445 - val_loss: 0.5301 - val_accuracy: 0.8432\n",
      "Epoch 349/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2371 - accuracy: 0.9478\n",
      "Epoch 00349: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2365 - accuracy: 0.9483 - val_loss: 0.4413 - val_accuracy: 0.8829\n",
      "Epoch 350/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2536 - accuracy: 0.9425\n",
      "Epoch 00350: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2536 - accuracy: 0.9428 - val_loss: 0.4067 - val_accuracy: 0.8820\n",
      "Epoch 351/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2387 - accuracy: 0.9535\n",
      "Epoch 00351: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2381 - accuracy: 0.9537 - val_loss: 0.3752 - val_accuracy: 0.8942\n",
      "Epoch 352/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2500 - accuracy: 0.9432\n",
      "Epoch 00352: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2496 - accuracy: 0.9431 - val_loss: 0.3875 - val_accuracy: 0.8961\n",
      "Epoch 353/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.2434 - accuracy: 0.9502\n",
      "Epoch 00353: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2433 - accuracy: 0.9506 - val_loss: 0.3831 - val_accuracy: 0.8980\n",
      "Epoch 354/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2417 - accuracy: 0.9525\n",
      "Epoch 00354: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2421 - accuracy: 0.9525 - val_loss: 0.4290 - val_accuracy: 0.8754\n",
      "Epoch 355/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2487 - accuracy: 0.9442\n",
      "Epoch 00355: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2482 - accuracy: 0.9445 - val_loss: 0.4154 - val_accuracy: 0.8876\n",
      "Epoch 356/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2391 - accuracy: 0.9492\n",
      "Epoch 00356: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2399 - accuracy: 0.9490 - val_loss: 0.6423 - val_accuracy: 0.8196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 357/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2730 - accuracy: 0.9344\n",
      "Epoch 00357: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2723 - accuracy: 0.9348 - val_loss: 0.7357 - val_accuracy: 0.7998\n",
      "Epoch 358/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2388 - accuracy: 0.9521\n",
      "Epoch 00358: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2393 - accuracy: 0.9516 - val_loss: 0.3694 - val_accuracy: 0.9027\n",
      "Epoch 359/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2417 - accuracy: 0.9506\n",
      "Epoch 00359: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2414 - accuracy: 0.9509 - val_loss: 0.3863 - val_accuracy: 0.8895\n",
      "Epoch 360/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2360 - accuracy: 0.9563\n",
      "Epoch 00360: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2358 - accuracy: 0.9563 - val_loss: 0.7079 - val_accuracy: 0.7941\n",
      "Epoch 361/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2442 - accuracy: 0.9461\n",
      "Epoch 00361: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2446 - accuracy: 0.9459 - val_loss: 0.5126 - val_accuracy: 0.8527\n",
      "Epoch 362/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2483 - accuracy: 0.9466\n",
      "Epoch 00362: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2477 - accuracy: 0.9471 - val_loss: 0.4583 - val_accuracy: 0.8687\n",
      "Epoch 363/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2333 - accuracy: 0.9518\n",
      "Epoch 00363: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2339 - accuracy: 0.9516 - val_loss: 0.5996 - val_accuracy: 0.8329\n",
      "Epoch 364/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.2439 - accuracy: 0.9484\n",
      "Epoch 00364: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2441 - accuracy: 0.9483 - val_loss: 0.3749 - val_accuracy: 0.8971\n",
      "Epoch 365/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.2520 - accuracy: 0.9450\n",
      "Epoch 00365: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2537 - accuracy: 0.9442 - val_loss: 0.4369 - val_accuracy: 0.8659\n",
      "Epoch 366/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.2455 - accuracy: 0.9474\n",
      "Epoch 00366: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2446 - accuracy: 0.9478 - val_loss: 0.6253 - val_accuracy: 0.8234\n",
      "Epoch 367/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2350 - accuracy: 0.9480\n",
      "Epoch 00367: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2352 - accuracy: 0.9478 - val_loss: 0.3819 - val_accuracy: 0.8942\n",
      "Epoch 368/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2470 - accuracy: 0.9451\n",
      "Epoch 00368: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2465 - accuracy: 0.9454 - val_loss: 0.4932 - val_accuracy: 0.8612\n",
      "Epoch 369/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2629 - accuracy: 0.9404\n",
      "Epoch 00369: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2622 - accuracy: 0.9409 - val_loss: 0.6687 - val_accuracy: 0.8121\n",
      "Epoch 370/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2462 - accuracy: 0.9499\n",
      "Epoch 00370: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2464 - accuracy: 0.9497 - val_loss: 1.1346 - val_accuracy: 0.7299\n",
      "Epoch 371/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2386 - accuracy: 0.9501\n",
      "Epoch 00371: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2382 - accuracy: 0.9501 - val_loss: 0.3875 - val_accuracy: 0.8924\n",
      "Epoch 372/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2286 - accuracy: 0.9580\n",
      "Epoch 00372: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2288 - accuracy: 0.9575 - val_loss: 0.3962 - val_accuracy: 0.8914\n",
      "Epoch 373/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2317 - accuracy: 0.9561\n",
      "Epoch 00373: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2313 - accuracy: 0.9563 - val_loss: 0.4872 - val_accuracy: 0.8650\n",
      "Epoch 374/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2411 - accuracy: 0.9492\n",
      "Epoch 00374: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2421 - accuracy: 0.9485 - val_loss: 0.3920 - val_accuracy: 0.8839\n",
      "Epoch 375/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2537 - accuracy: 0.9418\n",
      "Epoch 00375: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2539 - accuracy: 0.9416 - val_loss: 0.5367 - val_accuracy: 0.8650\n",
      "Epoch 376/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2400 - accuracy: 0.9509\n",
      "Epoch 00376: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2397 - accuracy: 0.9509 - val_loss: 0.5330 - val_accuracy: 0.8546\n",
      "Epoch 377/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2413 - accuracy: 0.9482\n",
      "Epoch 00377: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2414 - accuracy: 0.9480 - val_loss: 0.7707 - val_accuracy: 0.8036\n",
      "Epoch 378/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2496 - accuracy: 0.9463\n",
      "Epoch 00378: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2485 - accuracy: 0.9468 - val_loss: 0.5582 - val_accuracy: 0.8565\n",
      "Epoch 379/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.2380 - accuracy: 0.9506\n",
      "Epoch 00379: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2387 - accuracy: 0.9501 - val_loss: 0.4082 - val_accuracy: 0.8876\n",
      "Epoch 380/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2386 - accuracy: 0.9494\n",
      "Epoch 00380: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2379 - accuracy: 0.9499 - val_loss: 0.3939 - val_accuracy: 0.8857\n",
      "Epoch 381/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2537 - accuracy: 0.9442\n",
      "Epoch 00381: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2538 - accuracy: 0.9445 - val_loss: 0.4826 - val_accuracy: 0.8631\n",
      "Epoch 382/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2410 - accuracy: 0.9535\n",
      "Epoch 00382: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2412 - accuracy: 0.9532 - val_loss: 0.6581 - val_accuracy: 0.8263\n",
      "Epoch 383/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2341 - accuracy: 0.9525\n",
      "Epoch 00383: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2348 - accuracy: 0.9523 - val_loss: 0.5516 - val_accuracy: 0.8546\n",
      "Epoch 384/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2372 - accuracy: 0.9530\n",
      "Epoch 00384: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2366 - accuracy: 0.9532 - val_loss: 0.4015 - val_accuracy: 0.8886\n",
      "Epoch 385/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2335 - accuracy: 0.9571\n",
      "Epoch 00385: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2338 - accuracy: 0.9568 - val_loss: 0.4189 - val_accuracy: 0.8829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2472 - accuracy: 0.9494\n",
      "Epoch 00386: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2481 - accuracy: 0.9492 - val_loss: 0.3792 - val_accuracy: 0.8980\n",
      "Epoch 387/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2455 - accuracy: 0.9487\n",
      "Epoch 00387: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2454 - accuracy: 0.9487 - val_loss: 0.4118 - val_accuracy: 0.8961\n",
      "Epoch 388/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2296 - accuracy: 0.9592\n",
      "Epoch 00388: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2300 - accuracy: 0.9589 - val_loss: 0.3726 - val_accuracy: 0.8952\n",
      "Epoch 389/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2289 - accuracy: 0.9547\n",
      "Epoch 00389: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2289 - accuracy: 0.9544 - val_loss: 0.3959 - val_accuracy: 0.8914\n",
      "Epoch 390/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2396 - accuracy: 0.9487\n",
      "Epoch 00390: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2395 - accuracy: 0.9487 - val_loss: 0.6508 - val_accuracy: 0.8187\n",
      "Epoch 391/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2510 - accuracy: 0.9454\n",
      "Epoch 00391: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2534 - accuracy: 0.9445 - val_loss: 0.3993 - val_accuracy: 0.8905\n",
      "Epoch 392/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2509 - accuracy: 0.9463\n",
      "Epoch 00392: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2514 - accuracy: 0.9459 - val_loss: 0.7384 - val_accuracy: 0.7932\n",
      "Epoch 393/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2397 - accuracy: 0.9509\n",
      "Epoch 00393: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2395 - accuracy: 0.9511 - val_loss: 0.8391 - val_accuracy: 0.7866\n",
      "Epoch 394/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2333 - accuracy: 0.9554\n",
      "Epoch 00394: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2333 - accuracy: 0.9551 - val_loss: 0.4421 - val_accuracy: 0.8801\n",
      "Epoch 395/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2379 - accuracy: 0.9516\n",
      "Epoch 00395: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2382 - accuracy: 0.9513 - val_loss: 0.4289 - val_accuracy: 0.8839\n",
      "Epoch 396/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2451 - accuracy: 0.9461\n",
      "Epoch 00396: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2446 - accuracy: 0.9464 - val_loss: 0.4034 - val_accuracy: 0.8895\n",
      "Epoch 397/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2456 - accuracy: 0.9511\n",
      "Epoch 00397: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2452 - accuracy: 0.9513 - val_loss: 0.3849 - val_accuracy: 0.8971\n",
      "Epoch 398/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2464 - accuracy: 0.9473\n",
      "Epoch 00398: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2462 - accuracy: 0.9473 - val_loss: 0.3911 - val_accuracy: 0.8971\n",
      "Epoch 399/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2499 - accuracy: 0.9468\n",
      "Epoch 00399: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2499 - accuracy: 0.9468 - val_loss: 0.5125 - val_accuracy: 0.8536\n",
      "Epoch 400/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2398 - accuracy: 0.9521\n",
      "Epoch 00400: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2398 - accuracy: 0.9520 - val_loss: 0.5889 - val_accuracy: 0.8319\n",
      "Epoch 401/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2358 - accuracy: 0.9506\n",
      "Epoch 00401: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2365 - accuracy: 0.9504 - val_loss: 0.3693 - val_accuracy: 0.8980\n",
      "Epoch 402/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.2464 - accuracy: 0.9491\n",
      "Epoch 00402: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2457 - accuracy: 0.9490 - val_loss: 0.4663 - val_accuracy: 0.8744\n",
      "Epoch 403/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2399 - accuracy: 0.9492\n",
      "Epoch 00403: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2400 - accuracy: 0.9492 - val_loss: 0.3938 - val_accuracy: 0.8924\n",
      "Epoch 404/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2450 - accuracy: 0.9482\n",
      "Epoch 00404: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2443 - accuracy: 0.9485 - val_loss: 0.6597 - val_accuracy: 0.8225\n",
      "Epoch 405/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2333 - accuracy: 0.9532\n",
      "Epoch 00405: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2347 - accuracy: 0.9527 - val_loss: 0.3811 - val_accuracy: 0.8952\n",
      "Epoch 406/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2195 - accuracy: 0.9585\n",
      "Epoch 00406: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2191 - accuracy: 0.9586 - val_loss: 0.3780 - val_accuracy: 0.8990\n",
      "Epoch 407/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2388 - accuracy: 0.9556\n",
      "Epoch 00407: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2399 - accuracy: 0.9551 - val_loss: 0.4776 - val_accuracy: 0.8697\n",
      "Epoch 408/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2264 - accuracy: 0.9559\n",
      "Epoch 00408: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2260 - accuracy: 0.9560 - val_loss: 0.3765 - val_accuracy: 0.9027\n",
      "Epoch 409/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2485 - accuracy: 0.9449\n",
      "Epoch 00409: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2480 - accuracy: 0.9452 - val_loss: 0.5438 - val_accuracy: 0.8517\n",
      "Epoch 410/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2348 - accuracy: 0.9530\n",
      "Epoch 00410: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2353 - accuracy: 0.9523 - val_loss: 1.1786 - val_accuracy: 0.7186\n",
      "Epoch 411/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2341 - accuracy: 0.9540\n",
      "Epoch 00411: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2350 - accuracy: 0.9537 - val_loss: 0.5609 - val_accuracy: 0.8366\n",
      "Epoch 412/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2352 - accuracy: 0.9532\n",
      "Epoch 00412: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2351 - accuracy: 0.9532 - val_loss: 0.6842 - val_accuracy: 0.8017\n",
      "Epoch 413/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2290 - accuracy: 0.9518\n",
      "Epoch 00413: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2292 - accuracy: 0.9516 - val_loss: 0.4290 - val_accuracy: 0.8791\n",
      "Epoch 414/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2319 - accuracy: 0.9525\n",
      "Epoch 00414: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2338 - accuracy: 0.9520 - val_loss: 0.4146 - val_accuracy: 0.8961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2482 - accuracy: 0.9454\n",
      "Epoch 00415: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2476 - accuracy: 0.9457 - val_loss: 0.4416 - val_accuracy: 0.8791\n",
      "Epoch 416/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2411 - accuracy: 0.9463\n",
      "Epoch 00416: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2418 - accuracy: 0.9457 - val_loss: 0.4347 - val_accuracy: 0.8678\n",
      "Epoch 417/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2380 - accuracy: 0.9516\n",
      "Epoch 00417: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2381 - accuracy: 0.9516 - val_loss: 0.3849 - val_accuracy: 0.8961\n",
      "Epoch 418/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2450 - accuracy: 0.9437\n",
      "Epoch 00418: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2445 - accuracy: 0.9440 - val_loss: 0.3933 - val_accuracy: 0.8914\n",
      "Epoch 419/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2480 - accuracy: 0.9435\n",
      "Epoch 00419: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2491 - accuracy: 0.9433 - val_loss: 0.4208 - val_accuracy: 0.8914\n",
      "Epoch 420/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2275 - accuracy: 0.9578\n",
      "Epoch 00420: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2272 - accuracy: 0.9577 - val_loss: 0.3874 - val_accuracy: 0.8886\n",
      "Epoch 421/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2243 - accuracy: 0.9563\n",
      "Epoch 00421: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2250 - accuracy: 0.9563 - val_loss: 0.3867 - val_accuracy: 0.8952\n",
      "Epoch 422/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2238 - accuracy: 0.9563\n",
      "Epoch 00422: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2231 - accuracy: 0.9565 - val_loss: 0.3973 - val_accuracy: 0.8905\n",
      "Epoch 423/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2380 - accuracy: 0.9528\n",
      "Epoch 00423: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2374 - accuracy: 0.9532 - val_loss: 0.4030 - val_accuracy: 0.8905\n",
      "Epoch 424/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2302 - accuracy: 0.9532\n",
      "Epoch 00424: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2304 - accuracy: 0.9532 - val_loss: 0.5661 - val_accuracy: 0.8442\n",
      "Epoch 425/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2441 - accuracy: 0.9501\n",
      "Epoch 00425: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2436 - accuracy: 0.9504 - val_loss: 0.4012 - val_accuracy: 0.8914\n",
      "Epoch 426/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2466 - accuracy: 0.9447\n",
      "Epoch 00426: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2464 - accuracy: 0.9445 - val_loss: 0.4847 - val_accuracy: 0.8602\n",
      "Epoch 427/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2399 - accuracy: 0.9501\n",
      "Epoch 00427: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2403 - accuracy: 0.9501 - val_loss: 0.3874 - val_accuracy: 0.8895\n",
      "Epoch 428/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2284 - accuracy: 0.9575\n",
      "Epoch 00428: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2287 - accuracy: 0.9572 - val_loss: 0.7634 - val_accuracy: 0.8178\n",
      "Epoch 429/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2366 - accuracy: 0.9499\n",
      "Epoch 00429: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2358 - accuracy: 0.9504 - val_loss: 0.4123 - val_accuracy: 0.8820\n",
      "Epoch 430/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2236 - accuracy: 0.9566\n",
      "Epoch 00430: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2236 - accuracy: 0.9565 - val_loss: 0.4000 - val_accuracy: 0.8980\n",
      "Epoch 431/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2342 - accuracy: 0.9537\n",
      "Epoch 00431: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2335 - accuracy: 0.9539 - val_loss: 0.4741 - val_accuracy: 0.8735\n",
      "Epoch 432/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2257 - accuracy: 0.9544\n",
      "Epoch 00432: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2252 - accuracy: 0.9549 - val_loss: 0.4164 - val_accuracy: 0.8961\n",
      "Epoch 433/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2292 - accuracy: 0.9552\n",
      "Epoch 00433: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2282 - accuracy: 0.9556 - val_loss: 0.5261 - val_accuracy: 0.8508\n",
      "Epoch 434/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2297 - accuracy: 0.9528\n",
      "Epoch 00434: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2300 - accuracy: 0.9523 - val_loss: 0.7798 - val_accuracy: 0.7989\n",
      "Epoch 435/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2410 - accuracy: 0.9485\n",
      "Epoch 00435: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2415 - accuracy: 0.9480 - val_loss: 0.5395 - val_accuracy: 0.8451\n",
      "Epoch 436/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2325 - accuracy: 0.9511\n",
      "Epoch 00436: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2324 - accuracy: 0.9511 - val_loss: 0.3751 - val_accuracy: 0.8961\n",
      "Epoch 437/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2584 - accuracy: 0.9423\n",
      "Epoch 00437: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2580 - accuracy: 0.9426 - val_loss: 0.4892 - val_accuracy: 0.8772\n",
      "Epoch 438/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2274 - accuracy: 0.9556\n",
      "Epoch 00438: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2268 - accuracy: 0.9558 - val_loss: 0.5407 - val_accuracy: 0.8621\n",
      "Epoch 439/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2191 - accuracy: 0.9604\n",
      "Epoch 00439: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2188 - accuracy: 0.9605 - val_loss: 0.4169 - val_accuracy: 0.8886\n",
      "Epoch 440/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2397 - accuracy: 0.9485\n",
      "Epoch 00440: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2391 - accuracy: 0.9490 - val_loss: 0.5324 - val_accuracy: 0.8593\n",
      "Epoch 441/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2272 - accuracy: 0.9556\n",
      "Epoch 00441: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2272 - accuracy: 0.9553 - val_loss: 0.4619 - val_accuracy: 0.8829\n",
      "Epoch 442/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.2336 - accuracy: 0.9510\n",
      "Epoch 00442: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2332 - accuracy: 0.9511 - val_loss: 0.8944 - val_accuracy: 0.7715\n",
      "Epoch 443/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.2293 - accuracy: 0.9557\n",
      "Epoch 00443: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2301 - accuracy: 0.9553 - val_loss: 0.8011 - val_accuracy: 0.8083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.2454 - accuracy: 0.9450\n",
      "Epoch 00444: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2446 - accuracy: 0.9452 - val_loss: 0.3817 - val_accuracy: 0.8990\n",
      "Epoch 445/500\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.2398 - accuracy: 0.9485\n",
      "Epoch 00445: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2398 - accuracy: 0.9485 - val_loss: 0.5400 - val_accuracy: 0.8602\n",
      "Epoch 446/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2263 - accuracy: 0.9547\n",
      "Epoch 00446: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2269 - accuracy: 0.9544 - val_loss: 0.5197 - val_accuracy: 0.8499\n",
      "Epoch 447/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2298 - accuracy: 0.9542\n",
      "Epoch 00447: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2297 - accuracy: 0.9544 - val_loss: 0.3897 - val_accuracy: 0.8914\n",
      "Epoch 448/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2413 - accuracy: 0.9478\n",
      "Epoch 00448: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2405 - accuracy: 0.9480 - val_loss: 0.5069 - val_accuracy: 0.8669\n",
      "Epoch 449/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2360 - accuracy: 0.9528\n",
      "Epoch 00449: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2354 - accuracy: 0.9530 - val_loss: 0.4523 - val_accuracy: 0.8782\n",
      "Epoch 450/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2234 - accuracy: 0.9580\n",
      "Epoch 00450: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2234 - accuracy: 0.9579 - val_loss: 0.4106 - val_accuracy: 0.8961\n",
      "Epoch 451/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2303 - accuracy: 0.9559\n",
      "Epoch 00451: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2301 - accuracy: 0.9560 - val_loss: 0.4640 - val_accuracy: 0.8697\n",
      "Epoch 452/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2362 - accuracy: 0.9521\n",
      "Epoch 00452: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2364 - accuracy: 0.9518 - val_loss: 0.4639 - val_accuracy: 0.8763\n",
      "Epoch 453/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2413 - accuracy: 0.9492\n",
      "Epoch 00453: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2407 - accuracy: 0.9494 - val_loss: 0.3877 - val_accuracy: 0.9065\n",
      "Epoch 454/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2229 - accuracy: 0.9559\n",
      "Epoch 00454: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2224 - accuracy: 0.9560 - val_loss: 0.5002 - val_accuracy: 0.8470\n",
      "Epoch 455/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2368 - accuracy: 0.9518\n",
      "Epoch 00455: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2362 - accuracy: 0.9523 - val_loss: 0.4819 - val_accuracy: 0.8706\n",
      "Epoch 456/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2281 - accuracy: 0.9563\n",
      "Epoch 00456: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2278 - accuracy: 0.9563 - val_loss: 0.4057 - val_accuracy: 0.8886\n",
      "Epoch 457/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2347 - accuracy: 0.9492\n",
      "Epoch 00457: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2344 - accuracy: 0.9492 - val_loss: 0.4601 - val_accuracy: 0.8820\n",
      "Epoch 458/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2292 - accuracy: 0.9571\n",
      "Epoch 00458: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2292 - accuracy: 0.9572 - val_loss: 0.4565 - val_accuracy: 0.8820\n",
      "Epoch 459/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2403 - accuracy: 0.9470\n",
      "Epoch 00459: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2395 - accuracy: 0.9475 - val_loss: 0.3896 - val_accuracy: 0.8952\n",
      "Epoch 460/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2211 - accuracy: 0.9559\n",
      "Epoch 00460: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2223 - accuracy: 0.9551 - val_loss: 0.4055 - val_accuracy: 0.8886\n",
      "Epoch 461/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2555 - accuracy: 0.9432\n",
      "Epoch 00461: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2569 - accuracy: 0.9426 - val_loss: 0.8955 - val_accuracy: 0.7686\n",
      "Epoch 462/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2260 - accuracy: 0.9552\n",
      "Epoch 00462: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2252 - accuracy: 0.9556 - val_loss: 0.4046 - val_accuracy: 0.8942\n",
      "Epoch 463/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2327 - accuracy: 0.9528\n",
      "Epoch 00463: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2327 - accuracy: 0.9527 - val_loss: 0.5450 - val_accuracy: 0.8508\n",
      "Epoch 464/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2293 - accuracy: 0.9528\n",
      "Epoch 00464: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2289 - accuracy: 0.9530 - val_loss: 0.7795 - val_accuracy: 0.7970\n",
      "Epoch 465/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2198 - accuracy: 0.9587\n",
      "Epoch 00465: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2194 - accuracy: 0.9591 - val_loss: 0.5411 - val_accuracy: 0.8555\n",
      "Epoch 466/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2347 - accuracy: 0.9528\n",
      "Epoch 00466: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2348 - accuracy: 0.9523 - val_loss: 0.3988 - val_accuracy: 0.8952\n",
      "Epoch 467/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2283 - accuracy: 0.9568\n",
      "Epoch 00467: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2276 - accuracy: 0.9572 - val_loss: 0.4752 - val_accuracy: 0.8659\n",
      "Epoch 468/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.2180 - accuracy: 0.9591\n",
      "Epoch 00468: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2174 - accuracy: 0.9596 - val_loss: 0.3840 - val_accuracy: 0.8990\n",
      "Epoch 469/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.2268 - accuracy: 0.9531\n",
      "Epoch 00469: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2270 - accuracy: 0.9527 - val_loss: 1.3147 - val_accuracy: 0.6837\n",
      "Epoch 470/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2343 - accuracy: 0.9535\n",
      "Epoch 00470: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2339 - accuracy: 0.9537 - val_loss: 0.4053 - val_accuracy: 0.8914\n",
      "Epoch 471/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2297 - accuracy: 0.9523\n",
      "Epoch 00471: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2293 - accuracy: 0.9525 - val_loss: 0.3879 - val_accuracy: 0.8952\n",
      "Epoch 472/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2305 - accuracy: 0.9547\n",
      "Epoch 00472: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2310 - accuracy: 0.9544 - val_loss: 0.4086 - val_accuracy: 0.8886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 473/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2315 - accuracy: 0.9559\n",
      "Epoch 00473: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2321 - accuracy: 0.9556 - val_loss: 0.3898 - val_accuracy: 0.8952\n",
      "Epoch 474/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.2432 - accuracy: 0.9493\n",
      "Epoch 00474: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2431 - accuracy: 0.9492 - val_loss: 0.7414 - val_accuracy: 0.8036\n",
      "Epoch 475/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2261 - accuracy: 0.9516\n",
      "Epoch 00475: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2256 - accuracy: 0.9518 - val_loss: 0.6446 - val_accuracy: 0.8234\n",
      "Epoch 476/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.2252 - accuracy: 0.9591\n",
      "Epoch 00476: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2256 - accuracy: 0.9591 - val_loss: 0.6494 - val_accuracy: 0.8366\n",
      "Epoch 477/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2263 - accuracy: 0.9568\n",
      "Epoch 00477: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2263 - accuracy: 0.9568 - val_loss: 0.3777 - val_accuracy: 0.8999\n",
      "Epoch 478/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2311 - accuracy: 0.9554\n",
      "Epoch 00478: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2307 - accuracy: 0.9556 - val_loss: 0.4433 - val_accuracy: 0.8772\n",
      "Epoch 479/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2250 - accuracy: 0.9556\n",
      "Epoch 00479: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2246 - accuracy: 0.9556 - val_loss: 1.2737 - val_accuracy: 0.7101\n",
      "Epoch 480/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.2282 - accuracy: 0.9563\n",
      "Epoch 00480: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2293 - accuracy: 0.9558 - val_loss: 0.4536 - val_accuracy: 0.8716\n",
      "Epoch 481/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2248 - accuracy: 0.9542\n",
      "Epoch 00481: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2255 - accuracy: 0.9539 - val_loss: 0.4644 - val_accuracy: 0.8763\n",
      "Epoch 482/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2358 - accuracy: 0.9482\n",
      "Epoch 00482: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2355 - accuracy: 0.9485 - val_loss: 0.4249 - val_accuracy: 0.8857\n",
      "Epoch 483/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2356 - accuracy: 0.9521\n",
      "Epoch 00483: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2348 - accuracy: 0.9525 - val_loss: 0.6320 - val_accuracy: 0.8300\n",
      "Epoch 484/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2204 - accuracy: 0.9580\n",
      "Epoch 00484: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2210 - accuracy: 0.9577 - val_loss: 0.3869 - val_accuracy: 0.8924\n",
      "Epoch 485/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2192 - accuracy: 0.9561\n",
      "Epoch 00485: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2189 - accuracy: 0.9563 - val_loss: 0.4270 - val_accuracy: 0.8810\n",
      "Epoch 486/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2392 - accuracy: 0.9487\n",
      "Epoch 00486: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2389 - accuracy: 0.9490 - val_loss: 0.9612 - val_accuracy: 0.7611\n",
      "Epoch 487/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2350 - accuracy: 0.9535\n",
      "Epoch 00487: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2348 - accuracy: 0.9532 - val_loss: 0.5502 - val_accuracy: 0.8376\n",
      "Epoch 488/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2170 - accuracy: 0.9616\n",
      "Epoch 00488: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2172 - accuracy: 0.9615 - val_loss: 0.3844 - val_accuracy: 0.8886\n",
      "Epoch 489/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2208 - accuracy: 0.9587\n",
      "Epoch 00489: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2203 - accuracy: 0.9591 - val_loss: 0.4543 - val_accuracy: 0.8857\n",
      "Epoch 490/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2278 - accuracy: 0.9540\n",
      "Epoch 00490: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2289 - accuracy: 0.9534 - val_loss: 0.3830 - val_accuracy: 0.9008\n",
      "Epoch 491/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.2319 - accuracy: 0.9502\n",
      "Epoch 00491: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2311 - accuracy: 0.9506 - val_loss: 0.7132 - val_accuracy: 0.8178\n",
      "Epoch 492/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2276 - accuracy: 0.9561\n",
      "Epoch 00492: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2270 - accuracy: 0.9563 - val_loss: 0.4159 - val_accuracy: 0.8999\n",
      "Epoch 493/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2351 - accuracy: 0.9528\n",
      "Epoch 00493: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2349 - accuracy: 0.9527 - val_loss: 0.4658 - val_accuracy: 0.8735\n",
      "Epoch 494/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2326 - accuracy: 0.9537\n",
      "Epoch 00494: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2320 - accuracy: 0.9539 - val_loss: 0.4300 - val_accuracy: 0.8867\n",
      "Epoch 495/500\n",
      "131/133 [============================>.] - ETA: 0s - loss: 0.2291 - accuracy: 0.9556\n",
      "Epoch 00495: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 0.2290 - accuracy: 0.9556 - val_loss: 0.4010 - val_accuracy: 0.9056\n",
      "Epoch 496/500\n",
      "130/133 [============================>.] - ETA: 0s - loss: 0.2253 - accuracy: 0.9538\n",
      "Epoch 00496: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 0.2247 - accuracy: 0.9542 - val_loss: 0.5515 - val_accuracy: 0.8565\n",
      "Epoch 497/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.2246 - accuracy: 0.9569\n",
      "Epoch 00497: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.2237 - accuracy: 0.9572 - val_loss: 0.8752 - val_accuracy: 0.7705\n",
      "Epoch 498/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.2211 - accuracy: 0.9564\n",
      "Epoch 00498: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.2209 - accuracy: 0.9565 - val_loss: 0.3924 - val_accuracy: 0.8952\n",
      "Epoch 499/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.2256 - accuracy: 0.9574\n",
      "Epoch 00499: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.2255 - accuracy: 0.9575 - val_loss: 0.3949 - val_accuracy: 0.8952\n",
      "Epoch 500/500\n",
      "129/133 [============================>.] - ETA: 0s - loss: 0.2109 - accuracy: 0.9617\n",
      "Epoch 00500: val_accuracy did not improve from 0.90746\n",
      "133/133 [==============================] - 2s 14ms/step - loss: 0.2120 - accuracy: 0.9612 - val_loss: 0.5611 - val_accuracy: 0.8480\n"
     ]
    }
   ],
   "source": [
    "# Output is only based on the output generated after conv\n",
    "def conv_only_no_ms(w2v):\n",
    "    inputs = Input(shape=(X_train[0].shape[-1],))\n",
    "\n",
    "    embedding_layer = gensim_to_keras_embedding(w2v)\n",
    "    \n",
    "    embedding = embedding_layer(inputs)\n",
    "\n",
    "    lstm1 = LSTM(lstm_units,return_sequences=True, return_state=True, kernel_regularizer=l2(w_decay),recurrent_regularizer=l2(w_decay), dropout=dropout_rate)(embedding)\n",
    "    \n",
    "    \n",
    "    \n",
    "    output = Dense(units=1, activation='sigmoid', name='op_main')(lstm1[1])\n",
    "    \n",
    "\n",
    "    output_td_gap = GlobalAveragePooling1D(data_format='channels_first')(lstm1[0])\n",
    "    \n",
    "    output_td = TimeDistributed(Dense(units=1, activation='sigmoid'))(lstm1[0])\n",
    "    output_td = Flatten()(output_td)\n",
    "    \n",
    "    output_td = Multiply()([output_td_gap, output_td])\n",
    "    \n",
    "    output_td = Activation('relu', name='before_split')(output_td)\n",
    "    \n",
    "    output_td_splits = tf.split(output_td, 10, axis=-1)\n",
    "    \n",
    "    features = concatenate([output_td_splits[0], output_td_splits[1], output_td_splits[-2], output_td_splits[-1]])\n",
    "    \n",
    "    print(features.shape)\n",
    "    \n",
    "    output_td = Reshape((8, 10, 1))(features)\n",
    "    \n",
    "    output_td = Conv2D(2, 8, padding='same', strides=1, activation='relu', kernel_regularizer=l2(w_decay))(output_td)\n",
    "    output_td = BatchNormalization()(output_td)\n",
    "    output_td = Flatten()(output_td)\n",
    "   \n",
    "\n",
    "    output_td = Dense(units=1, activation='sigmoid', name='op_conv')(output_td)\n",
    "    \n",
    "    \n",
    "    \n",
    "    avg = tf.keras.layers.Average(name='avg')([output, output_td])\n",
    "    \n",
    "\n",
    "    model = Model(inputs, output_td)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = conv_only_no_ms(w2v_model)\n",
    "\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint('./weight_cp/weight_lstm2_noms.hdf5', save_freq=\"epoch\",  verbose=1, monitor='val_accuracy', save_best_only=True,\n",
    "    save_weights_only=False)\n",
    "\n",
    "metrics = ['accuracy']\n",
    "optimizer = Adam(0.0001)\n",
    "model.compile(optimizer = optimizer, loss='binary_crossentropy', metrics=metrics)\n",
    "model.summary()\n",
    "history2 = model.fit(X_train, y_train, epochs=epochs_to_run, validation_data=(X_val, y_val), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17b6bcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT OF Not-MultiSupervised LSTM (Convolution output)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       661\n",
      "           1       0.92      0.85      0.89       662\n",
      "\n",
      "    accuracy                           0.89      1323\n",
      "   macro avg       0.89      0.89      0.89      1323\n",
      "weighted avg       0.89      0.89      0.89      1323\n",
      "\n",
      "0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "model = load_model('./weight_cp/weight_lstm2_noms.hdf5')\n",
    "predictionss = model.predict(X_test)\n",
    "predictions = np.where(predictionss > 0.5, 1, 0)\n",
    "y_pred = []\n",
    "for p in predictions:\n",
    "    y_pred.append(p[0])\n",
    "y_pred = np.array(y_pred)\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(\"CLASSIFICATION REPORT OF Not-MultiSupervised LSTM (Convolution output)\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7013a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history1.history['val_avg_accuracy'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.title('Validation accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['With MS', 'Without MS (Conv only)'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11c0a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5b2d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
